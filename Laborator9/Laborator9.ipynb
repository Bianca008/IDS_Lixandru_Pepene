{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = magenta> Lixandru Andreaa-Bianca Grupa10LF382\n",
    "<br> \n",
    "<font color = magenta> Pepene Adina-FLorentina Grupa10LF382"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laborator 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modele de regresie\n",
    "\n",
    "Folositi urmatoarele seturi de date:\n",
    "1. [CPU Computer Hardware](https://archive.ics.uci.edu/ml/datasets/Computer+Hardware); excludeti din dataset coloanele: vendor name, model name, estimated relative performance; se va estima coloana \"published relative performance\".\n",
    "1. [Boston Housing](http://archive.ics.uci.edu/ml/machine-learning-databases/housing/)\n",
    "1. [Wisconsin Breast Cancer](http://www.dcc.fc.up.pt/~ltorgo/Regression/DataSets.html); cautati in panelul din stanga Wisconsin Breast Cancer si urmati pasii din \"My personal Notes\"\n",
    "1. [Communities and Crime](http://archive.ics.uci.edu/ml/datasets/communities+and+crime); stergeti primele 5 dimensiuni si trasaturile cu missing values.\n",
    "\n",
    "Pentru fiecare set de date aplicati minim 5 modele de regresie din scikit learn. Pentru fiecare raportati: mean absolute error, mean squared error, median absolute error - a se vedea [sklearn.metrics](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics) - folosind 5 fold cross validation. Valorile hiperparametrilor trebuie cautate cu grid search (cv=3)  si random search (n_iter dat de voi). Metrica folosita pentru cautarea hiperparametrilor va fi mean squared error. Raportati mediile rezultatelor atat pentru fold-urile de antrenare, cat si pentru cele de testare; indicatie: puteti folosi metoda `cross_validate` cu parametrul `return_train_score=True`, iar ca model un obiect de tip `GridSearchCV` sau `RandomizedSearchCV`.\n",
    "\n",
    "Rezultatele vor fi trecute intr-un dataframe. Intr-o stare intermediara, valorile vor fi calculate cu semnul minus: din motive de implementare, biblioteca sklearn transforma scorurile in numere negative; a se vedea imaginea de mai jos:\n",
    "\n",
    "![intermediate report](./images/cpu_intermediate_blurred.png)\n",
    "\n",
    "\n",
    "Valorile vor fi aduse la interval pozitiv, apoi vor fi marcate cele maxime si minime; orientativ, se poate folosi imaginea de mai jos, reprezentand dataframe afisat in notebook; puteti folosi alte variante de styling pe dataframe precum la https://pandas.pydata.org/pandas-docs/stable/user_guide/style.html#.  \n",
    "\n",
    "Se va crea un raport final in format HTML sau PDF - fisier(e) separat(e). Raportul trebuie sa contina minimal: numele setului de date si obiectul dataframe; preferabil sa se pastreze marcajul de culori realizat in notebook.\n",
    "\n",
    "![report](./images/cpu_results_blurred.png)\n",
    "\n",
    "Notare:\n",
    "1. Se acorda 20 de puncte din oficiu.\n",
    "1. Optimizare si cuantificare de performanta a modelelor: 3 puncte pentru fiecare combinatie set de date + model = 60 de puncte\n",
    "1. Documentare modele: numar modele * 2 puncte = 10 puncte. Documentati in jupyter notebook fiecare din modelele folosite, in limba romana. Puteti face o sectiune separata cu documentarea algoritmilor. Fiecare model trebuie sa aiba o descriere de minim 20 de randuri, minim o imagine asociata si minim 2 referinte bibliografice.\n",
    "1. 10 puncte: export in format HTML sau PDF.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Notare:* rezolvarea va fi incarcata pe platforma de elearning in saptamana 11-15 mai."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Citirea si separarea datelor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from typing import List\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from statistics import mean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>myct</th>\n",
       "      <th>mmin</th>\n",
       "      <th>mmax</th>\n",
       "      <th>cach</th>\n",
       "      <th>chmin</th>\n",
       "      <th>chmax</th>\n",
       "      <th>prp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>125</td>\n",
       "      <td>256</td>\n",
       "      <td>6000</td>\n",
       "      <td>256</td>\n",
       "      <td>16</td>\n",
       "      <td>128</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29</td>\n",
       "      <td>8000</td>\n",
       "      <td>32000</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>8000</td>\n",
       "      <td>32000</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "      <td>8000</td>\n",
       "      <td>32000</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>8000</td>\n",
       "      <td>16000</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   myct  mmin   mmax  cach  chmin  chmax  prp\n",
       "0   125   256   6000   256     16    128  198\n",
       "1    29  8000  32000    32      8     32  269\n",
       "2    29  8000  32000    32      8     32  220\n",
       "3    29  8000  32000    32      8     32  172\n",
       "4    29  8000  16000    32      8     16  132"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_cpu_names = ['vendor_names', 'model', 'myct', 'mmin', 'mmax', 'cach', 'chmin', 'chmax', 'prp', 'erp']\n",
    "\n",
    "dataframe_cpu = pd.read_csv('data\\machine\\machine.data', names=dataframe_cpu_names, header=None)\n",
    "\n",
    "dataframe_cpu = dataframe_cpu.drop(columns=['vendor_names', 'model', 'erp'])\n",
    "\n",
    "dataframe_cpu.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_cpu_x = dataframe_cpu.values[:, :-1]\n",
    "dataframe_cpu_y = dataframe_cpu.values[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>b</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      crim    zn  indus  chas    nox     rm   age     dis  rad    tax  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296.0   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242.0   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242.0   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222.0   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222.0   \n",
       "\n",
       "   ptratio       b  lstat  medv  \n",
       "0     15.3  396.90   4.98  24.0  \n",
       "1     17.8  396.90   9.14  21.6  \n",
       "2     17.8  392.83   4.03  34.7  \n",
       "3     18.7  394.63   2.94  33.4  \n",
       "4     18.7  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_housing_names = ['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis',\n",
    "                           'rad', 'tax', 'ptratio', 'b', 'lstat', 'medv']\n",
    "\n",
    "dataframe_housing = pd.read_csv('data\\housing\\housing.data', names=dataframe_housing_names, header = None, sep=r\"\\s+\")\n",
    "\n",
    "dataframe_housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_housing_x = dataframe_housing.values[:, :-1]\n",
    "dataframe_housing_y = dataframe_housing.values[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cautarea hiperparametrilor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_grid(model, parameters:dict , x_train:np.ndarray, y_train:np.ndarray, x_test:np.ndarray, y_test:np.ndarray):\n",
    "    \n",
    "    '''This function takes the parameters and search for best parameters.\n",
    "    \n",
    "    Parameters:\n",
    "        model - model from sklearn \n",
    "        parameters - all the alternatives to the hyperparameters\n",
    "        x_train, y_train - input and output values for model train\n",
    "        x_test, y_test - input and output values for model test\n",
    "    \n",
    "    It returns the errors.\n",
    "    '''\n",
    "    \n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=parameters, scoring='neg_mean_squared_error', cv=3,  return_train_score=True)\n",
    "    grid_search.fit(x_train, y_train)\n",
    "    \n",
    "    return errors(grid_search, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_random(model, parameters:dict , x_train:np.ndarray, y_train:np.ndarray, x_test:np.ndarray, y_test:np.ndarray):\n",
    "    \n",
    "    '''This function takes the parameters and search for best parameters.\n",
    "    \n",
    "    Parameters:\n",
    "        model - model from sklearn \n",
    "        parameters - all the alternatives to the hyperparameters\n",
    "        x_train, y_train - input and output values for model train\n",
    "        x_test, y_test - input and output values for model test\n",
    "    \n",
    "    It returns the errors.\n",
    "    '''\n",
    "    rand_search = RandomizedSearchCV(estimator=model, param_distributions=parameters, scoring='neg_mean_squared_error', cv=3,  return_train_score=True)\n",
    "    rand_search.fit(x_train, y_train)\n",
    "    \n",
    "    return errors(rand_search, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calcularea erorilor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def errors(model, x_train:np.ndarray, y_train:np.ndarray, \n",
    "           x_test:np.ndarray, y_test:np.ndarray)-> List[float]:\n",
    "    \n",
    "    '''Errors function calculates mean absolute error, \n",
    "    mean squared error and median absolute error for model.\n",
    "    \n",
    "    Parameters:\n",
    "        model - model from sklearn \n",
    "        x_train, y_train - input and output values for model train\n",
    "        x_test, y_test - input and output values for model test\n",
    "        \n",
    "    Returns a list with mean of errors:\n",
    "    neg_mean_absolute_error for train and test data\n",
    "    neg_mean_squared_error for train and test data\n",
    "    neg_median_absolute_error for train and test data\n",
    "    '''\n",
    "    \n",
    "    scores_neg_mean_abs_err_train = (-1)*cross_val_score(model, x_train, y_train, cv = 5, scoring = 'neg_mean_absolute_error').mean()\n",
    "    scores_neg_mean_abs_err_test = (-1)*cross_val_score(model, x_test, y_test, cv = 5, scoring = 'neg_mean_absolute_error').mean()\n",
    "\n",
    "    scores_neg_mean_sq_err_train = (-1)*cross_val_score(model, x_train, y_train, cv = 5, scoring = 'neg_mean_squared_error').mean()\n",
    "    scores_neg_mean_sq_err_test = (-1)*cross_val_score(model, x_test, y_test, cv = 5, scoring = 'neg_mean_squared_error').mean()\n",
    "    \n",
    "    scores_neg_med_abs_err_train = (-1)*cross_val_score(model, x_train, y_train, cv = 5, scoring = 'neg_median_absolute_error').mean()\n",
    "    scores_neg_med_abs_err_test = (-1)*cross_val_score(model, x_test, y_test, cv = 5, scoring = 'neg_median_absolute_error').mean()\n",
    "    \n",
    "    result = [scores_neg_mean_abs_err_train, scores_neg_mean_abs_err_test,\n",
    "              scores_neg_mean_sq_err_train, scores_neg_mean_sq_err_test,\n",
    "              scores_neg_med_abs_err_train, scores_neg_med_abs_err_test]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbor Regression(KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN(model, parameters:dict, x_train:np.ndarray, y_train:np.ndarray, x_test:np.ndarray, y_test:np.ndarray):\n",
    "    \n",
    "    '''KNN function get params and do regression based on k-nearest\n",
    "    neighbors with best parameters generated by grid search and random search.\n",
    "    It generates the error values.\n",
    "    \n",
    "    Parameters:\n",
    "        model - model from sklearn \n",
    "        parameters - all the alternatives to the hyperparameters\n",
    "        x_train, y_train - input and output values for model train\n",
    "        x_test, y_test - input and output values for model test \n",
    "    '''\n",
    "    \n",
    "    print (\"KNN\", search_grid(model, parameters, x_train, y_train, x_test, y_test))\n",
    "    print ()\n",
    "    print (\"KNN\", search_random(model, parameters, x_train, y_train, x_test, y_test))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree(model, parameters:dict, x_train:np.ndarray, y_train:np.ndarray, x_test:np.ndarray, y_test:np.ndarray):\n",
    "    \n",
    "    '''decision_tree function get params and do regression based on k-nearest\n",
    "    neighbors with best parameters generated by grid search and random search.\n",
    "    It generates the error values.\n",
    "    \n",
    "    Parameters:\n",
    "        model - model from sklearn \n",
    "        parameters - all the alternatives to the hyperparameters\n",
    "        x_train, y_train - input and output values for model train\n",
    "        x_test, y_test - input and output values for model test \n",
    "    '''\n",
    "    \n",
    "    print (\"Decision tree\", search_grid(model, parameters, x_train, y_train, x_test, y_test))\n",
    "    print ()\n",
    "    print (\"Decision tree\", search_random(model, parameters, x_train, y_train, x_test, y_test))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aplicarea modelelor pentru generarea erorilor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start(x, y):\n",
    "    \n",
    "    model_knn = KNeighborsRegressor()\n",
    "    model_decision_tree = DecisionTreeRegressor()\n",
    "\n",
    "    parameters_knn = {'n_neighbors': [3, 4, 5, 6, 8, 9, 10, 11], 'p': [2, 3, 4, 5]}\n",
    "    parameters_decision_tree = {'criterion': ['mse', 'friedman_mse'], 'max_depth': [3, 4, 5, 6, 7, 8]}\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=1/3)\n",
    "\n",
    "    decision_tree(model_decision_tree, parameters_decision_tree, x_train, y_train, x_test, y_test)\n",
    "    KNN(model_knn, parameters_knn, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree [34.43845557216772, 50.58154761904761, 7472.485128888735, 14093.781254676873, 12.749682539682539, 26.304960317460313]\n",
      "\n",
      "Decision tree [39.00410090868706, 51.10272370486656, 8154.224963501588, 13393.481705296188, 15.168626110731372, 22.969404761904762]\n",
      "KNN [36.977513227513235, 45.64095238095238, 5044.218959435626, 13473.80428571429, 13.366666666666665, 20.21333333333333]\n",
      "\n",
      "KNN [38.09944885361552, 45.66666666666667, 5378.160319297472, 13840.437797619044, 13.366666666666665, 20.93]\n"
     ]
    }
   ],
   "source": [
    "start(dataframe_cpu_x, dataframe_cpu_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree [3.1843289438696987, 3.680714546576721, 25.54356646371312, 28.416172747449423, 2.1532699841412706, 2.4400141898864787]\n",
      "\n",
      "Decision tree [3.4805413771030613, 3.7210833303428417, 24.554647711055946, 27.791017390273915, 2.2651588730301606, 2.4801694389426263]\n",
      "KNN [4.6494776119402985, 4.901451574569221, 45.66102318798166, 48.88175789859378, 3.1453333333333346, 3.5760000000000005]\n",
      "\n",
      "KNN [4.790644205443372, 5.010717468805704, 45.410689652933584, 50.03384633034895, 3.1660000000000013, 3.772277777777778]\n"
     ]
    }
   ],
   "source": [
    "start(dataframe_housing_x, dataframe_housing_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documentatie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. K-Nearest Neighbors Regression(KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Nearest Neighbors Regression este un algoritm simplu care stochează toate cazurile posibile și prezice o valoare pe baza unei măsuri de similaritate (de exemplu, funcții de distanță). KNN a fost utilizat în estimarea statistică și recunoașterea modelului de la începutul anilor 1970 ca tehnică non-parametrică. Regresia KNN utilizează aceleași funcții de distanță ca și clasificarea KNN. K reprezinta numarul de vecini care este cautat pentru a-l determina pe cel mai potrivit.\n",
    "<br><br>Când __K = 1__ algoritmul este cunoscut ca nearest neighbor. Acesta este cel mai simplu caz. Sa presupunem că P1 este un punct pentru care trebuie sa ii prezicem eticheta. Mai întâi, găsim cel mai apropiat punct de P1 și atribuim eticheta acestuia lui P1.\n",
    "\n",
    "<img src=\"resources/image1.png\" width=\"400\">\n",
    "\n",
    "Un alt exemplu pentru __K = 3__ este:\n",
    "\n",
    "<img src=\"resources/image2.png\" width=\"400\">\n",
    "\n",
    "Urmarind plot-urile de mai jos putem observa ca folosind doar un singur vecin, fiecare punct din setul de antrenare are o influență evidentă asupra predicțiilor, iar valorile prezise trec prin toate punctele. Aceasta duce la o predicție foarte nesigură. Considerând mai mulți vecini se ajunge la predicții mai ușoare, dar acestea nu se potrivesc și cu datele de instruire.\n",
    "\n",
    "<img src=\"resources/image3.png\" width=\"1000\">\n",
    "\n",
    "Regresia K-Nearest Neighbors poate fi utilizată în cazurile în care etichetele de date sunt continue, mai degrabă decât variabile discrete. Eticheta atribuită unui punct de interogare este calculată pe baza mediilor etichetelor celor mai apropiați vecini.\n",
    "În faza de clasificare, k este o constantă definită de utilizator, iar un vector nemarcat (o interogare sau un punct de testare) este clasificat prin atribuirea etichetei care este cea mai frecventă dintre eșantioanele de pregătire k cele mai apropiate de punctul de interogare.\n",
    "\n",
    "__Metode de calcul al distantei dintre doua puncte__\n",
    "\n",
    "Algoritmul KNN este un algoritm de invatare supervizata, care foloseste distante pentru a gasi similitudini si diferente.\n",
    "\n",
    "__1. Distanta Euclidiana:__ este cea mai frecventă și măsoară distanța liniară dintre două probe\n",
    "__2. Distanta Manhattan:__ măsoară timpul de călătorie punct-la-punct și este utilizata în mod obișnuit pentru predictorii binari\n",
    "\n",
    "<img src=\"resources/image4.png\" width=\"250\">\n",
    "\n",
    "__3. Distanta Hamming__\n",
    "\n",
    "<img src=\"resources/image5.png\" width=\"150\">\n",
    "\n",
    "\n",
    "Distanta Euclidiana si distanta Manhattan sunt folosite pentru variabile continue, iar distanta Hamming este folosita pentru variabile categoriale.\n",
    "\n",
    "Cum aflam care este cel mai potrivit K?\n",
    "Daca folosim un K foarte mic vom face overfitting pe setul de antrenare si nu vom avea rezultate deloc bune pentru setul de testare. Daca folosim un K foarte mare nu vom obtine rezultate bune nici pe setul de antrenare, nici pe setul de intrare. Ce facem? Solutia este curba 'elbow curve'. Un K bun poate fi selectat prin diferite tehnici euristice (ex: optimizarea hiperparametrului). \n",
    "\n",
    "<img src=\"resources/image6.png\" width=\"550\">\n",
    "\n",
    "Un dezavantaj al clasificării de bază a „votului majoritar” apare atunci când exemple dintr-o clasă mai frecventă tind să domine predicția noului exemplu, deoarece acestea tind să fie comune printre cei mai apropiați k din cauza numărului mare. O modalitate de a depăși această problemă este ponderea clasificării, ținând cont de distanța de la punctul de testare la fiecare dintre cei mai apropiați k vecini ai săi. Clasa (sau valoarea, în problemele de regresie) din fiecare dintre cele mai apropiate k puncte este înmulțită cu o greutate proporțională cu inversul distanței de la acel punct la punctul de testare. \n",
    "\n",
    "Precizia algoritmului KNN poate fi sever degradată prin prezența unor caracteristici zgomotoase sau irelevante sau dacă scările de caracteristici nu sunt în concordanță cu importanța lor. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bibliografie:\n",
    "\n",
    "1. https://www.saedsayad.com/k_nearest_neighbors_reg.htm\n",
    "2. https://medium.com/analytics-vidhya/k-neighbors-regression-analysis-in-python-61532d56d8e4\n",
    "3. https://scikit-learn.org/stable/modules/neighbors.html#regression\n",
    "4. https://www.analyticsvidhya.com/blog/2018/08/k-nearest-neighbor-introduction-regression-python/\n",
    "5. https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "notify_time": "5",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
