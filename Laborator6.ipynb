{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = Magenta> _Lixandru Andreea-Bianca 382\n",
    " <br>   Pepene Adina-Florentina 382_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laborator 6\n",
    "\n",
    "Versiunea 2020-04-01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modele de clasificare\n",
    "\n",
    "Folositi 4 seturi de date pentru probleme de clasificare, plecand de la repository-urile specificate in Cursul 5; de exemplu, [ics.uci.edu](http://archive.ics.uci.edu/ml/datasets.php?format=mat&task=cla&att=&area=&numAtt=&numIns=&type=mvar&sort=nameUp&view=table). Cel putin doua seturi de date sa fie cu valori lipsa. \n",
    "\n",
    "\n",
    "1. (20 puncte) Aplicati o metoda de missing value imputation, unde este cazul; justificati si documentati metoda folosita.\n",
    "1. (numar de modele * numar de seturi de date \\* 1 punct = 20 de puncte) Pentru fiecare set de date aplicati 5 modele de clasificare din scikit learn. Pentru fiecare raportati: acuratete, scorul F1 - a se vedea [sklearn.metrics](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics) - folosind 5 fold cross validation. Raportati mediile rezultatelor atat pentru fold-urile de antrenare, cat si pentru cele de testare. Rularile se vor face cu valori fixate ale hiperparametrilor. \n",
    "1. (numar modele * 4 puncte = 20 puncte) Documentati in jupyter notebook fiecare din modelele folosite, in limba romana. Daca acelasi algoritm e folosit pentru mai multe seturi de date, puteti face o sectiune separata cu documentarea algoritmilor + trimitere la algoritm. \n",
    "1. (numar de modele * numar de seturi de date * 1 punct = 20 de puncte) Raportati performanta fiecarui model, folosind 5 fold cross validation. Pentru fiecare din cele 5 rulari, cautati hiperparametrii optimi folosind 4-fold cross validation. Performanta modelului va fi raportata ca medie a celor  5 rulari. \n",
    "    *Observatie:* la fiecare din cele 5 rulari, hiperparametrii optimi pot diferi, din cauza datelor utilizate pentru antrenare/validare.  \n",
    "\n",
    "Se acorda 20 de puncte din oficiu. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exemple de modele de clasificare:\n",
    "1. [Multi-layer Perceptron classifier](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier)\n",
    "1. [KNN](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier)\n",
    "1. [SVM](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC)\n",
    "1. [Gaussian processes](https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.GaussianProcessClassifier.html#sklearn.gaussian_process.GaussianProcessClassifier)\n",
    "1. [RBF](https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.kernels.RBF.html#sklearn.gaussian_process.kernels.RBF)\n",
    "1. [Decision tree](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier)\n",
    "1. [Random forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier)\n",
    "1. [Gaussian Naive bayes](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html#sklearn.naive_bayes.GaussianNB) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Predare:* \n",
    "1. Fiecare student va depune pe site-ul de elearning fisier Jupyter notebook sau arhiva cu astfel de fisiere; \n",
    "1. In fiecare fisier se specifica numele celor doi studenti care au lucra in echipa. \n",
    "1. Predarea se face in saptamana 13-17 aprilie 2020\n",
    "1. Revedeti formele ulterioare ale acestui document pentru precizari despre: continutul rezultatelor raportate, modalitate de notare."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color= Magenta> Rezolvare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Citim seturile de date si ne uitam care dintre ele au valori lipsa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_yeast = [\"mcg\", \"gvh\",\"alm\",\"mit\",\"erl\",\"pox\",\"vac\",\"nuc\",\"class\"]\n",
    "\n",
    "df_yeast = pd.read_csv('./data/yeast/yeast.data',sep=r\" +\", engine=\"python\", names=names_yeast)\n",
    "\n",
    "df_yeast.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yeast.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wine = pd.read_csv('./data/wine/winequality-red.csv', sep=';')\n",
    "\n",
    "df_wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wine.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_breast_cancer = [\"class\",\"age\",\"menopause\",\"tumor-size\",\"inv-nodes\",\"node-caps\",\"deg-malig\",\n",
    "                       \"breast\",\"breast-quad\",\"irradiat\"]\n",
    "\n",
    "df_breast_cancer = pd.read_csv('./data/breast_cancer/breast-cancer.data', names=names_breast_cancer)\n",
    "\n",
    "df_breast_cancer['class'] = df_breast_cancer['class'].map({'recurrence-events': 1, 'no-recurrence-events': 0})\n",
    "\n",
    "df_breast_cancer['age'] = df_breast_cancer['age'].map({'10-19': 1, '20-29': 2, '30-39': 3,\n",
    "                                                       '40-49': 4, '50-59': 5, '60-69': 6,\n",
    "                                                       '70-79': 7, '80-89': 8, '90-99': 9})\n",
    "\n",
    "df_breast_cancer['menopause'] = df_breast_cancer['menopause'].map({'premeno' : 1,'lt40' : 2, 'ge40' : 3})\n",
    "\n",
    "df_breast_cancer['tumor-size'] = df_breast_cancer['tumor-size'].map({'0-4': 0, '5-9': 5, '10-14': 10, '15-19': 15, \n",
    "                                                                   '20-24': 20, '25-29': 25, '30-34': 30, '35-39': 35, \n",
    "                                                                   '40-44': 40, '45-49': 45, '50-54': 50, '55-59': 55})\n",
    "\n",
    "df_breast_cancer['inv-nodes'] = df_breast_cancer['inv-nodes'].map({'0-2':0, '3-5':3, '6-8':6, '9-11':9, '12-14':12, \n",
    "                                                                   '15-17':15,'18-20':18, '21-23':21, '24-26':24, \n",
    "                                                                   '27-29':27, '30-32':30, '33-35':33, '36-39':36})\n",
    "\n",
    "df_breast_cancer['node-caps'] = df_breast_cancer['node-caps'].map({'no': 0, 'yes': 1})\n",
    "\n",
    "df_breast_cancer['breast'] = df_breast_cancer['breast'].map({'left': 0, 'right': 1})\n",
    "\n",
    "df_breast_cancer['breast-quad'] = df_breast_cancer['breast-quad'].map({'left_up': 1, 'left_low': 2, 'right_up': 3,\n",
    "                                                                       'right_low': 4, 'central': 5})\n",
    "\n",
    "df_breast_cancer['irradiat'] = df_breast_cancer['irradiat'].map({'no': 0, 'yes': 1})\n",
    "\n",
    "df_breast_cancer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''In data set-ul breast_cancer missing values sunt marcate prin '?',\n",
    "nu prin valori NaN, asa ca dorim sa inlocuim  valorile '?' cu valori\n",
    "NaN astfel incat sa putem vedea cre sunt valorile necompletate si\n",
    "sa le putem inlocui sau sterge.'''\n",
    "\n",
    "df_breast_cancer = df_breast_cancer.replace('?', np.nan)\n",
    "df_breast_cancer.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_primary_tumor =[\"class\",\"age\",\"sex\",\"histologic-type\",\"degree-of-diffe\",\"bone\",\"bone-marrow\",\"lung\",\n",
    "                     \"pleura\",\"peritoneum\",\"liver\",\"brain\",\"skin\",\"neck\",\"supraclavicular\",\"axillar\",\"mediastinum\",\"abdomnial\"]\n",
    "\n",
    "df_primary_tumor = pd.read_csv(\"./data/primary_tumor/primary-tumor.data\", names=names_primary_tumor)\n",
    "\n",
    "df_primary_tumor.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_primary_tumor = df_primary_tumor.replace('?', np.nan)\n",
    "\n",
    "df_primary_tumor.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>Ex1:</font> Aplicati o metoda de missing value imputation, unde este cazul; justificati si documentati metoda folosita.\n",
    "<br>\n",
    "><br>Metode posibile:\n",
    "<br>1. Eliminarea liniilor care contin valori nan.\n",
    "<br>2. Eliminarea coloanelor care contin nan.\n",
    "<br>3. Umplerea valorilor nan cu:\n",
    "> -> o valoare constanta\n",
    "><br>-> copierea ultimei valori cunoscute(ffill)\n",
    "><br>-> umplere 'inapoi'(bfill)\n",
    "><br>-> o valoare calculata (ex: media)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Pentru dataset-ul breast_cancer am ales sa umplem valorile nan\n",
    "prin copierea ultimei valori cunoscute, intrucat am dori sa pastram\n",
    "cat mai multe din liniile si coloanele data set-ului nostru.\n",
    "Pe coloanele care lipsesc valori nu exista o varietate mare de valori,\n",
    "deci putem folosi ultima valoare cunoscuta. Setul de date este aproape\n",
    "complet si nu necesita multe adaugari.'''\n",
    "\n",
    "df_breast_cancer = df_breast_cancer.fillna(method='ffill')\n",
    "\n",
    "df_breast_cancer.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Pentru dataset-ul primary_tumor am ales sa umplem valorile lipsa\n",
    "cu media de pe coloana, intrucat am observat ca lipsesc multe valori \n",
    "de pe aceeasi coloana, deci nu putem avea o evidenta clara asupra\n",
    "datelor anterioare. Totusi, nu putem decide inca daca renuntam\n",
    "la coloana digree-of-diffe. Ramane de vazut...'''\n",
    "\n",
    "df_primary_tumor = df_primary_tumor.apply(lambda x: pd.to_numeric(x), axis=0)\n",
    "\n",
    "df_primary_tumor = df_primary_tumor.fillna(round(df_primary_tumor.mean()))\n",
    "\n",
    "df_primary_tumor.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>Ex2:</font> Pentru fiecare set de date aplicati 5 modele de clasificare din scikit learn. Pentru fiecare raportati: acuratete, scorul F1 - a se vedea sklearn.metrics - folosind 5 fold cross validation. Raportati mediile rezultatelor atat pentru fold-urile de antrenare, cat si pentru cele de testare. Rularile se vor face cu valori fixate ale hiperparametrilor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trebuie sa separam datele in date de intrare si date de iesire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_yeast = df_yeast[[\"mcg\", \"gvh\", \"alm\", \"mit\", \"erl\", \"pox\", \"vac\",\"nuc\"]].to_numpy()\n",
    "y_yeast = df_yeast[\"class\"].to_numpy()\n",
    "\n",
    "print(\"X_yeast\", x_yeast[:20, :])\n",
    "print(\"Y_yeast\", y_yeast[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_wine = df_wine [[\"fixed acidity\", \"volatile acidity\", \"citric acid\", \"residual sugar\", \"chlorides\", \n",
    "                   \"free sulfur dioxide\", \"total sulfur dioxide\", \"density\", \"pH\", \"sulphates\", \"alcohol\"]].to_numpy()\n",
    "y_wine = df_wine[\"quality\"].to_numpy()\n",
    "\n",
    "print(\"X_wine\", x_wine[:20, :])\n",
    "print(\"Y_wine\", y_wine[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_breast_cancer = df_breast_cancer[[\"age\", \"menopause\", \"tumor-size\", \"inv-nodes\", \"node-caps\", \"deg-malig\", \"breast\", \n",
    "                                    \"breast-quad\", \"irradiat\"]].to_numpy()\n",
    "y_breast_cancer = df_breast_cancer[\"class\"].to_numpy()\n",
    "\n",
    "print(\"X_breast_cancer\", x_breast_cancer[:20, :])\n",
    "print(\"Y_breast_cancer\", y_breast_cancer[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_primary_tumor = df_primary_tumor[[\"age\", \"sex\", \"histologic-type\", \"degree-of-diffe\", \"bone\", \"bone-marrow\", \"lung\",\n",
    "                     \"pleura\", \"peritoneum\", \"liver\", \"brain\", \"skin\", \"neck\", \"supraclavicular\", \"axillar\", \n",
    "                    \"mediastinum\", \"abdomnial\"]].to_numpy()\n",
    "y_primary_tumor = df_primary_tumor[\"class\"].to_numpy()\n",
    "\n",
    "print(\"X_primary_tumor\", x_primary_tumor[:20, :])\n",
    "print(\"Y_primary_tumor\", y_primary_tumor[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separam setul de date in set de antrenare si set de testare.\n",
    "<br> Cand folosim random state facem un random mai stabil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_balanced_data_set(y_train, y_test) -> None:\n",
    "    print(Counter(y_train))\n",
    "    print(Counter(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color= magenta> Yeast dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_yeast, X_test_yeast, y_train_yeast, y_test_yeast = train_test_split(x_yeast,\n",
    "                                                                            y_yeast, \n",
    "                                                                            test_size=1/3,\n",
    "                                                                            shuffle=True,\n",
    "                                                                            random_state=10)\n",
    "\n",
    "print(y_train_yeast[:20])\n",
    "print(y_test_yeast[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color= magenta> Wine dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_wine, X_test_wine, y_train_wine, y_test_wine = train_test_split(x_wine,\n",
    "                                                                        y_wine, \n",
    "                                                                        test_size=1/3,\n",
    "                                                                        shuffle=True,\n",
    "                                                                        random_state=10)\n",
    "\n",
    "print(y_train_wine[:20])\n",
    "print(y_test_wine[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color= magenta> Breast cancer dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_breast_cancer, X_test_breast_cancer, y_train_breast_cancer, y_test_breast_cancer = train_test_split(x_breast_cancer,\n",
    "                                                                                                            y_breast_cancer, \n",
    "                                                                                                            test_size=1/3,\n",
    "                                                                                                            shuffle=True,\n",
    "                                                                                                            random_state=10)\n",
    "\n",
    "print(y_train_breast_cancer[:20])\n",
    "print(y_test_breast_cancer[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color= magenta> Primary tumor dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_primary_tumor, X_test_primary_tumor, y_train_primary_tumor, y_test_primary_tumor = train_test_split(x_primary_tumor,\n",
    "                                                                                                            y_primary_tumor, \n",
    "                                                                                                            test_size=1/3,\n",
    "                                                                                                            shuffle=True,\n",
    "                                                                                                            random_state=10)\n",
    "\n",
    "print(y_train_primary_tumor[:20])\n",
    "print(y_test_primary_tumor[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_balanced_data_set(y_train_yeast, y_test_yeast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_balanced_data_set(y_train_wine, y_test_wine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_balanced_data_set(y_train_breast_cancer, y_test_breast_cancer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_balanced_data_set(y_train_primary_tumor, y_test_primary_tumor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=magenta> 1. KNeighbourClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_neighbours_method(X_train, y_train, X_test, y_test, number_of_neighbors) -> None:\n",
    "    model = KNeighborsClassifier(n_neighbors = number_of_neighbors)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_predicated_train = model.predict(X_train)\n",
    "    y_predicated_test = model.predict(X_test)\n",
    "    \n",
    "    print (\"Train score:\", model.score(X_train, y_train)*100)\n",
    "    print (\"Test score:\", model.score(X_test, y_test)*100)\n",
    "    print (\"Different outputs train:\", sum(y_predicated_train != y_train), \"from total of\", len(y_train))\n",
    "    print (\"Different outputs test:\", sum(y_predicated_test != y_test), \"from total of\", len(y_test))\n",
    "    print (\"Accuracy train:\", metrics.accuracy_score(y_train, y_predicated_train)*100)\n",
    "    # average='micro' Calculate metrics globally by counting the total true positives, false negatives and false positives.\n",
    "    print (\"F1-score train:\", metrics.f1_score(y_train, y_predicated_train, average='micro')*100)\n",
    "    print (\"Accuracy test:\", metrics.accuracy_score(y_test, y_predicated_test)*100)\n",
    "    print (\"F1-score test:\", metrics.f1_score(y_test, y_predicated_test, average='micro')*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_neighbours_method(X_train_yeast, y_train_yeast, X_test_yeast, y_test_yeast, 59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_neighbours_method(X_train_wine, y_train_wine, X_test_wine, y_test_wine, 73)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_neighbours_method(X_train_breast_cancer, y_train_breast_cancer, X_test_breast_cancer, y_test_breast_cancer, 23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_neighbours_method(X_train_primary_tumor, y_train_primary_tumor, X_test_primary_tumor, y_test_primary_tumor, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=Magenta> 2. MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_method(X_train, y_train, X_test, y_test, activ) -> None:\n",
    "    #‘sgd’ refers to stochastic gradient descent.\n",
    "    model =  MLPClassifier(activation = activ, random_state = 10)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_predicated_train = model.predict(X_train)\n",
    "    y_predicated_test = model.predict(X_test)\n",
    "    \n",
    "    print (\"Train score:\", model.score(X_train, y_train)*100)\n",
    "    print (\"Test score:\", model.score(X_test, y_test)*100)\n",
    "    print (\"Different outputs train:\", sum(y_predicated_train != y_train), \"from total of\", len(y_train))\n",
    "    print (\"Different outputs test:\", sum(y_predicated_test != y_test), \"from total of\", len(y_test))\n",
    "    print (\"Accuracy train:\", metrics.accuracy_score(y_train, y_predicated_train)*100)\n",
    "    # average='micro' Calculate metrics globally by counting the total true positives, false negatives and false positives.\n",
    "    print (\"F1-score train:\", metrics.f1_score(y_train, y_predicated_train, average='micro')*100)\n",
    "    print (\"Accuracy test:\", metrics.accuracy_score(y_test, y_predicated_test)*100)\n",
    "    print (\"F1-score test:\", metrics.f1_score(y_test, y_predicated_test, average='micro')*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_method(X_train_yeast, y_train_yeast, X_test_yeast, y_test_yeast, 'tanh')\n",
    "\n",
    "# Train score: 59.45399393326593 #solver='adam'\n",
    "# Test score: 61.41414141414141\n",
    "# Different outputs train: 401 from total of 989\n",
    "# Different outputs test: 191 from total of 495\n",
    "\n",
    "# Train score: 62.588473205257834 #solver='lbfgs'\n",
    "# Test score: 61.41414141414141\n",
    "# Different outputs train: 370 from total of 989\n",
    "# Different outputs test: 191 from total of 495"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mlp_method(X_train_wine, y_train_wine, X_test_wine, y_test_wine, 'tanh')\n",
    "\n",
    "# Train score: 62.7579737335835 #solver='adam'\n",
    "# Test score: 53.09568480300187\n",
    "# Different outputs train: 397 from total of 1066\n",
    "# Different outputs test: 250 from total of 533\n",
    "\n",
    "# Train score: 65.94746716697935 #solver='lbfgs'\n",
    "# Test score: 54.971857410881796\n",
    "# Different outputs train: 363 from total of 1066\n",
    "# Different outputs test: 240 from total of 533"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_method(X_train_breast_cancer, y_train_breast_cancer, X_test_breast_cancer, y_test_breast_cancer, 'relu')\n",
    "\n",
    "# Train score: 78.94736842105263 #solver='adam'\n",
    "# Test score: 73.95833333333334\n",
    "# Different outputs train: 40 from total of 190\n",
    "# Different outputs test: 25 from total of 96\n",
    "\n",
    "# Train score: 78.94736842105263 #solver='lbfgs'\n",
    "# Test score: 68.75\n",
    "# Different outputs train: 40 from total of 190\n",
    "# Different outputs test: 30 from total of 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_method(X_train_primary_tumor, y_train_primary_tumor, X_test_primary_tumor, y_test_primary_tumor, 'identity')\n",
    "\n",
    "# Train score: 56.19469026548673 #solver='adam'\n",
    "# Test score: 42.47787610619469\n",
    "# Different outputs train: 99 from total of 226\n",
    "# Different outputs test: 65 from total of 113\n",
    "\n",
    "# Train score: 66.3716814159292 #solver='lbfgs'\n",
    "# Test score: 38.93805309734513\n",
    "# Different outputs train: 76 from total of 226\n",
    "# Different outputs test: 69 from total of 113"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=Magenta> 3. SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svc_method(X_train, y_train, X_test, y_test) -> None:\n",
    "    model = SVC(class_weight=None, random_state = 10)\n",
    "    model.fit(X_train,y_train)\n",
    "    \n",
    "    y_predicated_train = model.predict(X_train)\n",
    "    y_predicated_test = model.predict(X_test)\n",
    "    \n",
    "    print (\"Train score:\", model.score(X_train, y_train)*100)\n",
    "    print (\"Test score:\", model.score(X_test, y_test)*100)\n",
    "    print (\"Different outputs train:\", sum(y_predicated_train != y_train), \"from total of\", len(y_train))\n",
    "    print (\"Different outputs test:\", sum(y_predicated_test != y_test), \"from total of\", len(y_test))\n",
    "    print (\"Accuracy train:\", metrics.accuracy_score(y_train, y_predicated_train)*100)\n",
    "    # average='micro' Calculate metrics globally by counting the total true positives, false negatives and false positives.\n",
    "    print (\"F1-score train:\", metrics.f1_score(y_train, y_predicated_train, average='micro')*100)\n",
    "    print (\"Accuracy test:\", metrics.accuracy_score(y_test, y_predicated_test)*100)\n",
    "    print (\"F1-score test:\", metrics.f1_score(y_test, y_predicated_test, average='micro')*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_method(X_train_yeast, y_train_yeast, X_test_yeast, y_test_yeast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_method(X_train_wine, y_train_wine, X_test_wine, y_test_wine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_method(X_train_breast_cancer, y_train_breast_cancer, X_test_breast_cancer, y_test_breast_cancer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_method(X_train_primary_tumor, y_train_primary_tumor, X_test_primary_tumor, y_test_primary_tumor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color = magenta> 4. GaussianProcessClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_method(X_train, y_train, X_test, y_test) -> None:\n",
    "    model = GaussianProcessClassifier(random_state = 10)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_predicated_train = model.predict(X_train)\n",
    "    y_predicated_test = model.predict(X_test)\n",
    "    \n",
    "    print (\"Train score:\", model.score(X_train, y_train)*100)\n",
    "    print (\"Test score:\", model.score(X_test, y_test)*100)\n",
    "    print (\"Different outputs train:\", sum(y_predicated_train != y_train), \"from total of\", len(y_train))\n",
    "    print (\"Different outputs test:\", sum(y_predicated_test != y_test), \"from total of\", len(y_test))\n",
    "    print (\"Accuracy train:\", metrics.accuracy_score(y_train, y_predicated_train)*100)\n",
    "    # average='micro' Calculate metrics globally by counting the total true positives, false negatives and false positives.\n",
    "    print (\"F1-score train:\", metrics.f1_score(y_train, y_predicated_train, average='micro')*100)\n",
    "    print (\"Accuracy test:\", metrics.accuracy_score(y_test, y_predicated_test)*100)\n",
    "    print (\"F1-score test:\", metrics.f1_score(y_test, y_predicated_test, average='micro')*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_method(X_train_yeast, y_train_yeast, X_test_yeast, y_test_yeast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_method(X_train_wine, y_train_wine, X_test_wine, y_test_wine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_method(X_train_breast_cancer, y_train_breast_cancer, X_test_breast_cancer, y_test_breast_cancer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_method(X_train_primary_tumor, y_train_primary_tumor, X_test_primary_tumor, y_test_primary_tumor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=magenta> 5. GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_nb_method(X_train, y_train, X_test, y_test) -> None:\n",
    "    model = GaussianNB()\n",
    "    model.fit(X_train, y_train)\n",
    "      \n",
    "    y_predicated_train = model.predict(X_train)\n",
    "    y_predicated_test = model.predict(X_test)\n",
    "    \n",
    "    print (\"Train score:\", model.score(X_train, y_train)*100)\n",
    "    print (\"Test score:\", model.score(X_test, y_test)*100)\n",
    "    print (\"Different outputs train:\", sum(y_predicated_train != y_train), \"from total of\", len(y_train))\n",
    "    print (\"Different outputs test:\", sum(y_predicated_test != y_test), \"from total of\", len(y_test))\n",
    "    print (\"Accuracy train:\", metrics.accuracy_score(y_train, y_predicated_train)*100)\n",
    "    # average='micro' Calculate metrics globally by counting the total true positives, false negatives and false positives.\n",
    "    print (\"F1-score train:\", metrics.f1_score(y_train, y_predicated_train, average='micro')*100)\n",
    "    print (\"Accuracy test:\", metrics.accuracy_score(y_test, y_predicated_test)*100)\n",
    "    print (\"F1-score test:\", metrics.f1_score(y_test, y_predicated_test, average='micro')*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_nb_method(X_train_yeast, y_train_yeast, X_test_yeast, y_test_yeast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_nb_method(X_train_wine, y_train_wine, X_test_wine, y_test_wine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_nb_method(X_train_breast_cancer, y_train_breast_cancer, X_test_breast_cancer, y_test_breast_cancer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_nb_method(X_train_primary_tumor, y_train_primary_tumor, X_test_primary_tumor, y_test_primary_tumor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color= magenta> 6. DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree_method(X_train, y_train, X_test, y_test) -> None:\n",
    "    model = DecisionTreeClassifier(max_depth=5, min_samples_leaf=15)\n",
    "    model.fit(X_train, y_train)\n",
    "       \n",
    "    y_predicated_train = model.predict(X_train)\n",
    "    y_predicated_test = model.predict(X_test)\n",
    "    \n",
    "    print (\"Train score:\", model.score(X_train, y_train)*100)\n",
    "    print (\"Test score:\", model.score(X_test, y_test)*100)\n",
    "    print (\"Different outputs train:\", sum(y_predicated_train != y_train), \"from total of\", len(y_train))\n",
    "    print (\"Different outputs test:\", sum(y_predicated_test != y_test), \"from total of\", len(y_test))\n",
    "    print (\"Accuracy train:\", metrics.accuracy_score(y_train, y_predicated_train)*100)\n",
    "    # average='micro' Calculate metrics globally by counting the total true positives, false negatives and false positives.\n",
    "    print (\"F1-score train:\", metrics.f1_score(y_train, y_predicated_train, average='micro')*100)\n",
    "    print (\"Accuracy test:\", metrics.accuracy_score(y_test, y_predicated_test)*100)\n",
    "    print (\"F1-score test:\", metrics.f1_score(y_test, y_predicated_test, average='micro')*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_method(X_train_yeast, y_train_yeast, X_test_yeast, y_test_yeast)\n",
    "#aici avem sigur overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_method(X_train_wine, y_train_wine, X_test_wine, y_test_wine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_method(X_train_breast_cancer, y_train_breast_cancer, X_test_breast_cancer, y_test_breast_cancer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_method(X_train_primary_tumor, y_train_primary_tumor, X_test_primary_tumor, y_test_primary_tumor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color= magenta> 7. RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_method(X_train, y_train, X_test, y_test, max_depth, min_samples_leaf) -> None:\n",
    "    model = RandomForestClassifier(max_depth=max_depth, min_samples_leaf=min_samples_leaf)\n",
    "    model.fit(X_train, y_train)\n",
    "       \n",
    "    y_predicated_train = model.predict(X_train)\n",
    "    y_predicated_test = model.predict(X_test)\n",
    "    \n",
    "    print (\"Train score:\", model.score(X_train, y_train)*100)\n",
    "    print (\"Test score:\", model.score(X_test, y_test)*100)\n",
    "    print (\"Different outputs train:\", sum(y_predicated_train != y_train), \"from total of\", len(y_train))\n",
    "    print (\"Different outputs test:\", sum(y_predicated_test != y_test), \"from total of\", len(y_test))\n",
    "    print (\"Accuracy train:\", metrics.accuracy_score(y_train, y_predicated_train)*100)\n",
    "    # average='micro' Calculate metrics globally by counting the total true positives, false negatives and false positives.\n",
    "    print (\"F1-score train:\", metrics.f1_score(y_train, y_predicated_train, average='micro')*100)\n",
    "    print (\"Accuracy test:\", metrics.accuracy_score(y_test, y_predicated_test)*100)\n",
    "    print (\"F1-score test:\", metrics.f1_score(y_test, y_predicated_test, average='micro')*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_method(X_train_yeast, y_train_yeast, X_test_yeast, y_test_yeast, 4, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_method(X_train_wine, y_train_wine, X_test_wine, y_test_wine, 3, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_method(X_train_breast_cancer, y_train_breast_cancer, X_test_breast_cancer, y_test_breast_cancer, 5, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_method(X_train_primary_tumor, y_train_primary_tumor, X_test_primary_tumor, y_test_primary_tumor, 5, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yeast 55\n",
    "<br>Wine Red ?\n",
    "<br>Breast Cancer 75\n",
    "<br>Primary tumor 48"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>Ex3:</font> Documentati in jupyter notebook fiecare din modelele folosite, in limba romana. Daca acelasi algoritm e folosit pentru mai multe seturi de date, puteti face o sectiune separata cu documentarea algoritmilor + trimitere la algoritm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GaussianNB\n",
    "<br>\n",
    "<br>\n",
    "<br>Acest tip de clasificare este foarte simplu, de aceea pentru seturile noastre de date obtinem un rezultat bun pentru setul de date breast_cancer, intrucat acesta se imparte in doua clase(no-recurrence-events si recurrence-events).\n",
    "<br>Pentru celelalte seturi de date rezultatul este evident, intrucat celelalte seturi de date au in jur de 10 clase.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Decision Tree Classifier\n",
    "<br>\n",
    "<br>\n",
    "<br>Aceasta metoda poate clasifica atat doua clase cat si mai multe clase intr-un dataset.\n",
    "<br>\n",
    "<br>Parametri:\n",
    "<br>splitter-> reprezinta strategia aleasa pentru divizarea nodurilor\n",
    "<br>max_depth-> reprezinta adancimea arborelui\n",
    "<br>min_samples_split-> nr minim de sample-uri necesare \n",
    "<br>min_samples_leaf-> nr minim de sample-uri necesare ca un nod sa fie frunza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier\n",
    "<br>\n",
    "<br>\n",
    "<br>Aceasta metoda foloseste o padure de arbori de decizie random.\n",
    "<br>Are ca scop controlul fenomenului de overfitting.\n",
    "<br>\n",
    "<br>Parametri:\n",
    "<br>n_estimators-> nr de arbori din padure\n",
    "<br>max_depth-> adancimea arborelui \n",
    "<br>min_samples_split-> nr de sample-uri necesare unui nod pentru a se face split\n",
    "<br>min_samples_leaf-> nr minim de sample-uri necesare ca un nod sa fie frunza\n",
    "<br>si altele\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>Observatii:\n",
    "<br>n_estimators-> nu produce overfitting daca crestem nr de arbori \n",
    "<br>max_features-> cu cat e mai mic cu atat evitam overfitting-ul, dar daca e prea mic reteaua face undefitting\n",
    "<br>max_depth-> are un rol important, reduce complexitatea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-layer Perceptron classifier\n",
    "<br>\n",
    "<br>\n",
    "<br>Acest model optimizează funcția log-loss folosind LBFGS sau descendență de gradient stocastic.\n",
    "<br>Această implementare funcționează cu date reprezentate ca tablouri numpy dense sau tablouri scipy slabe de valori în virgulă mobilă.\n",
    "<br>\n",
    "<br>Parametri:\n",
    "<br>hidden_layer_sizes ->  numărul de neuroni din stratul ascuns\n",
    "<br>activation -> funcție de activare\n",
    "<br>solver ->  pentru optimizarea ponderilor\n",
    "<br>alpha -> parametrul de penalizare L2\n",
    "<br>batch_size -> dimensiunea minibatches-urilor pentru optimizarea stocastica\n",
    "<br>learning_rate -> rata de învățare pentru actualizări de ponderi\n",
    "<br>learning_rate_init -> rata inițială de învățare\n",
    "<br>power_t -> exponent pentru scalare inversă a ratei de învățare \n",
    "<br>max_iter -> numărul maxim de iterații\n",
    "<br>shuffle -> amestecare de sample-uri la fiecare iterație\n",
    "<br>random_state -> generatorul de numere aleatorii\n",
    "<br>tol -> toleranță pentru optimizare\n",
    "<br>verbose -> printare mesaje de progres în stdout\n",
    "<br>warm_start -> reutilizați soluția apelului anterior\n",
    "<br>momentum -> momentum pentru actualizarea descendenței gradientului\n",
    "<br>nesterovs_momentum -> momentumul lui Nesterov\n",
    "<br>early_stopping -> va anula automat 10% din datele de instruire și va încheia antrenarea atunci când scorul de validare nu se îmbunătățește \n",
    "<br>validation_fraction -> proportia datelor de antrenare care vor fi rezervate ca set de validare\n",
    "<br>beta_1 -> rata de descompunere exponențială pentru estimările vectorului din primul moment\n",
    "<br>beta_2 -> rata de descompunere exponențială pentru estimările vectorului din al doilea moment\n",
    "<br>epsilon -> valoare pentru stabilitatea numerică\n",
    "<br>n_iter_no_change -> numărul maxim de epoci pentru a nu respecta îmbunătățirea dată de tol\n",
    "<br>max_fun -> numărul maxim de apeluri ale funcției de loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GaussianProcessClassifier\n",
    "<br>\n",
    "<br>\n",
    "<br>Este bazată pe aproximarea Laplace.\n",
    "<br>\n",
    "<br>Parametri:\n",
    "<br>kernel -> nucleul care specifică funcția de covarianță \n",
    "<br>optimizer -> optimizator intern acceptat pentru optimizarea parametrilor nucleului\n",
    "<br>n_restarts_optimizer -> numărul de reporniri ale optimizatorului pentru găsirea parametrilor kernel-ului\n",
    "<br>max_iter_predict -> numărul maxim de iterații din metoda lui Newton\n",
    "<br>warm_start -> soluția ultimei iterații Newton este utilizată ca inițializare pentru următorul apel\n",
    "<br>copy_X_train -> o copie persistentă a datelor de instruire \n",
    "<br>random_state -> generatorul de numere aleatorii \n",
    "<br>multi_class -> specifică modul în care sunt gestionate problemele de clasificare cu mai multe clase\n",
    "<br>n_jobs -> numărul de joburi utilizate pentru calcul"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNeighborsClassifier\n",
    "<br>\n",
    "<br>\n",
    "<br>Clasificatorul care implementează votul celor mai apropiați k vecini.\n",
    "<br>\n",
    "<br>Parametri:\n",
    "<br>n_neighbors -> numărul de vecini care vor fi folosiți\n",
    "<br>weights -> funcția de ponderi folosită în predicție\n",
    "<br>algorithm -> algoritmul folosit pentru calcularea vecinilor\n",
    "<br>leaf_size -> dimensiunea frunzelor pentru BallTree sau KDTree\n",
    "<br>p -> parametru de putere pentru metrica Minkowski\n",
    "<br>metric -> distanța utilizată pentru arbore\n",
    "<br>metric_params -> argumente suplimentare pentru funcția metrică\n",
    "<br>n_jobs -> numărul de joburi utilizate pentru calcul\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C-Support Vector Classification\n",
    "<br>\n",
    "<br>\n",
    "<br>Implementarea se bazează pe libsvm. \n",
    "<br>\n",
    "<br>Parametri:\n",
    "<br>C -> parametrul de regularizare\n",
    "<br>kernel -> nucleul care specifică funcția de covarianță \n",
    "<br>degree -> gradul funcției nucleului polinomial \n",
    "<br>gamma -> coeficientul de nucleu\n",
    "<br>coef0 -> termen independent în funcția de nucleu\n",
    "<br>shrinking -> folosește euristicul micșorat\n",
    "<br>probability -> estimări de probabilitate\n",
    "<br>tol -> toleranță pentru optimizare \n",
    "<br>cache_size -> specifică dimensiunea memoriei cache a nucleului\n",
    "<br>class_weight -> setați parametrul C al clasei i la clasa_pondere[i]*C pentru SVC\n",
    "<br>verbose -> printare mesaje de progres în stdout \n",
    "<br>max_iter -> numărul maxim de iterații\n",
    "<br>decision_function_shape -> returnează funcția de decizie 'ovr' sau 'ovo' în funcție de formă\n",
    "<br>break_ties -> prezicerea va rupe legăturile în funcție de valorile de încredere ale funcției de decizie\n",
    "<br>random_state -> generatorul de numere aleatorii "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>Ex4:</font>Pentru fiecare model: efectuati o cautare a hiperparametrilor optimi folosind grid search si random search (cu parametrul cv = 4), folosind 5 fold cross validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "notify_time": "5",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
