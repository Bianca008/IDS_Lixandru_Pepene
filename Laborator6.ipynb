{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = Magenta> _Lixandru Andreea-Bianca 382\n",
    " <br>   Pepene Adina-Florentina 382_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laborator 6\n",
    "\n",
    "Versiunea 2020-04-01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modele de clasificare\n",
    "\n",
    "Folositi 4 seturi de date pentru probleme de clasificare, plecand de la repository-urile specificate in Cursul 5; de exemplu, [ics.uci.edu](http://archive.ics.uci.edu/ml/datasets.php?format=mat&task=cla&att=&area=&numAtt=&numIns=&type=mvar&sort=nameUp&view=table). Cel putin doua seturi de date sa fie cu valori lipsa. \n",
    "\n",
    "\n",
    "1. (20 puncte) Aplicati o metoda de missing value imputation, unde este cazul; justificati si documentati metoda folosita.\n",
    "1. (numar de modele * numar de seturi de date \\* 1 punct = 20 de puncte) Pentru fiecare set de date aplicati 5 modele de clasificare din scikit learn. Pentru fiecare raportati: acuratete, scorul F1 - a se vedea [sklearn.metrics](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics) - folosind 5 fold cross validation. Raportati mediile rezultatelor atat pentru fold-urile de antrenare, cat si pentru cele de testare. Rularile se vor face cu valori fixate ale hiperparametrilor. \n",
    "1. (numar modele * 4 puncte = 20 puncte) Documentati in jupyter notebook fiecare din modelele folosite, in limba romana. Daca acelasi algoritm e folosit pentru mai multe seturi de date, puteti face o sectiune separata cu documentarea algoritmilor + trimitere la algoritm. \n",
    "1. (numar de modele * numar de seturi de date * 1 punct = 20 de puncte) Raportati performanta fiecarui model, folosind 5 fold cross validation. Pentru fiecare din cele 5 rulari, cautati hiperparametrii optimi folosind 4-fold cross validation. Performanta modelului va fi raportata ca medie a celor  5 rulari. \n",
    "    *Observatie:* la fiecare din cele 5 rulari, hiperparametrii optimi pot diferi, din cauza datelor utilizate pentru antrenare/validare.  \n",
    "\n",
    "Se acorda 20 de puncte din oficiu. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exemple de modele de clasificare:\n",
    "1. [Multi-layer Perceptron classifier](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier)\n",
    "1. [KNN](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier)\n",
    "1. [SVM](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC)\n",
    "1. [Gaussian processes](https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.GaussianProcessClassifier.html#sklearn.gaussian_process.GaussianProcessClassifier)\n",
    "1. [RBF](https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.kernels.RBF.html#sklearn.gaussian_process.kernels.RBF)\n",
    "1. [Decision tree](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier)\n",
    "1. [Random forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier)\n",
    "1. [Gaussian Naive bayes](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html#sklearn.naive_bayes.GaussianNB) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Predare:* \n",
    "1. Fiecare student va depune pe site-ul de elearning fisier Jupyter notebook sau arhiva cu astfel de fisiere; \n",
    "1. In fiecare fisier se specifica numele celor doi studenti care au lucra in echipa. \n",
    "1. Predarea se face in saptamana 13-17 aprilie 2020\n",
    "1. Revedeti formele ulterioare ale acestui document pentru precizari despre: continutul rezultatelor raportate, modalitate de notare."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color= Magenta> Rezolvare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>Ex1:</font> Aplicati o metoda de missing value imputation, unde este cazul; justificati si documentati metoda folosita.\n",
    "<br>\n",
    "><br>Metode posibile:\n",
    "<br>1. Eliminarea liniilor care contin valori nan.\n",
    "<br>2. Eliminarea coloanelor care contin nan.\n",
    "<br>3. Umplerea valorilor nan cu:\n",
    "> -> o valoare constanta\n",
    "><br>-> copierea ultimei valori cunoscute(ffill)\n",
    "><br>-> umplere 'inapoi'(bfill)\n",
    "><br>-> o valoare calculata (ex: media)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Citim seturile de date si ne uitam care dintre ele au valori lipsa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mcg</th>\n",
       "      <th>gvh</th>\n",
       "      <th>alm</th>\n",
       "      <th>mit</th>\n",
       "      <th>erl</th>\n",
       "      <th>pox</th>\n",
       "      <th>vac</th>\n",
       "      <th>nuc</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ADT1_YEAST</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.22</td>\n",
       "      <td>MIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADT2_YEAST</th>\n",
       "      <td>0.43</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.22</td>\n",
       "      <td>MIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADT3_YEAST</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.22</td>\n",
       "      <td>MIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAR2_YEAST</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.22</td>\n",
       "      <td>NUC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AATM_YEAST</th>\n",
       "      <td>0.42</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.22</td>\n",
       "      <td>MIT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             mcg   gvh   alm   mit  erl  pox   vac   nuc class\n",
       "ADT1_YEAST  0.58  0.61  0.47  0.13  0.5  0.0  0.48  0.22   MIT\n",
       "ADT2_YEAST  0.43  0.67  0.48  0.27  0.5  0.0  0.53  0.22   MIT\n",
       "ADT3_YEAST  0.64  0.62  0.49  0.15  0.5  0.0  0.53  0.22   MIT\n",
       "AAR2_YEAST  0.58  0.44  0.57  0.13  0.5  0.0  0.54  0.22   NUC\n",
       "AATM_YEAST  0.42  0.44  0.48  0.54  0.5  0.0  0.48  0.22   MIT"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_yeast = [\"mcg\", \"gvh\",\"alm\",\"mit\",\"erl\",\"pox\",\"vac\",\"nuc\",\"class\"]\n",
    "\n",
    "df_yeast = pd.read_csv('./data/yeast/yeast.data',sep=r\" +\", engine=\"python\", names=names_yeast)\n",
    "\n",
    "df_yeast.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1484 entries, ADT1_YEAST to G6PD_YEAST\n",
      "Data columns (total 9 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   mcg     1484 non-null   float64\n",
      " 1   gvh     1484 non-null   float64\n",
      " 2   alm     1484 non-null   float64\n",
      " 3   mit     1484 non-null   float64\n",
      " 4   erl     1484 non-null   float64\n",
      " 5   pox     1484 non-null   float64\n",
      " 6   vac     1484 non-null   float64\n",
      " 7   nuc     1484 non-null   float64\n",
      " 8   class   1484 non-null   object \n",
      "dtypes: float64(8), object(1)\n",
      "memory usage: 115.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df_yeast.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wine = pd.read_csv('./data/wine/winequality-red.csv', sep=';')\n",
    "\n",
    "df_wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1599 entries, 0 to 1598\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed acidity         1599 non-null   float64\n",
      " 1   volatile acidity      1599 non-null   float64\n",
      " 2   citric acid           1599 non-null   float64\n",
      " 3   residual sugar        1599 non-null   float64\n",
      " 4   chlorides             1599 non-null   float64\n",
      " 5   free sulfur dioxide   1599 non-null   float64\n",
      " 6   total sulfur dioxide  1599 non-null   float64\n",
      " 7   density               1599 non-null   float64\n",
      " 8   pH                    1599 non-null   float64\n",
      " 9   sulphates             1599 non-null   float64\n",
      " 10  alcohol               1599 non-null   float64\n",
      " 11  quality               1599 non-null   int64  \n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 150.0 KB\n"
     ]
    }
   ],
   "source": [
    "df_wine.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BI-RADS</th>\n",
       "      <th>Age</th>\n",
       "      <th>Shape</th>\n",
       "      <th>Margin</th>\n",
       "      <th>Density</th>\n",
       "      <th>Severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>67</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>58</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  BI-RADS Age Shape Margin Density  Severity\n",
       "0       5  67     3      5       3         1\n",
       "1       4  43     1      1       ?         1\n",
       "2       5  58     4      5       3         1\n",
       "3       4  28     1      1       3         0\n",
       "4       5  74     1      5       ?         1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_mammographics = [\"BI-RADS\",\"Age\",\"Shape\",\"Margin\",\"Density\",\"Severity\"]\n",
    "\n",
    "df_mammographics = pd.read_csv('./data/mammographic/mammographic_masses.data', names=names_mammographics)\n",
    "\n",
    "df_mammographics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 961 entries, 0 to 960\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   BI-RADS   959 non-null    object\n",
      " 1   Age       956 non-null    object\n",
      " 2   Shape     930 non-null    object\n",
      " 3   Margin    913 non-null    object\n",
      " 4   Density   885 non-null    object\n",
      " 5   Severity  961 non-null    int64 \n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 45.2+ KB\n"
     ]
    }
   ],
   "source": [
    "'''Valorile din data frame care lipsesc sunt marcate cu '?'.\n",
    "Ca sa putem vedea cate valori lipsesc trebuie sa inlocuim\n",
    "toate valorile '?' cu valoarea nan. '''\n",
    "\n",
    "df_mammographics = df_mammographics.replace('?', np.nan)\n",
    "df_mammographics.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 961 entries, 0 to 960\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   BI-RADS   961 non-null    object\n",
      " 1   Age       961 non-null    object\n",
      " 2   Shape     961 non-null    object\n",
      " 3   Margin    961 non-null    object\n",
      " 4   Density   961 non-null    object\n",
      " 5   Severity  961 non-null    int64 \n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 45.2+ KB\n"
     ]
    }
   ],
   "source": [
    "'''Exista mai multe metode prin care putem umple valorile lipsa \n",
    "am ales umplerea valorilor prin copierea ultimei valori cunoscute.'''\n",
    "\n",
    "df_mammographics = df_mammographics.fillna(method='ffill')\n",
    "\n",
    "df_mammographics.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BI-RADS</th>\n",
       "      <th>Age</th>\n",
       "      <th>Shape</th>\n",
       "      <th>Margin</th>\n",
       "      <th>Density</th>\n",
       "      <th>Severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>67</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>58</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  BI-RADS Age Shape Margin Density  Severity\n",
       "0       5  67     3      5       3         1\n",
       "1       4  43     1      1       3         1\n",
       "2       5  58     4      5       3         1\n",
       "3       4  28     1      1       3         0\n",
       "4       5  74     1      5       3         1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mammographics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BI-RADS</th>\n",
       "      <th>Age</th>\n",
       "      <th>Density</th>\n",
       "      <th>Severity</th>\n",
       "      <th>Shape_1</th>\n",
       "      <th>Shape_2</th>\n",
       "      <th>Shape_3</th>\n",
       "      <th>Shape_4</th>\n",
       "      <th>Margin_1</th>\n",
       "      <th>Margin_2</th>\n",
       "      <th>Margin_3</th>\n",
       "      <th>Margin_4</th>\n",
       "      <th>Margin_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>67</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>58</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>74</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  BI-RADS Age Density  Severity  Shape_1  Shape_2  Shape_3  Shape_4  Margin_1  \\\n",
       "0       5  67       3         1        0        0        1        0         0   \n",
       "1       4  43       3         1        1        0        0        0         1   \n",
       "2       5  58       3         1        0        0        0        1         0   \n",
       "3       4  28       3         0        1        0        0        0         1   \n",
       "4       5  74       3         1        1        0        0        0         0   \n",
       "\n",
       "   Margin_2  Margin_3  Margin_4  Margin_5  \n",
       "0         0         0         0         1  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         1  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mammographics = pd.get_dummies(df_mammographics, columns=[\"Shape\", \"Margin\"])\n",
    "\n",
    "df_mammographics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>age</th>\n",
       "      <th>menopause</th>\n",
       "      <th>tumor-size</th>\n",
       "      <th>inv-nodes</th>\n",
       "      <th>node-caps</th>\n",
       "      <th>deg-malig</th>\n",
       "      <th>breast</th>\n",
       "      <th>breast-quad</th>\n",
       "      <th>irradiat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no-recurrence-events</td>\n",
       "      <td>30-39</td>\n",
       "      <td>premeno</td>\n",
       "      <td>30-34</td>\n",
       "      <td>0-2</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "      <td>left</td>\n",
       "      <td>left_low</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no-recurrence-events</td>\n",
       "      <td>40-49</td>\n",
       "      <td>premeno</td>\n",
       "      <td>20-24</td>\n",
       "      <td>0-2</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>right</td>\n",
       "      <td>right_up</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no-recurrence-events</td>\n",
       "      <td>40-49</td>\n",
       "      <td>premeno</td>\n",
       "      <td>20-24</td>\n",
       "      <td>0-2</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>left</td>\n",
       "      <td>left_low</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no-recurrence-events</td>\n",
       "      <td>60-69</td>\n",
       "      <td>ge40</td>\n",
       "      <td>15-19</td>\n",
       "      <td>0-2</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>right</td>\n",
       "      <td>left_up</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no-recurrence-events</td>\n",
       "      <td>40-49</td>\n",
       "      <td>premeno</td>\n",
       "      <td>0-4</td>\n",
       "      <td>0-2</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>right</td>\n",
       "      <td>right_low</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  class    age menopause tumor-size inv-nodes node-caps  \\\n",
       "0  no-recurrence-events  30-39   premeno      30-34       0-2        no   \n",
       "1  no-recurrence-events  40-49   premeno      20-24       0-2        no   \n",
       "2  no-recurrence-events  40-49   premeno      20-24       0-2        no   \n",
       "3  no-recurrence-events  60-69      ge40      15-19       0-2        no   \n",
       "4  no-recurrence-events  40-49   premeno        0-4       0-2        no   \n",
       "\n",
       "   deg-malig breast breast-quad irradiat  \n",
       "0          3   left    left_low       no  \n",
       "1          2  right    right_up       no  \n",
       "2          2   left    left_low       no  \n",
       "3          2  right     left_up       no  \n",
       "4          2  right   right_low       no  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_breast_cancer = [\"class\",\"age\",\"menopause\",\"tumor-size\",\"inv-nodes\",\"node-caps\",\"deg-malig\",\n",
    "                       \"breast\",\"breast-quad\",\"irradiat\"]\n",
    "\n",
    "df_breast_cancer = pd.read_csv('./data/breast_cancer/breast-cancer.data', names=names_breast_cancer)\n",
    "\n",
    "df_breast_cancer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 286 entries, 0 to 285\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   class        286 non-null    object\n",
      " 1   age          286 non-null    object\n",
      " 2   menopause    286 non-null    object\n",
      " 3   tumor-size   286 non-null    object\n",
      " 4   inv-nodes    286 non-null    object\n",
      " 5   node-caps    278 non-null    object\n",
      " 6   deg-malig    286 non-null    int64 \n",
      " 7   breast       286 non-null    object\n",
      " 8   breast-quad  285 non-null    object\n",
      " 9   irradiat     286 non-null    object\n",
      "dtypes: int64(1), object(9)\n",
      "memory usage: 22.5+ KB\n"
     ]
    }
   ],
   "source": [
    "'''In data set-ul breast_cancer missing values sunt marcate prin '?',\n",
    "nu prin valori NaN, asa ca dorim sa inlocuim  valorile '?' cu valori\n",
    "NaN astfel incat sa putem vedea cre sunt valorile necompletate si\n",
    "sa le putem inlocui sau sterge.'''\n",
    "\n",
    "df_breast_cancer = df_breast_cancer.replace('?', np.nan)\n",
    "df_breast_cancer.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>histologic-type</th>\n",
       "      <th>degree-of-diffe</th>\n",
       "      <th>bone</th>\n",
       "      <th>bone-marrow</th>\n",
       "      <th>lung</th>\n",
       "      <th>pleura</th>\n",
       "      <th>peritoneum</th>\n",
       "      <th>liver</th>\n",
       "      <th>brain</th>\n",
       "      <th>skin</th>\n",
       "      <th>neck</th>\n",
       "      <th>supraclavicular</th>\n",
       "      <th>axillar</th>\n",
       "      <th>mediastinum</th>\n",
       "      <th>abdomnial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>?</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>?</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>?</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>?</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  age sex histologic-type degree-of-diffe  bone  bone-marrow  lung  \\\n",
       "0      1    1   1               ?               3     2            2     1   \n",
       "1      1    1   1               ?               3     2            2     2   \n",
       "2      1    1   2               2               3     1            2     2   \n",
       "3      1    1   2               ?               3     1            2     1   \n",
       "4      1    1   2               ?               3     1            2     1   \n",
       "\n",
       "   pleura  peritoneum  liver  brain skin  neck  supraclavicular axillar  \\\n",
       "0       2           2      2      2    2     2                2       2   \n",
       "1       2           2      1      2    2     2                1       2   \n",
       "2       2           2      2      2    2     2                2       2   \n",
       "3       1           2      2      2    2     2                2       2   \n",
       "4       1           2      2      2    2     2                2       2   \n",
       "\n",
       "   mediastinum  abdomnial  \n",
       "0            2          2  \n",
       "1            1          2  \n",
       "2            1          2  \n",
       "3            1          2  \n",
       "4            1          2  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_primary_tumor =[\"class\",\"age\",\"sex\",\"histologic-type\",\"degree-of-diffe\",\"bone\",\"bone-marrow\",\"lung\",\n",
    "                     \"pleura\",\"peritoneum\",\"liver\",\"brain\",\"skin\",\"neck\",\"supraclavicular\",\"axillar\",\"mediastinum\",\"abdomnial\"]\n",
    "\n",
    "df_primary_tumor = pd.read_csv(\"./data/primary_tumor/primary-tumor.data\", names=names_primary_tumor)\n",
    "\n",
    "df_primary_tumor.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 339 entries, 0 to 338\n",
      "Data columns (total 18 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   class            339 non-null    int64 \n",
      " 1   age              339 non-null    int64 \n",
      " 2   sex              338 non-null    object\n",
      " 3   histologic-type  272 non-null    object\n",
      " 4   degree-of-diffe  184 non-null    object\n",
      " 5   bone             339 non-null    int64 \n",
      " 6   bone-marrow      339 non-null    int64 \n",
      " 7   lung             339 non-null    int64 \n",
      " 8   pleura           339 non-null    int64 \n",
      " 9   peritoneum       339 non-null    int64 \n",
      " 10  liver            339 non-null    int64 \n",
      " 11  brain            339 non-null    int64 \n",
      " 12  skin             338 non-null    object\n",
      " 13  neck             339 non-null    int64 \n",
      " 14  supraclavicular  339 non-null    int64 \n",
      " 15  axillar          338 non-null    object\n",
      " 16  mediastinum      339 non-null    int64 \n",
      " 17  abdomnial        339 non-null    int64 \n",
      "dtypes: int64(13), object(5)\n",
      "memory usage: 47.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df_primary_tumor = df_primary_tumor.replace('?', np.nan)\n",
    "\n",
    "df_primary_tumor.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 286 entries, 0 to 285\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   class        286 non-null    object\n",
      " 1   age          286 non-null    object\n",
      " 2   menopause    286 non-null    object\n",
      " 3   tumor-size   286 non-null    object\n",
      " 4   inv-nodes    286 non-null    object\n",
      " 5   node-caps    286 non-null    object\n",
      " 6   deg-malig    286 non-null    int64 \n",
      " 7   breast       286 non-null    object\n",
      " 8   breast-quad  286 non-null    object\n",
      " 9   irradiat     286 non-null    object\n",
      "dtypes: int64(1), object(9)\n",
      "memory usage: 22.5+ KB\n"
     ]
    }
   ],
   "source": [
    "'''Pentru dataset-ul breast_cancer am ales sa umplem valorile nan\n",
    "prin copierea ultimei valori cunoscute, intrucat am dori sa pastram\n",
    "cat mai multe din liniile si coloanele data set-ului nostru.\n",
    "Pe coloanele care lipsesc valori nu exista o varietate mare de valori,\n",
    "deci putem folosi ultima valoare cunoscuta. Setul de date este aproape\n",
    "complet si nu necesita multe adaugari.'''\n",
    "\n",
    "df_breast_cancer = df_breast_cancer.fillna(method='ffill')\n",
    "\n",
    "df_breast_cancer.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>node-caps</th>\n",
       "      <th>breast</th>\n",
       "      <th>irradiat</th>\n",
       "      <th>age_20-29</th>\n",
       "      <th>age_30-39</th>\n",
       "      <th>age_40-49</th>\n",
       "      <th>age_50-59</th>\n",
       "      <th>age_60-69</th>\n",
       "      <th>age_70-79</th>\n",
       "      <th>...</th>\n",
       "      <th>inv-nodes_6-8</th>\n",
       "      <th>inv-nodes_9-11</th>\n",
       "      <th>deg-malig_1</th>\n",
       "      <th>deg-malig_2</th>\n",
       "      <th>deg-malig_3</th>\n",
       "      <th>breast-quad_central</th>\n",
       "      <th>breast-quad_left_low</th>\n",
       "      <th>breast-quad_left_up</th>\n",
       "      <th>breast-quad_right_low</th>\n",
       "      <th>breast-quad_right_up</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no-recurrence-events</td>\n",
       "      <td>no</td>\n",
       "      <td>left</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no-recurrence-events</td>\n",
       "      <td>no</td>\n",
       "      <td>right</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no-recurrence-events</td>\n",
       "      <td>no</td>\n",
       "      <td>left</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no-recurrence-events</td>\n",
       "      <td>no</td>\n",
       "      <td>right</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no-recurrence-events</td>\n",
       "      <td>no</td>\n",
       "      <td>right</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  class node-caps breast irradiat  age_20-29  age_30-39  \\\n",
       "0  no-recurrence-events        no   left       no          0          1   \n",
       "1  no-recurrence-events        no  right       no          0          0   \n",
       "2  no-recurrence-events        no   left       no          0          0   \n",
       "3  no-recurrence-events        no  right       no          0          0   \n",
       "4  no-recurrence-events        no  right       no          0          0   \n",
       "\n",
       "   age_40-49  age_50-59  age_60-69  age_70-79  ...  inv-nodes_6-8  \\\n",
       "0          0          0          0          0  ...              0   \n",
       "1          1          0          0          0  ...              0   \n",
       "2          1          0          0          0  ...              0   \n",
       "3          0          0          1          0  ...              0   \n",
       "4          1          0          0          0  ...              0   \n",
       "\n",
       "   inv-nodes_9-11  deg-malig_1  deg-malig_2  deg-malig_3  breast-quad_central  \\\n",
       "0               0            0            0            1                    0   \n",
       "1               0            0            1            0                    0   \n",
       "2               0            0            1            0                    0   \n",
       "3               0            0            1            0                    0   \n",
       "4               0            0            1            0                    0   \n",
       "\n",
       "   breast-quad_left_low  breast-quad_left_up  breast-quad_right_low  \\\n",
       "0                     1                    0                      0   \n",
       "1                     0                    0                      0   \n",
       "2                     1                    0                      0   \n",
       "3                     0                    1                      0   \n",
       "4                     0                    0                      1   \n",
       "\n",
       "   breast-quad_right_up  \n",
       "0                     0  \n",
       "1                     1  \n",
       "2                     0  \n",
       "3                     0  \n",
       "4                     0  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_breast_cancer_2 = pd.get_dummies(df_breast_cancer, columns=[\"age\", \"menopause\", \"tumor-size\", \"inv-nodes\", \"deg-malig\",\n",
    "                                                              \"breast-quad\"])\n",
    "\n",
    "df_breast_cancer_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 339 entries, 0 to 338\n",
      "Data columns (total 18 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   class            339 non-null    int64  \n",
      " 1   age              339 non-null    int64  \n",
      " 2   sex              339 non-null    float64\n",
      " 3   histologic-type  339 non-null    float64\n",
      " 4   degree-of-diffe  339 non-null    float64\n",
      " 5   bone             339 non-null    int64  \n",
      " 6   bone-marrow      339 non-null    int64  \n",
      " 7   lung             339 non-null    int64  \n",
      " 8   pleura           339 non-null    int64  \n",
      " 9   peritoneum       339 non-null    int64  \n",
      " 10  liver            339 non-null    int64  \n",
      " 11  brain            339 non-null    int64  \n",
      " 12  skin             339 non-null    float64\n",
      " 13  neck             339 non-null    int64  \n",
      " 14  supraclavicular  339 non-null    int64  \n",
      " 15  axillar          339 non-null    float64\n",
      " 16  mediastinum      339 non-null    int64  \n",
      " 17  abdomnial        339 non-null    int64  \n",
      "dtypes: float64(5), int64(13)\n",
      "memory usage: 47.8 KB\n"
     ]
    }
   ],
   "source": [
    "'''Pentru dataset-ul primary_tumor am ales sa umplem valorile lipsa\n",
    "cu media de pe coloana, intrucat am observat ca lipsesc multe valori \n",
    "de pe aceeasi coloana, deci nu putem avea o evidenta clara asupra\n",
    "datelor anterioare. Totusi, nu putem decide inca daca renuntam\n",
    "la coloana digree-of-diffe. Ramane de vazut...'''\n",
    "\n",
    "df_primary_tumor = df_primary_tumor.apply(lambda x: pd.to_numeric(x), axis=0)\n",
    "\n",
    "df_primary_tumor = df_primary_tumor.fillna(round(df_primary_tumor.mean()))\n",
    "\n",
    "df_primary_tumor.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>Ex2:</font> Pentru fiecare set de date aplicati 5 modele de clasificare din scikit learn. Pentru fiecare raportati: acuratete, scorul F1 - a se vedea sklearn.metrics - folosind 5 fold cross validation. Raportati mediile rezultatelor atat pentru fold-urile de antrenare, cat si pentru cele de testare. Rularile se vor face cu valori fixate ale hiperparametrilor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trebuie sa separam datele in date de intrare si date de iesire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_yeast [[0.58 0.61 0.47 0.13 0.5  0.   0.48 0.22]\n",
      " [0.43 0.67 0.48 0.27 0.5  0.   0.53 0.22]\n",
      " [0.64 0.62 0.49 0.15 0.5  0.   0.53 0.22]\n",
      " [0.58 0.44 0.57 0.13 0.5  0.   0.54 0.22]\n",
      " [0.42 0.44 0.48 0.54 0.5  0.   0.48 0.22]\n",
      " [0.51 0.4  0.56 0.17 0.5  0.5  0.49 0.22]\n",
      " [0.5  0.54 0.48 0.65 0.5  0.   0.53 0.22]\n",
      " [0.48 0.45 0.59 0.2  0.5  0.   0.58 0.34]\n",
      " [0.55 0.5  0.66 0.36 0.5  0.   0.49 0.22]\n",
      " [0.4  0.39 0.6  0.15 0.5  0.   0.58 0.3 ]\n",
      " [0.43 0.39 0.54 0.21 0.5  0.   0.53 0.27]\n",
      " [0.42 0.37 0.59 0.2  0.5  0.   0.52 0.29]\n",
      " [0.4  0.42 0.57 0.35 0.5  0.   0.53 0.25]\n",
      " [0.6  0.4  0.52 0.46 0.5  0.   0.53 0.22]\n",
      " [0.66 0.55 0.45 0.19 0.5  0.   0.46 0.22]\n",
      " [0.46 0.44 0.52 0.11 0.5  0.   0.5  0.22]\n",
      " [0.47 0.39 0.5  0.11 0.5  0.   0.49 0.4 ]\n",
      " [0.58 0.47 0.54 0.11 0.5  0.   0.51 0.26]\n",
      " [0.5  0.34 0.55 0.21 0.5  0.   0.49 0.22]\n",
      " [0.61 0.6  0.55 0.21 0.5  0.   0.5  0.25]]\n",
      "Y_yeast ['MIT' 'MIT' 'MIT' 'NUC' 'MIT' 'CYT' 'MIT' 'NUC' 'MIT' 'CYT' 'NUC' 'NUC'\n",
      " 'CYT' 'MIT' 'MIT' 'CYT' 'CYT' 'NUC' 'NUC' 'NUC']\n"
     ]
    }
   ],
   "source": [
    "x_yeast = df_yeast[[\"mcg\", \"gvh\", \"alm\", \"mit\", \"erl\", \"pox\", \"vac\",\"nuc\"]].to_numpy()\n",
    "y_yeast = df_yeast[\"class\"].to_numpy()\n",
    "\n",
    "print(\"X_yeast\", x_yeast[:20, :])\n",
    "print(\"Y_yeast\", y_yeast[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_wine [[7.400e+00 7.000e-01 0.000e+00 1.900e+00 7.600e-02 1.100e+01 3.400e+01\n",
      "  9.978e-01 3.510e+00 5.600e-01 9.400e+00]\n",
      " [7.800e+00 8.800e-01 0.000e+00 2.600e+00 9.800e-02 2.500e+01 6.700e+01\n",
      "  9.968e-01 3.200e+00 6.800e-01 9.800e+00]\n",
      " [7.800e+00 7.600e-01 4.000e-02 2.300e+00 9.200e-02 1.500e+01 5.400e+01\n",
      "  9.970e-01 3.260e+00 6.500e-01 9.800e+00]\n",
      " [1.120e+01 2.800e-01 5.600e-01 1.900e+00 7.500e-02 1.700e+01 6.000e+01\n",
      "  9.980e-01 3.160e+00 5.800e-01 9.800e+00]\n",
      " [7.400e+00 7.000e-01 0.000e+00 1.900e+00 7.600e-02 1.100e+01 3.400e+01\n",
      "  9.978e-01 3.510e+00 5.600e-01 9.400e+00]\n",
      " [7.400e+00 6.600e-01 0.000e+00 1.800e+00 7.500e-02 1.300e+01 4.000e+01\n",
      "  9.978e-01 3.510e+00 5.600e-01 9.400e+00]\n",
      " [7.900e+00 6.000e-01 6.000e-02 1.600e+00 6.900e-02 1.500e+01 5.900e+01\n",
      "  9.964e-01 3.300e+00 4.600e-01 9.400e+00]\n",
      " [7.300e+00 6.500e-01 0.000e+00 1.200e+00 6.500e-02 1.500e+01 2.100e+01\n",
      "  9.946e-01 3.390e+00 4.700e-01 1.000e+01]\n",
      " [7.800e+00 5.800e-01 2.000e-02 2.000e+00 7.300e-02 9.000e+00 1.800e+01\n",
      "  9.968e-01 3.360e+00 5.700e-01 9.500e+00]\n",
      " [7.500e+00 5.000e-01 3.600e-01 6.100e+00 7.100e-02 1.700e+01 1.020e+02\n",
      "  9.978e-01 3.350e+00 8.000e-01 1.050e+01]\n",
      " [6.700e+00 5.800e-01 8.000e-02 1.800e+00 9.700e-02 1.500e+01 6.500e+01\n",
      "  9.959e-01 3.280e+00 5.400e-01 9.200e+00]\n",
      " [7.500e+00 5.000e-01 3.600e-01 6.100e+00 7.100e-02 1.700e+01 1.020e+02\n",
      "  9.978e-01 3.350e+00 8.000e-01 1.050e+01]\n",
      " [5.600e+00 6.150e-01 0.000e+00 1.600e+00 8.900e-02 1.600e+01 5.900e+01\n",
      "  9.943e-01 3.580e+00 5.200e-01 9.900e+00]\n",
      " [7.800e+00 6.100e-01 2.900e-01 1.600e+00 1.140e-01 9.000e+00 2.900e+01\n",
      "  9.974e-01 3.260e+00 1.560e+00 9.100e+00]\n",
      " [8.900e+00 6.200e-01 1.800e-01 3.800e+00 1.760e-01 5.200e+01 1.450e+02\n",
      "  9.986e-01 3.160e+00 8.800e-01 9.200e+00]\n",
      " [8.900e+00 6.200e-01 1.900e-01 3.900e+00 1.700e-01 5.100e+01 1.480e+02\n",
      "  9.986e-01 3.170e+00 9.300e-01 9.200e+00]\n",
      " [8.500e+00 2.800e-01 5.600e-01 1.800e+00 9.200e-02 3.500e+01 1.030e+02\n",
      "  9.969e-01 3.300e+00 7.500e-01 1.050e+01]\n",
      " [8.100e+00 5.600e-01 2.800e-01 1.700e+00 3.680e-01 1.600e+01 5.600e+01\n",
      "  9.968e-01 3.110e+00 1.280e+00 9.300e+00]\n",
      " [7.400e+00 5.900e-01 8.000e-02 4.400e+00 8.600e-02 6.000e+00 2.900e+01\n",
      "  9.974e-01 3.380e+00 5.000e-01 9.000e+00]\n",
      " [7.900e+00 3.200e-01 5.100e-01 1.800e+00 3.410e-01 1.700e+01 5.600e+01\n",
      "  9.969e-01 3.040e+00 1.080e+00 9.200e+00]]\n",
      "Y_wine [5 5 5 6 5 5 5 7 7 5 5 5 5 5 5 5 7 5 4 6]\n"
     ]
    }
   ],
   "source": [
    "x_wine = df_wine [[\"fixed acidity\", \"volatile acidity\", \"citric acid\", \"residual sugar\", \"chlorides\", \n",
    "                   \"free sulfur dioxide\", \"total sulfur dioxide\", \"density\", \"pH\", \"sulphates\", \"alcohol\"]].to_numpy()\n",
    "y_wine = df_wine[\"quality\"].to_numpy()\n",
    "\n",
    "print(\"X_wine\", x_wine[:20, :])\n",
    "print(\"Y_wine\", y_wine[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mammographic = df_mammographics[[\"BI-RADS\",\"Age\",\n",
    "                                   \"Shape_1\",\"Shape_2\",\"Shape_3\",\"Shape_4\",\n",
    "                                   \"Margin_1\",\"Margin_2\",\"Margin_3\",\"Margin_4\",\"Margin_5\",\n",
    "                                   \"Density\"]].to_numpy()\n",
    "\n",
    "y_mammographic = df_mammographics[\"Severity\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_breast_cancer [['30-39' 'premeno' '30-34' '0-2' 'no' 3 'left' 'left_low' 'no']\n",
      " ['40-49' 'premeno' '20-24' '0-2' 'no' 2 'right' 'right_up' 'no']\n",
      " ['40-49' 'premeno' '20-24' '0-2' 'no' 2 'left' 'left_low' 'no']\n",
      " ['60-69' 'ge40' '15-19' '0-2' 'no' 2 'right' 'left_up' 'no']\n",
      " ['40-49' 'premeno' '0-4' '0-2' 'no' 2 'right' 'right_low' 'no']\n",
      " ['60-69' 'ge40' '15-19' '0-2' 'no' 2 'left' 'left_low' 'no']\n",
      " ['50-59' 'premeno' '25-29' '0-2' 'no' 2 'left' 'left_low' 'no']\n",
      " ['60-69' 'ge40' '20-24' '0-2' 'no' 1 'left' 'left_low' 'no']\n",
      " ['40-49' 'premeno' '50-54' '0-2' 'no' 2 'left' 'left_low' 'no']\n",
      " ['40-49' 'premeno' '20-24' '0-2' 'no' 2 'right' 'left_up' 'no']\n",
      " ['40-49' 'premeno' '0-4' '0-2' 'no' 3 'left' 'central' 'no']\n",
      " ['50-59' 'ge40' '25-29' '0-2' 'no' 2 'left' 'left_low' 'no']\n",
      " ['60-69' 'lt40' '10-14' '0-2' 'no' 1 'left' 'right_up' 'no']\n",
      " ['50-59' 'ge40' '25-29' '0-2' 'no' 3 'left' 'right_up' 'no']\n",
      " ['40-49' 'premeno' '30-34' '0-2' 'no' 3 'left' 'left_up' 'no']\n",
      " ['60-69' 'lt40' '30-34' '0-2' 'no' 1 'left' 'left_low' 'no']\n",
      " ['40-49' 'premeno' '15-19' '0-2' 'no' 2 'left' 'left_low' 'no']\n",
      " ['50-59' 'premeno' '30-34' '0-2' 'no' 3 'left' 'left_low' 'no']\n",
      " ['60-69' 'ge40' '30-34' '0-2' 'no' 3 'left' 'left_low' 'no']\n",
      " ['50-59' 'ge40' '30-34' '0-2' 'no' 1 'right' 'right_up' 'no']]\n",
      "Y_breast_cancer ['no-recurrence-events' 'no-recurrence-events' 'no-recurrence-events'\n",
      " 'no-recurrence-events' 'no-recurrence-events' 'no-recurrence-events'\n",
      " 'no-recurrence-events' 'no-recurrence-events' 'no-recurrence-events'\n",
      " 'no-recurrence-events' 'no-recurrence-events' 'no-recurrence-events'\n",
      " 'no-recurrence-events' 'no-recurrence-events' 'no-recurrence-events'\n",
      " 'no-recurrence-events' 'no-recurrence-events' 'no-recurrence-events'\n",
      " 'no-recurrence-events' 'no-recurrence-events']\n"
     ]
    }
   ],
   "source": [
    "x_breast_cancer = df_breast_cancer[[\"age\", \"menopause\", \"tumor-size\", \"inv-nodes\", \"node-caps\", \"deg-malig\", \"breast\", \n",
    "                                    \"breast-quad\", \"irradiat\"]].to_numpy()\n",
    "y_breast_cancer = df_breast_cancer[\"class\"].to_numpy()\n",
    "\n",
    "print(\"X_breast_cancer\", x_breast_cancer[:20, :])\n",
    "print(\"Y_breast_cancer\", y_breast_cancer[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_primary_tumor [[1. 1. 2. 3. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
      " [1. 1. 2. 3. 2. 2. 2. 2. 2. 1. 2. 2. 2. 1. 2. 1. 2.]\n",
      " [1. 2. 2. 3. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2.]\n",
      " [1. 2. 2. 3. 1. 2. 1. 1. 2. 2. 2. 2. 2. 2. 2. 1. 2.]\n",
      " [1. 2. 2. 3. 1. 2. 1. 1. 2. 2. 2. 2. 2. 2. 2. 1. 2.]\n",
      " [1. 2. 2. 3. 1. 2. 2. 2. 2. 2. 1. 2. 2. 1. 1. 1. 2.]\n",
      " [2. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 1. 1. 1. 2. 2. 2.]\n",
      " [2. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
      " [2. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2.]\n",
      " [2. 1. 1. 2. 1. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 2.]\n",
      " [2. 1. 1. 3. 1. 2. 2. 1. 2. 2. 2. 2. 2. 1. 2. 1. 2.]\n",
      " [2. 1. 1. 3. 1. 2. 2. 2. 2. 2. 2. 1. 2. 2. 1. 2. 2.]\n",
      " [2. 1. 1. 3. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
      " [2. 1. 1. 3. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
      " [2. 1. 1. 3. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 1. 2.]\n",
      " [2. 1. 1. 2. 2. 2. 2. 1. 2. 1. 2. 2. 2. 2. 2. 2. 2.]\n",
      " [2. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 1. 2.]\n",
      " [2. 1. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2.]\n",
      " [2. 1. 2. 3. 1. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2.]\n",
      " [2. 1. 2. 3. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 1. 2.]]\n",
      "Y_primary_tumor [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "x_primary_tumor = df_primary_tumor[[\"age\", \"sex\", \"histologic-type\", \"degree-of-diffe\", \"bone\", \"bone-marrow\", \"lung\",\n",
    "                     \"pleura\", \"peritoneum\", \"liver\", \"brain\", \"skin\", \"neck\", \"supraclavicular\", \"axillar\", \n",
    "                    \"mediastinum\", \"abdomnial\"]].to_numpy()\n",
    "y_primary_tumor = df_primary_tumor[\"class\"].to_numpy()\n",
    "\n",
    "print(\"X_primary_tumor\", x_primary_tumor[:20, :])\n",
    "print(\"Y_primary_tumor\", y_primary_tumor[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separam setul de date in set de antrenare si set de testare.\n",
    "<br> Cand folosim random state facem un random mai stabil."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color= magenta> A. Algoritmi care nu necesita scalarea datelor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color= magenta> 1. DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree_method(X, y) -> None:\n",
    "    \n",
    "    model = DecisionTreeClassifier(max_depth=5, min_samples_leaf=15)\n",
    "        \n",
    "    scores = cross_validate(model, X, y, cv=5, scoring='accuracy', return_train_score=True)\n",
    "    scores_f = cross_validate(model, X, y, cv=5, scoring='f1_weighted', return_train_score=True)\n",
    "    \n",
    "    print ('Acuratetea setului de antrenare este:', scores['train_score'], 'si are media:', scores['train_score'].mean())\n",
    "    print ('Acuratetea setului de testare este:', scores['test_score'], 'si are media:', scores['test_score'].mean())\n",
    "\n",
    "    print ('F1 pentru setul de antrenare este:', scores_f['train_score'], 'si are media', scores_f['train_score'].mean())\n",
    "    print ('F1 pentru setul de testare este:', scores_f['test_score'], 'si are media', scores_f['test_score'].mean())\n",
    "    \n",
    "#      for i in range(5):\n",
    "#         X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3, random_state=i)\n",
    "        \n",
    "#         model = DecisionTreeClassifier(max_depth=5, min_samples_leaf=15)\n",
    "#         model.fit(X_train, y_train)\n",
    "       \n",
    "#         y_predicated_train = model.predict(X_train)\n",
    "#         y_predicated_test = model.predict(X_test)\n",
    "    \n",
    "#         print (\"Iteration: \", i)\n",
    "#         print (\"Train score:\", model.score(X_train, y_train)*100)\n",
    "#         print (\"Test score:\", model.score(X_test, y_test)*100)\n",
    "#         print (\"Different outputs train:\", sum(y_predicated_train != y_train), \"from total of\", len(y_train))\n",
    "#         print (\"Different outputs test:\", sum(y_predicated_test != y_test), \"from total of\", len(y_test))\n",
    "#         print (\"Accuracy train:\", metrics.accuracy_score(y_train, y_predicated_train)*100)\n",
    "#         # average='micro' Calculate metrics globally by counting the total true positives, false negatives and false positives.\n",
    "#         print (\"F1-score train:\", metrics.f1_score(y_train, y_predicated_train, average='micro')*100)\n",
    "#         print (\"Accuracy test:\", metrics.accuracy_score(y_test, y_predicated_test)*100)\n",
    "#         print (\"F1-score test:\", metrics.f1_score(y_test, y_predicated_test, average='micro')*100)\n",
    "#         print ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuratetea setului de antrenare este: [0.61836563 0.61920809 0.60994103 0.63100253 0.61700337] si are media: 0.6191041274866043\n",
      "Acuratetea setului de testare este: [0.60606061 0.57239057 0.56228956 0.53872054 0.56756757] si are media: 0.5694057694057694\n",
      "F1 pentru setul de antrenare este: [0.60269116 0.59670385 0.59136236 0.61577814 0.59557764] si are media 0.6004226305634168\n",
      "F1 pentru setul de testare este: [0.59267024 0.55168132 0.53780771 0.52466963 0.54820681] si are media 0.5510071424486854\n"
     ]
    }
   ],
   "source": [
    "decision_tree_method(x_yeast, y_yeast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuratetea setului de antrenare este: [0.65050821 0.65050821 0.65129007 0.66692729 0.6671875 ] si are media: 0.6572842552775606\n",
      "Acuratetea setului de testare este: [0.5125     0.4875     0.565625   0.54375    0.57366771] si are media: 0.5366085423197492\n",
      "F1 pentru setul de antrenare este: [0.62895952 0.62114804 0.63520597 0.63780948 0.64974681] si are media 0.6345739624252036\n",
      "F1 pentru setul de testare este: [0.46757743 0.4678346  0.55057509 0.52144317 0.55862606] si are media 0.5132112682481044\n"
     ]
    }
   ],
   "source": [
    "decision_tree_method(x_wine, y_wine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuratetea setului de antrenare este: [0.84765625 0.83875163 0.83224967 0.85695709 0.84915475] si are media: 0.8449538767880365\n",
      "Acuratetea setului de testare este: [0.8238342  0.84895833 0.86979167 0.796875   0.8125    ] si are media: 0.8303918393782382\n",
      "F1 pentru setul de antrenare este: [0.84707059 0.83891629 0.83109108 0.85711622 0.84912447] si are media 0.8446637289495176\n",
      "F1 pentru setul de testare este: [0.82347124 0.84835523 0.8694528  0.79712312 0.80697028] si are media 0.8290745357062399\n"
     ]
    }
   ],
   "source": [
    "decision_tree_method(x_mammographic, y_mammographic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color= magenta> 2. RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_method(X, y, max_depth, min_samples_leaf) -> None:\n",
    "    \n",
    "    model = RandomForestClassifier(max_depth=max_depth, min_samples_leaf=min_samples_leaf)\n",
    "        \n",
    "    scores = cross_validate(model, X, y, cv=5, scoring='accuracy', return_train_score=True)\n",
    "    scores_f = cross_validate(model, X, y, cv=5, scoring='f1_weighted', return_train_score=True)\n",
    "    \n",
    "    print ('Acuratetea setului de antrenare este:', scores['train_score'], 'si are media:', scores['train_score'].mean())\n",
    "    print ('Acuratetea setului de testare este:', scores['test_score'], 'si are media:', scores['test_score'].mean())\n",
    "\n",
    "    print ('F1 pentru setul de antrenare este:', scores_f['train_score'], 'si are media', scores_f['train_score'].mean())\n",
    "    print ('F1 pentru setul de testare este:', scores_f['test_score'], 'si are media', scores_f['test_score'].mean())\n",
    "    \n",
    "    \n",
    "#     for i in range(5):\n",
    "#         X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3, random_state=i)\n",
    "        \n",
    "#         model = RandomForestClassifier(max_depth=max_depth, min_samples_leaf=min_samples_leaf)\n",
    "#         model.fit(X_train, y_train)\n",
    "       \n",
    "#         y_predicated_train = model.predict(X_train)\n",
    "#         y_predicated_test = model.predict(X_test)\n",
    "    \n",
    "#         print (\"Train score:\", model.score(X_train, y_train)*100)\n",
    "#         print (\"Test score:\", model.score(X_test, y_test)*100)\n",
    "#         print (\"Different outputs train:\", sum(y_predicated_train != y_train), \"from total of\", len(y_train))\n",
    "#         print (\"Different outputs test:\", sum(y_predicated_test != y_test), \"from total of\", len(y_test))\n",
    "#         print (\"Accuracy train:\", metrics.accuracy_score(y_train, y_predicated_train)*100)\n",
    "#         # average='micro' Calculate metrics globally by counting the total true positives, false negatives and false positives.\n",
    "#         print (\"F1-score train:\", metrics.f1_score(y_train, y_predicated_train, average='micro')*100)\n",
    "#         print (\"Accuracy test:\", metrics.accuracy_score(y_test, y_predicated_test)*100)\n",
    "#         print (\"F1-score test:\", metrics.f1_score(y_test, y_predicated_test, average='micro')*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuratetea setului de antrenare este: [0.61331087 0.62426285 0.61752317 0.64195451 0.62626263] si are media: 0.6246628032643197\n",
      "Acuratetea setului de testare este: [0.58249158 0.57912458 0.63636364 0.52861953 0.61148649] si are media: 0.5876171626171626\n",
      "F1 pentru setul de antrenare este: [0.59659008 0.60909327 0.60577034 0.61371842 0.61183528] si are media 0.6074014788773463\n",
      "F1 pentru setul de testare este: [0.56884106 0.5531812  0.61749958 0.53036119 0.5903004 ] si are media 0.5720366855197321\n"
     ]
    }
   ],
   "source": [
    "random_forest_method(x_yeast, y_yeast, 4, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuratetea setului de antrenare este: [0.63096169 0.6247068  0.61532447 0.62236122 0.60703125] si are media: 0.6200770865910867\n",
      "Acuratetea setului de testare este: [0.528125   0.559375   0.6375     0.578125   0.59561129] si are media: 0.5797472570532914\n",
      "F1 pentru setul de antrenare este: [0.58121611 0.58132796 0.56732681 0.56370289 0.55510429] si are media 0.5697356124342999\n",
      "F1 pentru setul de testare este: [0.48168137 0.49364677 0.57010909 0.50572575 0.55037101] si are media 0.5203067970530925\n"
     ]
    }
   ],
   "source": [
    "random_forest_method(x_wine, y_wine, 3, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuratetea setului de antrenare este: [0.83463542 0.82574772 0.82574772 0.84785436 0.84655397] si are media: 0.8361078375596012\n",
      "Acuratetea setului de testare este: [0.80829016 0.828125   0.85416667 0.8125     0.8125    ] si are media: 0.8231163644214163\n",
      "F1 pentru setul de antrenare este: [0.84264466 0.83463991 0.83244309 0.84280549 0.84898253] si are media 0.8403031379328632\n",
      "F1 pentru setul de testare este: [0.80820724 0.84391962 0.8439538  0.80754816 0.80892937] si are media 0.8225116374577504\n"
     ]
    }
   ],
   "source": [
    "random_forest_method(x_mammographic, y_mammographic, 5, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=magenta> B. Algoritmi care necesita scalarea datelor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pentru urmatoarele metode de clasificare vom scala datele."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaler.fit(x_wine)\n",
    "\n",
    "x_wine = scaler.transform(x_wine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-87-e29920714ba7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mscaler_mammographic\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_mammographic\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"BI-RADS\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Age\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#x_mammographic = scaler.transform(x_mammographic)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "# scaler_mammographic = MinMaxScaler()\n",
    "\n",
    "# scaler.fit(x_mammographic[\"BI-RADS\",\"Age\"])\n",
    "\n",
    "# #x_mammographic = scaler.transform(x_mammographic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=magenta> 1. KNeighbourClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_neighbours_method(X, y, number_of_neighbors) -> None:\n",
    "    \n",
    "    model = KNeighborsClassifier(n_neighbors=number_of_neighbors)\n",
    "    \n",
    "    scores = cross_validate(model, X, y, cv=5, scoring='accuracy', return_train_score=True)\n",
    "    scores_f = cross_validate(model, X, y, cv=5, scoring='f1_weighted', return_train_score=True)\n",
    "    \n",
    "    print ('Acuratetea setului de antrenare este:', scores['train_score'], 'si are media:', scores['train_score'].mean())\n",
    "    print ('Acuratetea setului de testare este:', scores['test_score'], 'si are media:', scores['test_score'].mean())\n",
    "\n",
    "    print ('F1 pentru setul de antrenare este:', scores_f['train_score'], 'si are media', scores_f['train_score'].mean())\n",
    "    print ('F1 pentru setul de testare este:', scores_f['test_score'], 'si are media', scores_f['test_score'].mean())\n",
    "\n",
    "#     for i in range(5):\n",
    "#         X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3, random_state=i)\n",
    "    \n",
    "#         model = KNeighborsClassifier(n_neighbors = number_of_neighbors)\n",
    "#         model.fit(X_train, y_train)\n",
    "    \n",
    "#         y_predicated_train = model.predict(X_train)\n",
    "#         y_predicated_test = model.predict(X_test)\n",
    "    \n",
    "#         print (\"Iteration:\", i)\n",
    "#         print (\"Train score:\", model.score(X_train, y_train)*100)\n",
    "#         print (\"Test score:\", model.score(X_test, y_test)*100)\n",
    "#         print (\"Different outputs train:\", sum(y_predicated_train != y_train), \"from total of\", len(y_train))\n",
    "#         print (\"Different outputs test:\", sum(y_predicated_test != y_test), \"from total of\", len(y_test))\n",
    "#         print (\"Accuracy train:\", metrics.accuracy_score(y_train, y_predicated_train)*100)\n",
    "#         # average='micro' Calculate metrics globally by counting the total true positives, false negatives and false positives.\n",
    "#         print (\"F1-score train:\", metrics.f1_score(y_train, y_predicated_train, average='micro')*100)\n",
    "#         print (\"Accuracy test:\", metrics.accuracy_score(y_test, y_predicated_test)*100)\n",
    "#         print (\"F1-score test:\", metrics.f1_score(y_test, y_predicated_test, average='micro')*100)\n",
    "#         print ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuratetea setului de antrenare este: [0.64953665 0.65880371 0.64869419 0.65964617 0.6489899 ] si are media: 0.6531341213312569\n",
      "Acuratetea setului de testare este: [0.54882155 0.56228956 0.5959596  0.53198653 0.60472973] si are media: 0.5687573937573938\n",
      "F1 pentru setul de antrenare este: [0.6400713  0.64859767 0.64153687 0.6512153  0.63969849] si are media 0.6442239256194373\n",
      "F1 pentru setul de testare este: [0.53840288 0.55291814 0.59317743 0.51876893 0.59730318] si are media 0.5601141134298688\n"
     ]
    }
   ],
   "source": [
    "k_neighbours_method(x_yeast, y_yeast, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuratetea setului de antrenare este: [0.59265051 0.61141517 0.59265051 0.59655981 0.59921875] si are media: 0.5984989493745113\n",
      "Acuratetea setului de testare este: [0.534375   0.5375     0.63125    0.59375    0.58934169] si are media: 0.5772433385579937\n",
      "F1 pentru setul de antrenare este: [0.56963722 0.58200114 0.55534125 0.57052625 0.56642527] si are media 0.5687862257960197\n",
      "F1 pentru setul de testare este: [0.47535029 0.51309811 0.60209033 0.58095024 0.55004792] si are media 0.5443073765758127\n"
     ]
    }
   ],
   "source": [
    "k_neighbours_method(x_wine, y_wine, 73)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuratetea setului de antrenare este: [0.8359375  0.8283485  0.82054616 0.83355007 0.83094928] si are media: 0.8298663036410924\n",
      "Acuratetea setului de testare este: [0.8134715  0.84375    0.828125   0.80729167 0.76041667] si are media: 0.8106109671848014\n",
      "F1 pentru setul de antrenare este: [0.83599562 0.82800639 0.82057972 0.83340265 0.83061236] si are media 0.829719346813059\n",
      "F1 pentru setul de testare este: [0.8130872  0.8439538  0.82788534 0.80752742 0.7558542 ] si are media 0.8096615927463491\n"
     ]
    }
   ],
   "source": [
    "k_neighbours_method(x_mammographic, y_mammographic, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=Magenta> 2. MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_method(X, y, activ) -> None:\n",
    "    #â€˜sgdâ€™ refers to stochastic gradient descent.\n",
    "    \n",
    "    model =  MLPClassifier(activation = activ, random_state=10)\n",
    "    \n",
    "    scores = cross_validate(model, X, y, cv=5, scoring='accuracy', return_train_score=True)\n",
    "    scores_f = cross_validate(model, X, y, cv=5, scoring='f1_weighted', return_train_score=True)\n",
    "    \n",
    "    print ('Acuratetea setului de antrenare este:', scores['train_score'], 'si are media:', scores['train_score'].mean())\n",
    "    print ('Acuratetea setului de testare este:', scores['test_score'], 'si are media:', scores['test_score'].mean())\n",
    "\n",
    "    print ('F1 pentru setul de antrenare este:', scores_f['train_score'], 'si are media', scores_f['train_score'].mean())\n",
    "    print ('F1 pentru setul de testare este:', scores_f['test_score'], 'si are media', scores_f['test_score'].mean())\n",
    "    \n",
    "#     for i in range(5):\n",
    "#         X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3, random_state=i)\n",
    "        \n",
    "#         model =  MLPClassifier(activation = activ, random_state = 10)\n",
    "#         model.fit(X_train, y_train)\n",
    "    \n",
    "#         y_predicated_train = model.predict(X_train)\n",
    "#         y_predicated_test = model.predict(X_test)\n",
    "    \n",
    "#         print (\"Iteration:\", i)\n",
    "#         print (\"Train score:\", model.score(X_train, y_train)*100)\n",
    "#         print (\"Test score:\", model.score(X_test, y_test)*100)\n",
    "#         print (\"Different outputs train:\", sum(y_predicated_train != y_train), \"from total of\", len(y_train))\n",
    "#         print (\"Different outputs test:\", sum(y_predicated_test != y_test), \"from total of\", len(y_test))\n",
    "#         print (\"Accuracy train:\", metrics.accuracy_score(y_train, y_predicated_train)*100)\n",
    "#         # average='micro' Calculate metrics globally by counting the total true positives, false negatives and false positives.\n",
    "#         print (\"F1-score train:\", metrics.f1_score(y_train, y_predicated_train, average='micro')*100)\n",
    "#         print (\"Accuracy test:\", metrics.accuracy_score(y_test, y_predicated_test)*100)\n",
    "#         print (\"F1-score test:\", metrics.f1_score(y_test, y_predicated_test, average='micro')*100)\n",
    "#         print ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\dataScience\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "D:\\Anaconda\\envs\\dataScience\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "D:\\Anaconda\\envs\\dataScience\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "D:\\Anaconda\\envs\\dataScience\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "D:\\Anaconda\\envs\\dataScience\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "D:\\Anaconda\\envs\\dataScience\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "D:\\Anaconda\\envs\\dataScience\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "D:\\Anaconda\\envs\\dataScience\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "D:\\Anaconda\\envs\\dataScience\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuratetea setului de antrenare este: [0.58972199 0.58972199 0.57877001 0.60404381 0.59848485] si are media: 0.5921485282479385\n",
      "Acuratetea setului de testare este: [0.58922559 0.57912458 0.58922559 0.54208754 0.58783784] si are media: 0.5775002275002274\n",
      "F1 pentru setul de antrenare este: [0.57604484 0.57556155 0.56599829 0.59077186 0.58408689] si are media 0.578492686928124\n",
      "F1 pentru setul de testare este: [0.57101369 0.56406854 0.57653579 0.52974852 0.57529287] si are media 0.5633318808664869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\dataScience\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "mlp_method (x_yeast, y_yeast, 'tanh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\dataScience\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "D:\\Anaconda\\envs\\dataScience\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "D:\\Anaconda\\envs\\dataScience\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "D:\\Anaconda\\envs\\dataScience\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "D:\\Anaconda\\envs\\dataScience\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "D:\\Anaconda\\envs\\dataScience\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "D:\\Anaconda\\envs\\dataScience\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "D:\\Anaconda\\envs\\dataScience\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "D:\\Anaconda\\envs\\dataScience\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuratetea setului de antrenare este: [0.62314308 0.64581704 0.61219703 0.60985145 0.615625  ] si are media: 0.6213267200938233\n",
      "Acuratetea setului de testare este: [0.540625   0.515625   0.565625   0.565625   0.55799373] si are media: 0.5490987460815047\n",
      "F1 pentru setul de antrenare este: [0.60021854 0.62591633 0.58974116 0.58360973 0.58480903] si are media 0.5968589578870673\n",
      "F1 pentru setul de testare este: [0.4809405  0.49839484 0.54145581 0.54977549 0.52037727] si are media 0.5181887832976356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\dataScience\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "mlp_method (x_wine, y_wine, 'tanh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\dataScience\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "D:\\Anaconda\\envs\\dataScience\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "D:\\Anaconda\\envs\\dataScience\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "D:\\Anaconda\\envs\\dataScience\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "D:\\Anaconda\\envs\\dataScience\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "D:\\Anaconda\\envs\\dataScience\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "D:\\Anaconda\\envs\\dataScience\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuratetea setului de antrenare este: [0.82552083 0.81274382 0.81924577 0.83224967 0.83094928] si are media: 0.8241418779800608\n",
      "Acuratetea setului de testare este: [0.78238342 0.83333333 0.81770833 0.77604167 0.81770833] si are media: 0.8054350172711571\n",
      "F1 pentru setul de antrenare este: [0.82558265 0.81284115 0.81932561 0.832477   0.83118112] si are media 0.8242815058738477\n",
      "F1 pentru setul de testare este: [0.78267573 0.83318864 0.81745415 0.77633975 0.81697262] si are media 0.8053261771644881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\dataScience\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "mlp_method (x_mammographic, y_mammographic, 'tanh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlp_method(X_train_yeast, y_train_yeast, X_test_yeast, y_test_yeast, 'tanh')\n",
    "\n",
    "# # Train score: 59.45399393326593 #solver='adam'\n",
    "# # Test score: 61.41414141414141\n",
    "# # Different outputs train: 401 from total of 989\n",
    "# # Different outputs test: 191 from total of 495\n",
    "\n",
    "# # Train score: 62.588473205257834 #solver='lbfgs'\n",
    "# # Test score: 61.41414141414141\n",
    "# # Different outputs train: 370 from total of 989\n",
    "# # Different outputs test: 191 from total of 495"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# mlp_method(X_train_wine, y_train_wine, X_test_wine, y_test_wine, 'tanh')\n",
    "\n",
    "# # Train score: 62.7579737335835 #solver='adam'\n",
    "# # Test score: 53.09568480300187\n",
    "# # Different outputs train: 397 from total of 1066\n",
    "# # Different outputs test: 250 from total of 533\n",
    "\n",
    "# # Train score: 65.94746716697935 #solver='lbfgs'\n",
    "# # Test score: 54.971857410881796\n",
    "# # Different outputs train: 363 from total of 1066\n",
    "# # Different outputs test: 240 from total of 533"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlp_method(X_train_breast_cancer, y_train_breast_cancer, X_test_breast_cancer, y_test_breast_cancer, 'relu')\n",
    "\n",
    "# # Train score: 78.94736842105263 #solver='adam'\n",
    "# # Test score: 73.95833333333334\n",
    "# # Different outputs train: 40 from total of 190\n",
    "# # Different outputs test: 25 from total of 96\n",
    "\n",
    "# # Train score: 78.94736842105263 #solver='lbfgs'\n",
    "# # Test score: 68.75\n",
    "# # Different outputs train: 40 from total of 190\n",
    "# # Different outputs test: 30 from total of 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlp_method(X_train_primary_tumor, y_train_primary_tumor, X_test_primary_tumor, y_test_primary_tumor, 'identity')\n",
    "\n",
    "# # Train score: 56.19469026548673 #solver='adam'\n",
    "# # Test score: 42.47787610619469\n",
    "# # Different outputs train: 99 from total of 226\n",
    "# # Different outputs test: 65 from total of 113\n",
    "\n",
    "# # Train score: 66.3716814159292 #solver='lbfgs'\n",
    "# # Test score: 38.93805309734513\n",
    "# # Different outputs train: 76 from total of 226\n",
    "# # Different outputs test: 69 from total of 113"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=Magenta> 3. SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svc_method(X, y) -> None:\n",
    "    \n",
    "    model = SVC(class_weight=None, random_state = 10)\n",
    "    \n",
    "    scores = cross_validate(model, X, y, cv=5, scoring='accuracy', return_train_score=True)\n",
    "    scores_f = cross_validate(model, X, y, cv=5, scoring='f1_weighted', return_train_score=True)\n",
    "    \n",
    "    print ('Acuratetea setului de antrenare este:', scores['train_score'], 'si are media:', scores['train_score'].mean())\n",
    "    print ('Acuratetea setului de testare este:', scores['test_score'], 'si are media:', scores['test_score'].mean())\n",
    "\n",
    "    print ('F1 pentru setul de antrenare este:', scores_f['train_score'], 'si are media', scores_f['train_score'].mean())\n",
    "    print ('F1 pentru setul de testare este:', scores_f['test_score'], 'si are media', scores_f['test_score'].mean())\n",
    "    \n",
    "#     for i in range(5):\n",
    "#         X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3, random_state=i)\n",
    "        \n",
    "#         model = SVC(class_weight=None, random_state = 10)\n",
    "#         model.fit(X_train,y_train)\n",
    "    \n",
    "#         y_predicated_train = model.predict(X_train)\n",
    "#         y_predicated_test = model.predict(X_test)\n",
    "    \n",
    "#         print (\"Iteration:\", i)\n",
    "#         print (\"Train score:\", model.score(X_train, y_train)*100)\n",
    "#         print (\"Test score:\", model.score(X_test, y_test)*100)\n",
    "#         print (\"Different outputs train:\", sum(y_predicated_train != y_train), \"from total of\", len(y_train))\n",
    "#         print (\"Different outputs test:\", sum(y_predicated_test != y_test), \"from total of\", len(y_test))\n",
    "#         print (\"Accuracy train:\", metrics.accuracy_score(y_train, y_predicated_train)*100)\n",
    "#         # average='micro' Calculate metrics globally by counting the total true positives, false negatives and false positives.\n",
    "#         print (\"F1-score train:\", metrics.f1_score(y_train, y_predicated_train, average='micro')*100)\n",
    "#         print (\"Accuracy test:\", metrics.accuracy_score(y_test, y_predicated_test)*100)\n",
    "#         print (\"F1-score test:\", metrics.f1_score(y_test, y_predicated_test, average='micro')*100)\n",
    "#         print ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuratetea setului de antrenare este: [0.61078349 0.62173547 0.60320135 0.64026959 0.61784512] si are media: 0.618767001665064\n",
      "Acuratetea setului de testare este: [0.61616162 0.61616162 0.62289562 0.54882155 0.59121622] si are media: 0.599051324051324\n",
      "F1 pentru setul de antrenare este: [0.60028884 0.61091196 0.59489801 0.63121115 0.60759518] si are media 0.6089810273490984\n",
      "F1 pentru setul de testare este: [0.60209739 0.60709779 0.6130061  0.53866087 0.58190772] si are media 0.5885539757319778\n"
     ]
    }
   ],
   "source": [
    "svc_method (x_yeast, y_yeast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuratetea setului de antrenare este: [0.49413604 0.50977326 0.50820954 0.51681001 0.515625  ] si are media: 0.5089107701329163\n",
      "Acuratetea setului de testare este: [0.56875    0.534375   0.475      0.45625    0.47648903] si are media: 0.5021728056426331\n",
      "F1 pentru setul de antrenare este: [0.44658447 0.46315407 0.45401245 0.46292213 0.46402868] si are media 0.4581403584304849\n",
      "F1 pentru setul de testare este: [0.51466981 0.48120523 0.41764233 0.3989265  0.4201086 ] si are media 0.4465104911226513\n"
     ]
    }
   ],
   "source": [
    "svc_method (x_wine, y_wine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuratetea setului de antrenare este: [0.71614583 0.69830949 0.6970091  0.70351105 0.71131339] si are media: 0.7052577752492415\n",
      "Acuratetea setului de testare este: [0.65284974 0.72395833 0.73958333 0.71875    0.67708333] si are media: 0.7024449481865285\n",
      "F1 pentru setul de antrenare este: [0.71521169 0.69657612 0.69616113 0.70230304 0.71002274] si are media 0.7040549442212546\n",
      "F1 pentru setul de testare este: [0.65234206 0.72323993 0.737861   0.71819581 0.67429926] si are media 0.7011876125687839\n"
     ]
    }
   ],
   "source": [
    "svc_method (x_mammographic, y_mammographic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color = magenta> 4. GaussianProcessClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_method(X, y) -> None:\n",
    "    \n",
    "    model = GaussianProcessClassifier(random_state = 10)\n",
    "    \n",
    "    scores = cross_validate(model, X, y, cv=5, scoring='accuracy', return_train_score=True)\n",
    "    scores_f = cross_validate(model, X, y, cv=5, scoring='f1_weighted', return_train_score=True)\n",
    "    \n",
    "    print ('Acuratetea setului de antrenare este:', scores['train_score'], 'si are media:', scores['train_score'].mean())\n",
    "    print ('Acuratetea setului de testare este:', scores['test_score'], 'si are media:', scores['test_score'].mean())\n",
    "\n",
    "    print ('F1 pentru setul de antrenare este:', scores_f['train_score'], 'si are media', scores_f['train_score'].mean())\n",
    "    print ('F1 pentru setul de testare este:', scores_f['test_score'], 'si are media', scores_f['test_score'].mean())\n",
    "    \n",
    "#     for i in range(5):\n",
    "#         X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3, random_state=i)\n",
    "        \n",
    "#         model = GaussianProcessClassifier(random_state = 10)\n",
    "#         model.fit(X_train, y_train)\n",
    "    \n",
    "#         y_predicated_train = model.predict(X_train)\n",
    "#         y_predicated_test = model.predict(X_test)\n",
    "    \n",
    "#         print (\"Train score:\", model.score(X_train, y_train)*100)\n",
    "#         print (\"Test score:\", model.score(X_test, y_test)*100)\n",
    "#         print (\"Different outputs train:\", sum(y_predicated_train != y_train), \"from total of\", len(y_train))\n",
    "#         print (\"Different outputs test:\", sum(y_predicated_test != y_test), \"from total of\", len(y_test))\n",
    "#         print (\"Accuracy train:\", metrics.accuracy_score(y_train, y_predicated_train)*100)\n",
    "#         # average='micro' Calculate metrics globally by counting the total true positives, false negatives and false positives.\n",
    "#         print (\"F1-score train:\", metrics.f1_score(y_train, y_predicated_train, average='micro')*100)\n",
    "#         print (\"Accuracy test:\", metrics.accuracy_score(y_test, y_predicated_test)*100)\n",
    "#         print (\"F1-score test:\", metrics.f1_score(y_test, y_predicated_test, average='micro')*100)\n",
    "#         print ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuratetea setului de antrenare este: [0.54928391 0.54759899 0.53664701 0.56697557 0.55387205] si are media: 0.5508755059723889\n",
      "Acuratetea setului de testare este: [0.53872054 0.56902357 0.56228956 0.4983165  0.55405405] si are media: 0.5444808444808444\n",
      "F1 pentru setul de antrenare este: [0.52604099 0.52297166 0.51240678 0.54444678 0.5296878 ] si are media 0.5271108034696936\n",
      "F1 pentru setul de testare este: [0.50722909 0.54379091 0.53765294 0.4757784  0.52781064] si are media 0.5184523929808442\n"
     ]
    }
   ],
   "source": [
    "gaussian_method(x_yeast, y_yeast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuratetea setului de antrenare este: [0.96716185 0.96637998 0.96325254 0.96559812 0.97109375] si are media: 0.9666972488272088\n",
      "Acuratetea setului de testare este: [0.475     0.446875  0.45625   0.434375  0.4169279] si are media: 0.44588557993730404\n",
      "F1 pentru setul de antrenare este: [0.96671901 0.96616915 0.96300821 0.96531017 0.97098934] si are media 0.9664391776802462\n",
      "F1 pentru setul de testare este: [0.45735767 0.4470916  0.45057482 0.4345787  0.39989279] si are media 0.4378991168328115\n"
     ]
    }
   ],
   "source": [
    "gaussian_method(x_wine, y_wine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuratetea setului de antrenare este: [0.90364583 0.90117035 0.89856957 0.90897269 0.90507152] si are media: 0.9034859937147811\n",
      "Acuratetea setului de testare este: [0.8238342  0.83333333 0.8125     0.77083333 0.765625  ] si are media: 0.8012251727115718\n",
      "F1 pentru setul de antrenare este: [0.90373237 0.90122172 0.89862229 0.90897269 0.90511345] si are media 0.9035325035892858\n",
      "F1 pentru setul de testare este: [0.82347124 0.83351426 0.8125     0.77113225 0.76279478] si are media 0.8006825048465511\n"
     ]
    }
   ],
   "source": [
    "gaussian_method(x_mammographic, y_mammographic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=magenta> 5. GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_nb_method(X, y) -> None:\n",
    "    \n",
    "    model = GaussianNB()\n",
    "    \n",
    "    scores = cross_validate(model, X, y, cv=5, scoring='accuracy', return_train_score=True)\n",
    "    scores_f = cross_validate(model, X, y, cv=5, scoring='f1_weighted', return_train_score=True)\n",
    "    \n",
    "    print ('Acuratetea setului de antrenare este:', scores['train_score'], 'si are media:', scores['train_score'].mean())\n",
    "    print ('Acuratetea setului de testare este:', scores['test_score'], 'si are media:', scores['test_score'].mean())\n",
    "\n",
    "    print ('F1 pentru setul de antrenare este:', scores_f['train_score'], 'si are media', scores_f['train_score'].mean())\n",
    "    print ('F1 pentru setul de testare este:', scores_f['test_score'], 'si are media', scores_f['test_score'].mean())\n",
    "    \n",
    "#      for i in range(5):\n",
    "#         X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3, random_state=i)\n",
    "        \n",
    "#         model = GaussianNB()\n",
    "#         model.fit(X_train, y_train)\n",
    "      \n",
    "#         y_predicated_train = model.predict(X_train)\n",
    "#         y_predicated_test = model.predict(X_test)\n",
    "    \n",
    "#         print (\"Iteration: \", i)\n",
    "#         print (\"Train score:\", model.score(X_train, y_train)*100)\n",
    "#         print (\"Test score:\", model.score(X_test, y_test)*100)\n",
    "#         print (\"Different outputs train:\", sum(y_predicated_train != y_train), \"from total of\", len(y_train))\n",
    "#         print (\"Different outputs test:\", sum(y_predicated_test != y_test), \"from total of\", len(y_test))\n",
    "#         print (\"Accuracy train:\", metrics.accuracy_score(y_train, y_predicated_train)*100)\n",
    "#         # average='micro' Calculate metrics globally by counting the total true positives, false negatives and false positives.\n",
    "#         print (\"F1-score train:\", metrics.f1_score(y_train, y_predicated_train, average='micro')*100)\n",
    "#         print (\"Accuracy test:\", metrics.accuracy_score(y_test, y_predicated_test)*100)\n",
    "#         print (\"F1-score test:\", metrics.f1_score(y_test, y_predicated_test, average='micro')*100)\n",
    "#         print ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuratetea setului de antrenare este: [0.16933446 0.15501264 0.23841618 0.1390059  0.13131313] si are media: 0.16661645945554956\n",
      "Acuratetea setului de testare este: [0.13804714 0.14478114 0.2020202  0.1043771  0.14864865] si are media: 0.14757484757484757\n",
      "F1 pentru setul de antrenare este: [0.20685848 0.17505935 0.20255769 0.13787692 0.14763672] si are media 0.17399783456613466\n",
      "F1 pentru setul de testare este: [0.15451384 0.16579675 0.17967319 0.10006242 0.16623635] si are media 0.15325650959500053\n"
     ]
    }
   ],
   "source": [
    "gaussian_nb_method(x_yeast, y_yeast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuratetea setului de antrenare este: [0.57779515 0.5629398  0.56606724 0.56137608 0.565625  ] si are media: 0.5667606528537921\n",
      "Acuratetea setului de testare este: [0.5125    0.46875   0.58125   0.49375   0.5862069] si are media: 0.5284913793103448\n",
      "F1 pentru setul de antrenare este: [0.58295396 0.56202501 0.56398573 0.56140101 0.56702308] si are media 0.5674777562235395\n",
      "F1 pentru setul de testare este: [0.5143785  0.46755027 0.57605361 0.49545849 0.58298556] si are media 0.527285282479964\n"
     ]
    }
   ],
   "source": [
    "gaussian_nb_method(x_wine, y_wine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuratetea setului de antrenare este: [0.80598958 0.79323797 0.8023407  0.80884265 0.79583875] si are media: 0.8012499322713481\n",
      "Acuratetea setului de testare este: [0.77720207 0.80729167 0.79166667 0.77083333 0.81770833] si are media: 0.7929404145077721\n",
      "F1 pentru setul de antrenare este: [0.80623946 0.79351515 0.80260838 0.80904691 0.79607415] si are media 0.8014968122005328\n",
      "F1 pentru setul de testare este: [0.77687625 0.80679471 0.79193841 0.77113225 0.81787205] si are media 0.7929227334573341\n"
     ]
    }
   ],
   "source": [
    "gaussian_nb_method(x_mammographic, y_mammographic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yeast 55\n",
    "<br>Wine Red ?\n",
    "<br>Breast Cancer 75\n",
    "<br>Primary tumor 48"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>Ex3:</font> Documentati in jupyter notebook fiecare din modelele folosite, in limba romana. Daca acelasi algoritm e folosit pentru mai multe seturi de date, puteti face o sectiune separata cu documentarea algoritmilor + trimitere la algoritm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GaussianNB\n",
    "<br>\n",
    "<br>\n",
    "<br>Acest tip de clasificare este foarte simplu, de aceea pentru seturile noastre de date obtinem un rezultat bun pentru setul de date breast_cancer, intrucat acesta se imparte in doua clase(no-recurrence-events si recurrence-events).\n",
    "<br>Pentru celelalte seturi de date rezultatul este evident, intrucat celelalte seturi de date au in jur de 10 clase.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Decision Tree Classifier\n",
    "<br>\n",
    "<br>\n",
    "<br>Aceasta metoda poate clasifica atat doua clase cat si mai multe clase intr-un dataset.\n",
    "<br>\n",
    "<br>Parametri:\n",
    "<br>splitter-> reprezinta strategia aleasa pentru divizarea nodurilor\n",
    "<br>max_depth-> reprezinta adancimea arborelui\n",
    "<br>min_samples_split-> nr minim de sample-uri necesare \n",
    "<br>min_samples_leaf-> nr minim de sample-uri necesare ca un nod sa fie frunza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier\n",
    "<br>\n",
    "<br>\n",
    "<br>Aceasta metoda foloseste o padure de arbori de decizie random.\n",
    "<br>Are ca scop controlul fenomenului de overfitting.\n",
    "<br>\n",
    "<br>Parametri:\n",
    "<br>n_estimators-> nr de arbori din padure\n",
    "<br>max_depth-> adancimea arborelui \n",
    "<br>min_samples_split-> nr de sample-uri necesare unui nod pentru a se face split\n",
    "<br>min_samples_leaf-> nr minim de sample-uri necesare ca un nod sa fie frunza\n",
    "<br>si altele\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>Observatii:\n",
    "<br>n_estimators-> nu produce overfitting daca crestem nr de arbori \n",
    "<br>max_features-> cu cat e mai mic cu atat evitam overfitting-ul, dar daca e prea mic reteaua face undefitting\n",
    "<br>max_depth-> are un rol important, reduce complexitatea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-layer Perceptron classifier\n",
    "<br>\n",
    "<br>\n",
    "<br>Acest model optimizeazÄƒ funcÈ›ia log-loss folosind LBFGS sau descendenÈ›Äƒ de gradient stocastic.\n",
    "<br>AceastÄƒ implementare funcÈ›ioneazÄƒ cu date reprezentate ca tablouri numpy dense sau tablouri scipy slabe de valori Ã®n virgulÄƒ mobilÄƒ.\n",
    "<br>\n",
    "<br>Parametri:\n",
    "<br>hidden_layer_sizes ->  numÄƒrul de neuroni din stratul ascuns\n",
    "<br>activation -> funcÈ›ie de activare\n",
    "<br>solver ->  pentru optimizarea ponderilor\n",
    "<br>alpha -> parametrul de penalizare L2\n",
    "<br>batch_size -> dimensiunea minibatches-urilor pentru optimizarea stocastica\n",
    "<br>learning_rate -> rata de Ã®nvÄƒÈ›are pentru actualizÄƒri de ponderi\n",
    "<br>learning_rate_init -> rata iniÈ›ialÄƒ de Ã®nvÄƒÈ›are\n",
    "<br>power_t -> exponent pentru scalare inversÄƒ a ratei de Ã®nvÄƒÈ›are \n",
    "<br>max_iter -> numÄƒrul maxim de iteraÈ›ii\n",
    "<br>shuffle -> amestecare de sample-uri la fiecare iteraÈ›ie\n",
    "<br>random_state -> generatorul de numere aleatorii\n",
    "<br>tol -> toleranÈ›Äƒ pentru optimizare\n",
    "<br>verbose -> printare mesaje de progres Ã®n stdout\n",
    "<br>warm_start -> reutilizaÈ›i soluÈ›ia apelului anterior\n",
    "<br>momentum -> momentum pentru actualizarea descendenÈ›ei gradientului\n",
    "<br>nesterovs_momentum -> momentumul lui Nesterov\n",
    "<br>early_stopping -> va anula automat 10% din datele de instruire È™i va Ã®ncheia antrenarea atunci cÃ¢nd scorul de validare nu se Ã®mbunÄƒtÄƒÈ›eÈ™te \n",
    "<br>validation_fraction -> proportia datelor de antrenare care vor fi rezervate ca set de validare\n",
    "<br>beta_1 -> rata de descompunere exponenÈ›ialÄƒ pentru estimÄƒrile vectorului din primul moment\n",
    "<br>beta_2 -> rata de descompunere exponenÈ›ialÄƒ pentru estimÄƒrile vectorului din al doilea moment\n",
    "<br>epsilon -> valoare pentru stabilitatea numericÄƒ\n",
    "<br>n_iter_no_change -> numÄƒrul maxim de epoci pentru a nu respecta Ã®mbunÄƒtÄƒÈ›irea datÄƒ de tol\n",
    "<br>max_fun -> numÄƒrul maxim de apeluri ale funcÈ›iei de loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GaussianProcessClassifier\n",
    "<br>\n",
    "<br>\n",
    "<br>Este bazatÄƒ pe aproximarea Laplace.\n",
    "<br>\n",
    "<br>Parametri:\n",
    "<br>kernel -> nucleul care specificÄƒ funcÈ›ia de covarianÈ›Äƒ \n",
    "<br>optimizer -> optimizator intern acceptat pentru optimizarea parametrilor nucleului\n",
    "<br>n_restarts_optimizer -> numÄƒrul de reporniri ale optimizatorului pentru gÄƒsirea parametrilor kernel-ului\n",
    "<br>max_iter_predict -> numÄƒrul maxim de iteraÈ›ii din metoda lui Newton\n",
    "<br>warm_start -> soluÈ›ia ultimei iteraÈ›ii Newton este utilizatÄƒ ca iniÈ›ializare pentru urmÄƒtorul apel\n",
    "<br>copy_X_train -> o copie persistentÄƒ a datelor de instruire \n",
    "<br>random_state -> generatorul de numere aleatorii \n",
    "<br>multi_class -> specificÄƒ modul Ã®n care sunt gestionate problemele de clasificare cu mai multe clase\n",
    "<br>n_jobs -> numÄƒrul de joburi utilizate pentru calcul"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNeighborsClassifier\n",
    "<br>\n",
    "<br>\n",
    "<br>Clasificatorul care implementeazÄƒ votul celor mai apropiaÈ›i k vecini.\n",
    "<br>\n",
    "<br>Parametri:\n",
    "<br>n_neighbors -> numÄƒrul de vecini care vor fi folosiÈ›i\n",
    "<br>weights -> funcÈ›ia de ponderi folositÄƒ Ã®n predicÈ›ie\n",
    "<br>algorithm -> algoritmul folosit pentru calcularea vecinilor\n",
    "<br>leaf_size -> dimensiunea frunzelor pentru BallTree sau KDTree\n",
    "<br>p -> parametru de putere pentru metrica Minkowski\n",
    "<br>metric -> distanÈ›a utilizatÄƒ pentru arbore\n",
    "<br>metric_params -> argumente suplimentare pentru funcÈ›ia metricÄƒ\n",
    "<br>n_jobs -> numÄƒrul de joburi utilizate pentru calcul\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C-Support Vector Classification\n",
    "<br>\n",
    "<br>\n",
    "<br>Implementarea se bazeazÄƒ pe libsvm. \n",
    "<br>\n",
    "<br>Parametri:\n",
    "<br>C -> parametrul de regularizare\n",
    "<br>kernel -> nucleul care specificÄƒ funcÈ›ia de covarianÈ›Äƒ \n",
    "<br>degree -> gradul funcÈ›iei nucleului polinomial \n",
    "<br>gamma -> coeficientul de nucleu\n",
    "<br>coef0 -> termen independent Ã®n funcÈ›ia de nucleu\n",
    "<br>shrinking -> foloseÈ™te euristicul micÈ™orat\n",
    "<br>probability -> estimÄƒri de probabilitate\n",
    "<br>tol -> toleranÈ›Äƒ pentru optimizare \n",
    "<br>cache_size -> specificÄƒ dimensiunea memoriei cache a nucleului\n",
    "<br>class_weight -> setaÈ›i parametrul C al clasei i la clasa_pondere[i]*C pentru SVC\n",
    "<br>verbose -> printare mesaje de progres Ã®n stdout \n",
    "<br>max_iter -> numÄƒrul maxim de iteraÈ›ii\n",
    "<br>decision_function_shape -> returneazÄƒ funcÈ›ia de decizie 'ovr' sau 'ovo' Ã®n funcÈ›ie de formÄƒ\n",
    "<br>break_ties -> prezicerea va rupe legÄƒturile Ã®n funcÈ›ie de valorile de Ã®ncredere ale funcÈ›iei de decizie\n",
    "<br>random_state -> generatorul de numere aleatorii "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>Ex4:</font>Pentru fiecare model: efectuati o cautare a hiperparametrilor optimi folosind grid search si random search (cu parametrul cv = 4), folosind 5 fold cross validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "notify_time": "5",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
