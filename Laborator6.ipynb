{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = Magenta> _Lixandru Andreea-Bianca 382\n",
    " <br>   Pepene Adina-Florentina 382_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laborator 6\n",
    "\n",
    "Versiunea 2020-04-01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modele de clasificare\n",
    "\n",
    "Folositi 4 seturi de date pentru probleme de clasificare, plecand de la repository-urile specificate in Cursul 5; de exemplu, [ics.uci.edu](http://archive.ics.uci.edu/ml/datasets.php?format=mat&task=cla&att=&area=&numAtt=&numIns=&type=mvar&sort=nameUp&view=table). Cel putin doua seturi de date sa fie cu valori lipsa. \n",
    "\n",
    "\n",
    "1. (20 puncte) Aplicati o metoda de missing value imputation, unde este cazul; justificati si documentati metoda folosita.\n",
    "1. (numar de modele * numar de seturi de date \\* 1 punct = 20 de puncte) Pentru fiecare set de date aplicati 5 modele de clasificare din scikit learn. Pentru fiecare raportati: acuratete, scorul F1 - a se vedea [sklearn.metrics](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics) - folosind 5 fold cross validation. Raportati mediile rezultatelor atat pentru fold-urile de antrenare, cat si pentru cele de testare. Rularile se vor face cu valori fixate ale hiperparametrilor. \n",
    "1. (numar modele * 4 puncte = 20 puncte) Documentati in jupyter notebook fiecare din modelele folosite, in limba romana. Daca acelasi algoritm e folosit pentru mai multe seturi de date, puteti face o sectiune separata cu documentarea algoritmilor + trimitere la algoritm. \n",
    "1. (numar de modele * numar de seturi de date * 1 punct = 20 de puncte) Raportati performanta fiecarui model, folosind 5 fold cross validation. Pentru fiecare din cele 5 rulari, cautati hiperparametrii optimi folosind 4-fold cross validation. Performanta modelului va fi raportata ca medie a celor  5 rulari. \n",
    "    *Observatie:* la fiecare din cele 5 rulari, hiperparametrii optimi pot diferi, din cauza datelor utilizate pentru antrenare/validare.  \n",
    "\n",
    "Se acorda 20 de puncte din oficiu. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exemple de modele de clasificare:\n",
    "1. [Multi-layer Perceptron classifier](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier)\n",
    "1. [KNN](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier)\n",
    "1. [SVM](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC)\n",
    "1. [Gaussian processes](https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.GaussianProcessClassifier.html#sklearn.gaussian_process.GaussianProcessClassifier)\n",
    "1. [RBF](https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.kernels.RBF.html#sklearn.gaussian_process.kernels.RBF)\n",
    "1. [Decision tree](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier)\n",
    "1. [Random forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier)\n",
    "1. [Gaussian Naive bayes](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html#sklearn.naive_bayes.GaussianNB) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Predare:* \n",
    "1. Fiecare student va depune pe site-ul de elearning fisier Jupyter notebook sau arhiva cu astfel de fisiere; \n",
    "1. In fiecare fisier se specifica numele celor doi studenti care au lucra in echipa. \n",
    "1. Predarea se face in saptamana 13-17 aprilie 2020\n",
    "1. Revedeti formele ulterioare ale acestui document pentru precizari despre: continutul rezultatelor raportate, modalitate de notare."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color= Magenta> Rezolvare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>Ex1:</font> Aplicati o metoda de missing value imputation, unde este cazul; justificati si documentati metoda folosita.\n",
    "<br>\n",
    "><br>Metode posibile:\n",
    "<br>1. Eliminarea liniilor care contin valori nan.\n",
    "<br>2. Eliminarea coloanelor care contin nan.\n",
    "<br>3. Umplerea valorilor nan cu:\n",
    "> -> o valoare constanta\n",
    "><br>-> copierea ultimei valori cunoscute(ffill)\n",
    "><br>-> umplere 'inapoi'(bfill)\n",
    "><br>-> o valoare calculata (ex: media)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Citim seturile de date si ne uitam care dintre ele au valori lipsa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mcg</th>\n",
       "      <th>gvh</th>\n",
       "      <th>alm</th>\n",
       "      <th>mit</th>\n",
       "      <th>erl</th>\n",
       "      <th>pox</th>\n",
       "      <th>vac</th>\n",
       "      <th>nuc</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ADT1_YEAST</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.22</td>\n",
       "      <td>MIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADT2_YEAST</th>\n",
       "      <td>0.43</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.22</td>\n",
       "      <td>MIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADT3_YEAST</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.22</td>\n",
       "      <td>MIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAR2_YEAST</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.22</td>\n",
       "      <td>NUC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AATM_YEAST</th>\n",
       "      <td>0.42</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.22</td>\n",
       "      <td>MIT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             mcg   gvh   alm   mit  erl  pox   vac   nuc class\n",
       "ADT1_YEAST  0.58  0.61  0.47  0.13  0.5  0.0  0.48  0.22   MIT\n",
       "ADT2_YEAST  0.43  0.67  0.48  0.27  0.5  0.0  0.53  0.22   MIT\n",
       "ADT3_YEAST  0.64  0.62  0.49  0.15  0.5  0.0  0.53  0.22   MIT\n",
       "AAR2_YEAST  0.58  0.44  0.57  0.13  0.5  0.0  0.54  0.22   NUC\n",
       "AATM_YEAST  0.42  0.44  0.48  0.54  0.5  0.0  0.48  0.22   MIT"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_yeast = [\"mcg\", \"gvh\", \"alm\", \"mit\", \"erl\", \"pox\", \"vac\", \"nuc\", \"class\"]\n",
    "\n",
    "df_yeast = pd.read_csv('./data/yeast/yeast.data', sep=r\" +\", engine=\"python\", names=names_yeast)\n",
    "\n",
    "df_yeast.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1484 entries, ADT1_YEAST to G6PD_YEAST\n",
      "Data columns (total 9 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   mcg     1484 non-null   float64\n",
      " 1   gvh     1484 non-null   float64\n",
      " 2   alm     1484 non-null   float64\n",
      " 3   mit     1484 non-null   float64\n",
      " 4   erl     1484 non-null   float64\n",
      " 5   pox     1484 non-null   float64\n",
      " 6   vac     1484 non-null   float64\n",
      " 7   nuc     1484 non-null   float64\n",
      " 8   class   1484 non-null   object \n",
      "dtypes: float64(8), object(1)\n",
      "memory usage: 115.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df_yeast.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wine = pd.read_csv('./data/wine/winequality-red.csv', sep=';')\n",
    "\n",
    "df_wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1599 entries, 0 to 1598\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed acidity         1599 non-null   float64\n",
      " 1   volatile acidity      1599 non-null   float64\n",
      " 2   citric acid           1599 non-null   float64\n",
      " 3   residual sugar        1599 non-null   float64\n",
      " 4   chlorides             1599 non-null   float64\n",
      " 5   free sulfur dioxide   1599 non-null   float64\n",
      " 6   total sulfur dioxide  1599 non-null   float64\n",
      " 7   density               1599 non-null   float64\n",
      " 8   pH                    1599 non-null   float64\n",
      " 9   sulphates             1599 non-null   float64\n",
      " 10  alcohol               1599 non-null   float64\n",
      " 11  quality               1599 non-null   int64  \n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 150.0 KB\n"
     ]
    }
   ],
   "source": [
    "df_wine.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BI-RADS</th>\n",
       "      <th>Age</th>\n",
       "      <th>Shape</th>\n",
       "      <th>Margin</th>\n",
       "      <th>Density</th>\n",
       "      <th>Severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>67</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>58</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  BI-RADS Age Shape Margin Density  Severity\n",
       "0       5  67     3      5       3         1\n",
       "1       4  43     1      1       ?         1\n",
       "2       5  58     4      5       3         1\n",
       "3       4  28     1      1       3         0\n",
       "4       5  74     1      5       ?         1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_mammographics = [\"BI-RADS\", \"Age\", \"Shape\", \"Margin\", \"Density\", \"Severity\"]\n",
    "\n",
    "df_mammographics = pd.read_csv('./data/mammographic/mammographic_masses.data', names=names_mammographics)\n",
    "\n",
    "df_mammographics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 961 entries, 0 to 960\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   BI-RADS   959 non-null    object\n",
      " 1   Age       956 non-null    object\n",
      " 2   Shape     930 non-null    object\n",
      " 3   Margin    913 non-null    object\n",
      " 4   Density   885 non-null    object\n",
      " 5   Severity  961 non-null    int64 \n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 45.2+ KB\n"
     ]
    }
   ],
   "source": [
    "'''Valorile din data frame care lipsesc sunt marcate cu '?'.\n",
    "Ca sa putem vedea cate valori lipsesc trebuie sa inlocuim\n",
    "toate valorile '?' cu valoarea nan. '''\n",
    "\n",
    "df_mammographics = df_mammographics.replace('?', np.nan)\n",
    "df_mammographics.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 961 entries, 0 to 960\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   BI-RADS   961 non-null    object\n",
      " 1   Age       961 non-null    object\n",
      " 2   Shape     961 non-null    object\n",
      " 3   Margin    961 non-null    object\n",
      " 4   Density   961 non-null    object\n",
      " 5   Severity  961 non-null    int64 \n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 45.2+ KB\n"
     ]
    }
   ],
   "source": [
    "'''Exista mai multe metode prin care putem umple valorile lipsa \n",
    "am ales umplerea valorilor prin copierea ultimei valori cunoscute.'''\n",
    "\n",
    "df_mammographics = df_mammographics.fillna(method='ffill')\n",
    "\n",
    "df_mammographics.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BI-RADS</th>\n",
       "      <th>Age</th>\n",
       "      <th>Shape</th>\n",
       "      <th>Margin</th>\n",
       "      <th>Density</th>\n",
       "      <th>Severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>67</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>58</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  BI-RADS Age Shape Margin Density  Severity\n",
       "0       5  67     3      5       3         1\n",
       "1       4  43     1      1       3         1\n",
       "2       5  58     4      5       3         1\n",
       "3       4  28     1      1       3         0\n",
       "4       5  74     1      5       3         1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mammographics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BI-RADS</th>\n",
       "      <th>Age</th>\n",
       "      <th>Severity</th>\n",
       "      <th>Shape_1</th>\n",
       "      <th>Shape_2</th>\n",
       "      <th>Shape_3</th>\n",
       "      <th>Shape_4</th>\n",
       "      <th>Margin_1</th>\n",
       "      <th>Margin_2</th>\n",
       "      <th>Margin_3</th>\n",
       "      <th>Margin_4</th>\n",
       "      <th>Margin_5</th>\n",
       "      <th>Density_1</th>\n",
       "      <th>Density_2</th>\n",
       "      <th>Density_3</th>\n",
       "      <th>Density_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  BI-RADS Age  Severity  Shape_1  Shape_2  Shape_3  Shape_4  Margin_1  \\\n",
       "0       5  67         1        0        0        1        0         0   \n",
       "1       4  43         1        1        0        0        0         1   \n",
       "2       5  58         1        0        0        0        1         0   \n",
       "3       4  28         0        1        0        0        0         1   \n",
       "4       5  74         1        1        0        0        0         0   \n",
       "\n",
       "   Margin_2  Margin_3  Margin_4  Margin_5  Density_1  Density_2  Density_3  \\\n",
       "0         0         0         0         1          0          0          1   \n",
       "1         0         0         0         0          0          0          1   \n",
       "2         0         0         0         1          0          0          1   \n",
       "3         0         0         0         0          0          0          1   \n",
       "4         0         0         0         1          0          0          1   \n",
       "\n",
       "   Density_4  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mammographics = pd.get_dummies(df_mammographics, columns=[\"Shape\", \"Margin\", \"Density\"])\n",
    "\n",
    "df_mammographics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mcg</th>\n",
       "      <th>Gvh</th>\n",
       "      <th>Lip</th>\n",
       "      <th>Chg</th>\n",
       "      <th>Aac</th>\n",
       "      <th>Alm1</th>\n",
       "      <th>Alm2</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;null&gt;</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.5</td>\n",
       "      <td>&lt;null&gt;</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.35</td>\n",
       "      <td>cp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.44</td>\n",
       "      <td>cp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.46</td>\n",
       "      <td>cp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.59</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.52</td>\n",
       "      <td>&lt;null&gt;</td>\n",
       "      <td>&lt;null&gt;</td>\n",
       "      <td>cp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.35</td>\n",
       "      <td>cp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Mcg   Gvh   Lip  Chg     Aac    Alm1    Alm2 Class\n",
       "0  <null>  0.29  0.48  0.5  <null>    0.24    0.35    cp\n",
       "1    0.07   0.4  0.48  0.5    0.54    0.35    0.44    cp\n",
       "2    0.56   0.4  0.48  0.5    0.49    0.37    0.46    cp\n",
       "3    0.59  0.49  0.48  0.5    0.52  <null>  <null>    cp\n",
       "4    0.23  0.32  0.48  0.5    0.55    0.25    0.35    cp"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_ecoli = ['Mcg', 'Gvh', 'Lip', 'Chg', 'Aac', 'Alm1', 'Alm2', 'Class']\n",
    "\n",
    "df_ecoli = pd.read_csv('./data/ecoli/ecoli.csv', names = names_ecoli)\n",
    "\n",
    "df_ecoli.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 302 entries, 0 to 301\n",
      "Data columns (total 8 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Mcg     276 non-null    object\n",
      " 1   Gvh     274 non-null    object\n",
      " 2   Lip     267 non-null    object\n",
      " 3   Chg     277 non-null    object\n",
      " 4   Aac     278 non-null    object\n",
      " 5   Alm1    260 non-null    object\n",
      " 6   Alm2    271 non-null    object\n",
      " 7   Class   302 non-null    object\n",
      "dtypes: object(8)\n",
      "memory usage: 19.0+ KB\n"
     ]
    }
   ],
   "source": [
    "'''In data set-ul ecoli missing values sunt marcate prin '<null>',\n",
    "nu prin valori NaN, asa ca dorim sa inlocuim  valorile '<null>' cu valori\n",
    "NaN astfel incat sa putem vedea cre sunt valorile necompletate si\n",
    "sa le putem inlocui sau sterge.'''\n",
    "\n",
    "df_ecoli = df_ecoli.replace('<null>', np.nan)\n",
    "df_ecoli.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 302 entries, 0 to 301\n",
      "Data columns (total 8 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Mcg     302 non-null    object\n",
      " 1   Gvh     302 non-null    object\n",
      " 2   Lip     302 non-null    object\n",
      " 3   Chg     302 non-null    object\n",
      " 4   Aac     302 non-null    object\n",
      " 5   Alm1    302 non-null    object\n",
      " 6   Alm2    302 non-null    object\n",
      " 7   Class   302 non-null    object\n",
      "dtypes: object(8)\n",
      "memory usage: 19.0+ KB\n"
     ]
    }
   ],
   "source": [
    "'''Pentru dataset-ul ecoli am ales sa umplem valorile Nan\n",
    "prin copierea urmatoarei valori cunoscute, intrucat am dori sa pastram\n",
    "cat mai multe din liniile si coloanele data set-ului nostru.\n",
    "Pe coloanele care lipsesc valori nu exista o varietate mare de valori,\n",
    "deci putem folosi ultima valoare cunoscuta. Setul de date este aproape\n",
    "complet si nu necesita multe adaugari.'''\n",
    "\n",
    "df_ecoli = df_ecoli.fillna(method='bfill')\n",
    "\n",
    "df_ecoli.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>age</th>\n",
       "      <th>menopause</th>\n",
       "      <th>tumor-size</th>\n",
       "      <th>inv-nodes</th>\n",
       "      <th>node-caps</th>\n",
       "      <th>deg-malig</th>\n",
       "      <th>breast</th>\n",
       "      <th>breast-quad</th>\n",
       "      <th>irradiat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no-recurrence-events</td>\n",
       "      <td>30-39</td>\n",
       "      <td>premeno</td>\n",
       "      <td>30-34</td>\n",
       "      <td>0-2</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "      <td>left</td>\n",
       "      <td>left_low</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no-recurrence-events</td>\n",
       "      <td>40-49</td>\n",
       "      <td>premeno</td>\n",
       "      <td>20-24</td>\n",
       "      <td>0-2</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>right</td>\n",
       "      <td>right_up</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no-recurrence-events</td>\n",
       "      <td>40-49</td>\n",
       "      <td>premeno</td>\n",
       "      <td>20-24</td>\n",
       "      <td>0-2</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>left</td>\n",
       "      <td>left_low</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no-recurrence-events</td>\n",
       "      <td>60-69</td>\n",
       "      <td>ge40</td>\n",
       "      <td>15-19</td>\n",
       "      <td>0-2</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>right</td>\n",
       "      <td>left_up</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no-recurrence-events</td>\n",
       "      <td>40-49</td>\n",
       "      <td>premeno</td>\n",
       "      <td>0-4</td>\n",
       "      <td>0-2</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>right</td>\n",
       "      <td>right_low</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  class    age menopause tumor-size inv-nodes node-caps  \\\n",
       "0  no-recurrence-events  30-39   premeno      30-34       0-2        no   \n",
       "1  no-recurrence-events  40-49   premeno      20-24       0-2        no   \n",
       "2  no-recurrence-events  40-49   premeno      20-24       0-2        no   \n",
       "3  no-recurrence-events  60-69      ge40      15-19       0-2        no   \n",
       "4  no-recurrence-events  40-49   premeno        0-4       0-2        no   \n",
       "\n",
       "   deg-malig breast breast-quad irradiat  \n",
       "0          3   left    left_low       no  \n",
       "1          2  right    right_up       no  \n",
       "2          2   left    left_low       no  \n",
       "3          2  right     left_up       no  \n",
       "4          2  right   right_low       no  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_breast_cancer = [\"class\", \"age\", \"menopause\", \"tumor-size\", \"inv-nodes\", \"node-caps\", \"deg-malig\",\n",
    "                       \"breast\", \"breast-quad\", \"irradiat\"]\n",
    "\n",
    "df_breast_cancer = pd.read_csv('./data/breast_cancer/breast-cancer.data', names=names_breast_cancer)\n",
    "\n",
    "df_breast_cancer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 286 entries, 0 to 285\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   class        286 non-null    object\n",
      " 1   age          286 non-null    object\n",
      " 2   menopause    286 non-null    object\n",
      " 3   tumor-size   286 non-null    object\n",
      " 4   inv-nodes    286 non-null    object\n",
      " 5   node-caps    278 non-null    object\n",
      " 6   deg-malig    286 non-null    int64 \n",
      " 7   breast       286 non-null    object\n",
      " 8   breast-quad  285 non-null    object\n",
      " 9   irradiat     286 non-null    object\n",
      "dtypes: int64(1), object(9)\n",
      "memory usage: 22.5+ KB\n"
     ]
    }
   ],
   "source": [
    "'''In data set-ul breast_cancer missing values sunt marcate prin '?',\n",
    "nu prin valori NaN, asa ca dorim sa inlocuim  valorile '?' cu valori\n",
    "NaN astfel incat sa putem vedea cre sunt valorile necompletate si\n",
    "sa le putem inlocui sau sterge.'''\n",
    "\n",
    "df_breast_cancer = df_breast_cancer.replace('?', np.nan)\n",
    "df_breast_cancer.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>histologic-type</th>\n",
       "      <th>degree-of-diffe</th>\n",
       "      <th>bone</th>\n",
       "      <th>bone-marrow</th>\n",
       "      <th>lung</th>\n",
       "      <th>pleura</th>\n",
       "      <th>peritoneum</th>\n",
       "      <th>liver</th>\n",
       "      <th>brain</th>\n",
       "      <th>skin</th>\n",
       "      <th>neck</th>\n",
       "      <th>supraclavicular</th>\n",
       "      <th>axillar</th>\n",
       "      <th>mediastinum</th>\n",
       "      <th>abdomnial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>?</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>?</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>?</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>?</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  age sex histologic-type degree-of-diffe  bone  bone-marrow  lung  \\\n",
       "0      1    1   1               ?               3     2            2     1   \n",
       "1      1    1   1               ?               3     2            2     2   \n",
       "2      1    1   2               2               3     1            2     2   \n",
       "3      1    1   2               ?               3     1            2     1   \n",
       "4      1    1   2               ?               3     1            2     1   \n",
       "\n",
       "   pleura  peritoneum  liver  brain skin  neck  supraclavicular axillar  \\\n",
       "0       2           2      2      2    2     2                2       2   \n",
       "1       2           2      1      2    2     2                1       2   \n",
       "2       2           2      2      2    2     2                2       2   \n",
       "3       1           2      2      2    2     2                2       2   \n",
       "4       1           2      2      2    2     2                2       2   \n",
       "\n",
       "   mediastinum  abdomnial  \n",
       "0            2          2  \n",
       "1            1          2  \n",
       "2            1          2  \n",
       "3            1          2  \n",
       "4            1          2  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_primary_tumor =[\"class\",\"age\",\"sex\",\"histologic-type\",\"degree-of-diffe\",\"bone\",\"bone-marrow\",\"lung\",\n",
    "                     \"pleura\",\"peritoneum\",\"liver\",\"brain\",\"skin\",\"neck\",\"supraclavicular\",\"axillar\",\"mediastinum\",\"abdomnial\"]\n",
    "\n",
    "df_primary_tumor = pd.read_csv(\"./data/primary_tumor/primary-tumor.data\", names=names_primary_tumor)\n",
    "\n",
    "df_primary_tumor.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 339 entries, 0 to 338\n",
      "Data columns (total 18 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   class            339 non-null    int64 \n",
      " 1   age              339 non-null    int64 \n",
      " 2   sex              338 non-null    object\n",
      " 3   histologic-type  272 non-null    object\n",
      " 4   degree-of-diffe  184 non-null    object\n",
      " 5   bone             339 non-null    int64 \n",
      " 6   bone-marrow      339 non-null    int64 \n",
      " 7   lung             339 non-null    int64 \n",
      " 8   pleura           339 non-null    int64 \n",
      " 9   peritoneum       339 non-null    int64 \n",
      " 10  liver            339 non-null    int64 \n",
      " 11  brain            339 non-null    int64 \n",
      " 12  skin             338 non-null    object\n",
      " 13  neck             339 non-null    int64 \n",
      " 14  supraclavicular  339 non-null    int64 \n",
      " 15  axillar          338 non-null    object\n",
      " 16  mediastinum      339 non-null    int64 \n",
      " 17  abdomnial        339 non-null    int64 \n",
      "dtypes: int64(13), object(5)\n",
      "memory usage: 47.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df_primary_tumor = df_primary_tumor.replace('?', np.nan)\n",
    "\n",
    "df_primary_tumor.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 286 entries, 0 to 285\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   class        286 non-null    object\n",
      " 1   age          286 non-null    object\n",
      " 2   menopause    286 non-null    object\n",
      " 3   tumor-size   286 non-null    object\n",
      " 4   inv-nodes    286 non-null    object\n",
      " 5   node-caps    286 non-null    object\n",
      " 6   deg-malig    286 non-null    int64 \n",
      " 7   breast       286 non-null    object\n",
      " 8   breast-quad  286 non-null    object\n",
      " 9   irradiat     286 non-null    object\n",
      "dtypes: int64(1), object(9)\n",
      "memory usage: 22.5+ KB\n"
     ]
    }
   ],
   "source": [
    "'''Pentru dataset-ul breast_cancer am ales sa umplem valorile nan\n",
    "prin copierea ultimei valori cunoscute, intrucat am dori sa pastram\n",
    "cat mai multe din liniile si coloanele data set-ului nostru.\n",
    "Pe coloanele care lipsesc valori nu exista o varietate mare de valori,\n",
    "deci putem folosi ultima valoare cunoscuta. Setul de date este aproape\n",
    "complet si nu necesita multe adaugari.'''\n",
    "\n",
    "df_breast_cancer = df_breast_cancer.fillna(method='ffill')\n",
    "\n",
    "df_breast_cancer.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>node-caps</th>\n",
       "      <th>breast</th>\n",
       "      <th>irradiat</th>\n",
       "      <th>age_20-29</th>\n",
       "      <th>age_30-39</th>\n",
       "      <th>age_40-49</th>\n",
       "      <th>age_50-59</th>\n",
       "      <th>age_60-69</th>\n",
       "      <th>age_70-79</th>\n",
       "      <th>...</th>\n",
       "      <th>inv-nodes_6-8</th>\n",
       "      <th>inv-nodes_9-11</th>\n",
       "      <th>deg-malig_1</th>\n",
       "      <th>deg-malig_2</th>\n",
       "      <th>deg-malig_3</th>\n",
       "      <th>breast-quad_central</th>\n",
       "      <th>breast-quad_left_low</th>\n",
       "      <th>breast-quad_left_up</th>\n",
       "      <th>breast-quad_right_low</th>\n",
       "      <th>breast-quad_right_up</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no-recurrence-events</td>\n",
       "      <td>no</td>\n",
       "      <td>left</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no-recurrence-events</td>\n",
       "      <td>no</td>\n",
       "      <td>right</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no-recurrence-events</td>\n",
       "      <td>no</td>\n",
       "      <td>left</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no-recurrence-events</td>\n",
       "      <td>no</td>\n",
       "      <td>right</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no-recurrence-events</td>\n",
       "      <td>no</td>\n",
       "      <td>right</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  class node-caps breast irradiat  age_20-29  age_30-39  \\\n",
       "0  no-recurrence-events        no   left       no          0          1   \n",
       "1  no-recurrence-events        no  right       no          0          0   \n",
       "2  no-recurrence-events        no   left       no          0          0   \n",
       "3  no-recurrence-events        no  right       no          0          0   \n",
       "4  no-recurrence-events        no  right       no          0          0   \n",
       "\n",
       "   age_40-49  age_50-59  age_60-69  age_70-79  ...  inv-nodes_6-8  \\\n",
       "0          0          0          0          0  ...              0   \n",
       "1          1          0          0          0  ...              0   \n",
       "2          1          0          0          0  ...              0   \n",
       "3          0          0          1          0  ...              0   \n",
       "4          1          0          0          0  ...              0   \n",
       "\n",
       "   inv-nodes_9-11  deg-malig_1  deg-malig_2  deg-malig_3  breast-quad_central  \\\n",
       "0               0            0            0            1                    0   \n",
       "1               0            0            1            0                    0   \n",
       "2               0            0            1            0                    0   \n",
       "3               0            0            1            0                    0   \n",
       "4               0            0            1            0                    0   \n",
       "\n",
       "   breast-quad_left_low  breast-quad_left_up  breast-quad_right_low  \\\n",
       "0                     1                    0                      0   \n",
       "1                     0                    0                      0   \n",
       "2                     1                    0                      0   \n",
       "3                     0                    1                      0   \n",
       "4                     0                    0                      1   \n",
       "\n",
       "   breast-quad_right_up  \n",
       "0                     0  \n",
       "1                     1  \n",
       "2                     0  \n",
       "3                     0  \n",
       "4                     0  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_breast_cancer_2 = pd.get_dummies(df_breast_cancer, columns=[\"age\", \"menopause\", \"tumor-size\", \"inv-nodes\", \"deg-malig\",\n",
    "                                                              \"breast-quad\"])\n",
    "\n",
    "df_breast_cancer_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 339 entries, 0 to 338\n",
      "Data columns (total 18 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   class            339 non-null    int64  \n",
      " 1   age              339 non-null    int64  \n",
      " 2   sex              339 non-null    float64\n",
      " 3   histologic-type  339 non-null    float64\n",
      " 4   degree-of-diffe  339 non-null    float64\n",
      " 5   bone             339 non-null    int64  \n",
      " 6   bone-marrow      339 non-null    int64  \n",
      " 7   lung             339 non-null    int64  \n",
      " 8   pleura           339 non-null    int64  \n",
      " 9   peritoneum       339 non-null    int64  \n",
      " 10  liver            339 non-null    int64  \n",
      " 11  brain            339 non-null    int64  \n",
      " 12  skin             339 non-null    float64\n",
      " 13  neck             339 non-null    int64  \n",
      " 14  supraclavicular  339 non-null    int64  \n",
      " 15  axillar          339 non-null    float64\n",
      " 16  mediastinum      339 non-null    int64  \n",
      " 17  abdomnial        339 non-null    int64  \n",
      "dtypes: float64(5), int64(13)\n",
      "memory usage: 47.8 KB\n"
     ]
    }
   ],
   "source": [
    "'''Pentru dataset-ul primary_tumor am ales sa umplem valorile lipsa\n",
    "cu media de pe coloana, intrucat am observat ca lipsesc multe valori \n",
    "de pe aceeasi coloana, deci nu putem avea o evidenta clara asupra\n",
    "datelor anterioare. Totusi, nu putem decide inca daca renuntam\n",
    "la coloana digree-of-diffe. Ramane de vazut...'''\n",
    "\n",
    "df_primary_tumor = df_primary_tumor.apply(lambda x: pd.to_numeric(x), axis=0)\n",
    "\n",
    "df_primary_tumor = df_primary_tumor.fillna(round(df_primary_tumor.mean()))\n",
    "\n",
    "df_primary_tumor.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>Ex2:</font> Pentru fiecare set de date aplicati 5 modele de clasificare din scikit learn. Pentru fiecare raportati: acuratete, scorul F1 - a se vedea sklearn.metrics - folosind 5 fold cross validation. Raportati mediile rezultatelor atat pentru fold-urile de antrenare, cat si pentru cele de testare. Rularile se vor face cu valori fixate ale hiperparametrilor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trebuie sa separam datele in date de intrare si date de iesire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mcg</th>\n",
       "      <th>gvh</th>\n",
       "      <th>alm</th>\n",
       "      <th>mit</th>\n",
       "      <th>erl</th>\n",
       "      <th>pox</th>\n",
       "      <th>vac</th>\n",
       "      <th>nuc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ADT1_YEAST</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADT2_YEAST</th>\n",
       "      <td>0.43</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADT3_YEAST</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAR2_YEAST</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AATM_YEAST</th>\n",
       "      <td>0.42</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             mcg   gvh   alm   mit  erl  pox   vac   nuc\n",
       "ADT1_YEAST  0.58  0.61  0.47  0.13  0.5  0.0  0.48  0.22\n",
       "ADT2_YEAST  0.43  0.67  0.48  0.27  0.5  0.0  0.53  0.22\n",
       "ADT3_YEAST  0.64  0.62  0.49  0.15  0.5  0.0  0.53  0.22\n",
       "AAR2_YEAST  0.58  0.44  0.57  0.13  0.5  0.0  0.54  0.22\n",
       "AATM_YEAST  0.42  0.44  0.48  0.54  0.5  0.0  0.48  0.22"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_yeast = df_yeast[[\"mcg\", \"gvh\", \"alm\", \"mit\", \"erl\", \"pox\", \"vac\", \"nuc\"]]\n",
    "y_yeast = df_yeast[\"class\"]\n",
    "\n",
    "x_yeast.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ADT1_YEAST    MIT\n",
       "ADT2_YEAST    MIT\n",
       "ADT3_YEAST    MIT\n",
       "AAR2_YEAST    NUC\n",
       "AATM_YEAST    MIT\n",
       "Name: class, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_yeast.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  \n",
       "0      9.4  \n",
       "1      9.8  \n",
       "2      9.8  \n",
       "3      9.8  \n",
       "4      9.4  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_wine = df_wine [[\"fixed acidity\", \"volatile acidity\", \"citric acid\", \"residual sugar\", \"chlorides\", \n",
    "                   \"free sulfur dioxide\", \"total sulfur dioxide\", \"density\", \"pH\", \"sulphates\", \"alcohol\"]]\n",
    "y_wine = df_wine[\"quality\"]\n",
    "\n",
    "x_wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5\n",
       "1    5\n",
       "2    5\n",
       "3    6\n",
       "4    5\n",
       "Name: quality, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mammographic = df_mammographics[[\"BI-RADS\",\"Age\",\n",
    "                                   \"Shape_1\",\"Shape_2\",\"Shape_3\",\"Shape_4\",\n",
    "                                   \"Margin_1\",\"Margin_2\",\"Margin_3\",\"Margin_4\",\"Margin_5\",\n",
    "                                   \"Density_1\",\"Density_2\", \"Density_3\", \"Density_4\"]]\n",
    "\n",
    "y_mammographic = df_mammographics[\"Severity\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mcg</th>\n",
       "      <th>Gvh</th>\n",
       "      <th>Lip</th>\n",
       "      <th>Chg</th>\n",
       "      <th>Aac</th>\n",
       "      <th>Alm1</th>\n",
       "      <th>Alm2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.59</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Mcg   Gvh   Lip  Chg   Aac  Alm1  Alm2\n",
       "0  0.07  0.29  0.48  0.5  0.54  0.24  0.35\n",
       "1  0.07   0.4  0.48  0.5  0.54  0.35  0.44\n",
       "2  0.56   0.4  0.48  0.5  0.49  0.37  0.46\n",
       "3  0.59  0.49  0.48  0.5  0.52  0.37  0.46\n",
       "4  0.23  0.32  0.48  0.5  0.55  0.25  0.35"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_ecoli = df_ecoli[['Mcg', 'Gvh', 'Lip', 'Chg', 'Aac', 'Alm1', 'Alm2']]\n",
    "\n",
    "y_ecoli = df_ecoli['Class']\n",
    "\n",
    "x_ecoli.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_breast_cancer [['30-39' 'premeno' '30-34' '0-2' 'no' 3 'left' 'left_low' 'no']\n",
      " ['40-49' 'premeno' '20-24' '0-2' 'no' 2 'right' 'right_up' 'no']\n",
      " ['40-49' 'premeno' '20-24' '0-2' 'no' 2 'left' 'left_low' 'no']\n",
      " ['60-69' 'ge40' '15-19' '0-2' 'no' 2 'right' 'left_up' 'no']\n",
      " ['40-49' 'premeno' '0-4' '0-2' 'no' 2 'right' 'right_low' 'no']\n",
      " ['60-69' 'ge40' '15-19' '0-2' 'no' 2 'left' 'left_low' 'no']\n",
      " ['50-59' 'premeno' '25-29' '0-2' 'no' 2 'left' 'left_low' 'no']\n",
      " ['60-69' 'ge40' '20-24' '0-2' 'no' 1 'left' 'left_low' 'no']\n",
      " ['40-49' 'premeno' '50-54' '0-2' 'no' 2 'left' 'left_low' 'no']\n",
      " ['40-49' 'premeno' '20-24' '0-2' 'no' 2 'right' 'left_up' 'no']\n",
      " ['40-49' 'premeno' '0-4' '0-2' 'no' 3 'left' 'central' 'no']\n",
      " ['50-59' 'ge40' '25-29' '0-2' 'no' 2 'left' 'left_low' 'no']\n",
      " ['60-69' 'lt40' '10-14' '0-2' 'no' 1 'left' 'right_up' 'no']\n",
      " ['50-59' 'ge40' '25-29' '0-2' 'no' 3 'left' 'right_up' 'no']\n",
      " ['40-49' 'premeno' '30-34' '0-2' 'no' 3 'left' 'left_up' 'no']\n",
      " ['60-69' 'lt40' '30-34' '0-2' 'no' 1 'left' 'left_low' 'no']\n",
      " ['40-49' 'premeno' '15-19' '0-2' 'no' 2 'left' 'left_low' 'no']\n",
      " ['50-59' 'premeno' '30-34' '0-2' 'no' 3 'left' 'left_low' 'no']\n",
      " ['60-69' 'ge40' '30-34' '0-2' 'no' 3 'left' 'left_low' 'no']\n",
      " ['50-59' 'ge40' '30-34' '0-2' 'no' 1 'right' 'right_up' 'no']]\n",
      "Y_breast_cancer ['no-recurrence-events' 'no-recurrence-events' 'no-recurrence-events'\n",
      " 'no-recurrence-events' 'no-recurrence-events' 'no-recurrence-events'\n",
      " 'no-recurrence-events' 'no-recurrence-events' 'no-recurrence-events'\n",
      " 'no-recurrence-events' 'no-recurrence-events' 'no-recurrence-events'\n",
      " 'no-recurrence-events' 'no-recurrence-events' 'no-recurrence-events'\n",
      " 'no-recurrence-events' 'no-recurrence-events' 'no-recurrence-events'\n",
      " 'no-recurrence-events' 'no-recurrence-events']\n"
     ]
    }
   ],
   "source": [
    "x_breast_cancer = df_breast_cancer[[\"age\", \"menopause\", \"tumor-size\", \"inv-nodes\", \"node-caps\", \"deg-malig\", \"breast\", \n",
    "                                    \"breast-quad\", \"irradiat\"]].to_numpy()\n",
    "y_breast_cancer = df_breast_cancer[\"class\"].to_numpy()\n",
    "\n",
    "print(\"X_breast_cancer\", x_breast_cancer[:20, :])\n",
    "print(\"Y_breast_cancer\", y_breast_cancer[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_primary_tumor [[1. 1. 2. 3. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
      " [1. 1. 2. 3. 2. 2. 2. 2. 2. 1. 2. 2. 2. 1. 2. 1. 2.]\n",
      " [1. 2. 2. 3. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2.]\n",
      " [1. 2. 2. 3. 1. 2. 1. 1. 2. 2. 2. 2. 2. 2. 2. 1. 2.]\n",
      " [1. 2. 2. 3. 1. 2. 1. 1. 2. 2. 2. 2. 2. 2. 2. 1. 2.]\n",
      " [1. 2. 2. 3. 1. 2. 2. 2. 2. 2. 1. 2. 2. 1. 1. 1. 2.]\n",
      " [2. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 1. 1. 1. 2. 2. 2.]\n",
      " [2. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
      " [2. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2.]\n",
      " [2. 1. 1. 2. 1. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 2.]\n",
      " [2. 1. 1. 3. 1. 2. 2. 1. 2. 2. 2. 2. 2. 1. 2. 1. 2.]\n",
      " [2. 1. 1. 3. 1. 2. 2. 2. 2. 2. 2. 1. 2. 2. 1. 2. 2.]\n",
      " [2. 1. 1. 3. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
      " [2. 1. 1. 3. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
      " [2. 1. 1. 3. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 1. 2.]\n",
      " [2. 1. 1. 2. 2. 2. 2. 1. 2. 1. 2. 2. 2. 2. 2. 2. 2.]\n",
      " [2. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 1. 2.]\n",
      " [2. 1. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2.]\n",
      " [2. 1. 2. 3. 1. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2.]\n",
      " [2. 1. 2. 3. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 1. 2.]]\n",
      "Y_primary_tumor [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "x_primary_tumor = df_primary_tumor[[\"age\", \"sex\", \"histologic-type\", \"degree-of-diffe\", \"bone\", \"bone-marrow\", \"lung\",\n",
    "                     \"pleura\", \"peritoneum\", \"liver\", \"brain\", \"skin\", \"neck\", \"supraclavicular\", \"axillar\", \n",
    "                    \"mediastinum\", \"abdomnial\"]].to_numpy()\n",
    "y_primary_tumor = df_primary_tumor[\"class\"].to_numpy()\n",
    "\n",
    "print(\"X_primary_tumor\", x_primary_tumor[:20, :])\n",
    "print(\"Y_primary_tumor\", y_primary_tumor[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separam setul de date in set de antrenare si set de testare.\n",
    "<br> Cand folosim random state facem un random mai stabil."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color= magenta> A. Algoritmi care nu necesita scalarea datelor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color= magenta> 1. DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree_method(X, y) -> None:\n",
    "    \n",
    "    model = DecisionTreeClassifier(max_depth=5, min_samples_leaf=15)\n",
    "        \n",
    "    scores = cross_validate(model, X, y, cv=5, scoring=['accuracy','f1_weighted'], return_train_score=True)\n",
    "    \n",
    "    print ('Acuratetea setului de antrenare este:', scores['train_accuracy'],\n",
    "           'si are media:', scores['train_accuracy'].mean())\n",
    "    print ('Acuratetea setului de testare este:', scores['test_accuracy'],\n",
    "           'si are media:', scores['test_accuracy'].mean())\n",
    "    \n",
    "    print ('F1 pentru setul de antrenare este:', scores['train_f1_weighted'],\n",
    "           'si are media', scores['train_f1_weighted'].mean())\n",
    "    print ('F1 pentru setul de testare este:', scores['test_f1_weighted'],\n",
    "           'si are media', scores['test_f1_weighted'].mean())\n",
    "    \n",
    "#      for i in range(5):\n",
    "#         X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3, random_state=i)\n",
    "        \n",
    "#         model = DecisionTreeClassifier(max_depth=5, min_samples_leaf=15)\n",
    "#         model.fit(X_train, y_train)\n",
    "       \n",
    "#         y_predicated_train = model.predict(X_train)\n",
    "#         y_predicated_test = model.predict(X_test)\n",
    "    \n",
    "#         print (\"Iteration: \", i)\n",
    "#         print (\"Train score:\", model.score(X_train, y_train)*100)\n",
    "#         print (\"Test score:\", model.score(X_test, y_test)*100)\n",
    "#         print (\"Different outputs train:\", sum(y_predicated_train != y_train), \"from total of\", len(y_train))\n",
    "#         print (\"Different outputs test:\", sum(y_predicated_test != y_test), \"from total of\", len(y_test))\n",
    "#         print (\"Accuracy train:\", metrics.accuracy_score(y_train, y_predicated_train)*100)\n",
    "#         # average='micro' Calculate metrics globally by counting the total true positives, false negatives and false positives.\n",
    "#         print (\"F1-score train:\", metrics.f1_score(y_train, y_predicated_train, average='micro')*100)\n",
    "#         print (\"Accuracy test:\", metrics.accuracy_score(y_test, y_predicated_test)*100)\n",
    "#         print (\"F1-score test:\", metrics.f1_score(y_test, y_predicated_test, average='micro')*100)\n",
    "#         print ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuratetea setului de antrenare este: [0.61836563 0.61920809 0.60994103 0.63100253 0.61700337] si are media: 0.6191041274866043\n",
      "Acuratetea setului de testare este: [0.60606061 0.57239057 0.56228956 0.53872054 0.56756757] si are media: 0.5694057694057694\n",
      "F1 pentru setul de antrenare este: [0.60269116 0.59670385 0.59136236 0.61577814 0.59557764] si are media 0.6004226305634168\n",
      "F1 pentru setul de testare este: [0.59267024 0.55168132 0.53780771 0.52466963 0.54820681] si are media 0.5510071424486854\n"
     ]
    }
   ],
   "source": [
    "decision_tree_method(x_yeast, y_yeast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuratetea setului de antrenare este: [0.65050821 0.65050821 0.65129007 0.66692729 0.6671875 ] si are media: 0.6572842552775606\n",
      "Acuratetea setului de testare este: [0.5125     0.4875     0.565625   0.55625    0.57366771] si are media: 0.5391085423197493\n",
      "F1 pentru setul de antrenare este: [0.62895952 0.62114804 0.63520597 0.63780948 0.64974681] si are media 0.6345739624252036\n",
      "F1 pentru setul de testare este: [0.46757743 0.4678346  0.55057509 0.53259325 0.55862606] si are media 0.5154412843722398\n"
     ]
    }
   ],
   "source": [
    "decision_tree_method(x_wine, y_wine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuratetea setului de antrenare este: [0.84765625 0.83875163 0.83224967 0.85695709 0.84915475] si are media: 0.8449538767880365\n",
      "Acuratetea setului de testare este: [0.8238342  0.84895833 0.86979167 0.796875   0.8125    ] si are media: 0.8303918393782382\n",
      "F1 pentru setul de antrenare este: [0.84707059 0.83891629 0.83109108 0.85711622 0.84912447] si are media 0.8446637289495176\n",
      "F1 pentru setul de testare este: [0.82347124 0.84835523 0.8694528  0.79712312 0.80697028] si are media 0.8290745357062399\n"
     ]
    }
   ],
   "source": [
    "decision_tree_method(x_mammographic, y_mammographic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuratetea setului de antrenare este: [0.84647303 0.84232365 0.8553719  0.85123967 0.85123967] si are media: 0.8493295840334694\n",
      "Acuratetea setului de testare este: [0.80327869 0.83606557 0.83333333 0.81666667 0.83333333] si are media: 0.8245355191256831\n",
      "F1 pentru setul de antrenare este: [0.83420591 0.8273433  0.83889488 0.83980311 0.83708865] si are media 0.8354671702586612\n",
      "F1 pentru setul de testare este: [0.79477318 0.82533532 0.82522039 0.79007902 0.80526224] si are media 0.8081340301166875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adina\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "decision_tree_method(x_ecoli, y_ecoli)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color= magenta> 2. RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_method(X, y, max_depth, min_samples_leaf) -> None:\n",
    "    \n",
    "    model = RandomForestClassifier(max_depth=max_depth, min_samples_leaf=min_samples_leaf)\n",
    "        \n",
    "    scores = cross_validate(model, X, y, cv=5, scoring=['accuracy','f1_weighted'], return_train_score=True)\n",
    "    \n",
    "    print ('Acuratetea setului de antrenare este:', scores['train_accuracy'],\n",
    "           'si are media:', scores['train_accuracy'].mean())\n",
    "    print ('Acuratetea setului de testare este:', scores['test_accuracy'],\n",
    "           'si are media:', scores['test_accuracy'].mean())\n",
    "    \n",
    "    print ('F1 pentru setul de antrenare este:', scores['train_f1_weighted'],\n",
    "           'si are media', scores['train_f1_weighted'].mean())\n",
    "    print ('F1 pentru setul de testare este:', scores['test_f1_weighted'],\n",
    "           'si are media', scores['test_f1_weighted'].mean())\n",
    "    \n",
    "#     for i in range(5):\n",
    "#         X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3, random_state=i)\n",
    "        \n",
    "#         model = RandomForestClassifier(max_depth=max_depth, min_samples_leaf=min_samples_leaf)\n",
    "#         model.fit(X_train, y_train)\n",
    "       \n",
    "#         y_predicated_train = model.predict(X_train)\n",
    "#         y_predicated_test = model.predict(X_test)\n",
    "    \n",
    "#         print (\"Train score:\", model.score(X_train, y_train)*100)\n",
    "#         print (\"Test score:\", model.score(X_test, y_test)*100)\n",
    "#         print (\"Different outputs train:\", sum(y_predicated_train != y_train), \"from total of\", len(y_train))\n",
    "#         print (\"Different outputs test:\", sum(y_predicated_test != y_test), \"from total of\", len(y_test))\n",
    "#         print (\"Accuracy train:\", metrics.accuracy_score(y_train, y_predicated_train)*100)\n",
    "#         # average='micro' Calculate metrics globally by counting the total true positives, false negatives and false positives.\n",
    "#         print (\"F1-score train:\", metrics.f1_score(y_train, y_predicated_train, average='micro')*100)\n",
    "#         print (\"Accuracy test:\", metrics.accuracy_score(y_test, y_predicated_test)*100)\n",
    "#         print (\"F1-score test:\", metrics.f1_score(y_test, y_predicated_test, average='micro')*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuratetea setului de antrenare este: [0.61415333 0.62931761 0.62426285 0.63268745 0.63047138] si are media: 0.6261785220925912\n",
      "Acuratetea setului de testare este: [0.5959596  0.57575758 0.63636364 0.52525253 0.625     ] si are media: 0.5916666666666666\n",
      "F1 pentru setul de antrenare este: [0.59677525 0.61339011 0.61024938 0.61879942 0.61375063] si are media 0.6105929569452889\n",
      "F1 pentru setul de testare este: [0.57529282 0.56049921 0.61861787 0.51613937 0.60269501] si are media 0.5746488553387981\n"
     ]
    }
   ],
   "source": [
    "random_forest_method(x_yeast, y_yeast, 4, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuratetea setului de antrenare este: [0.62001564 0.61767005 0.61063331 0.62939797 0.61171875] si are media: 0.6178871432759969\n",
      "Acuratetea setului de testare este: [0.553125   0.54375    0.628125   0.590625   0.59561129] si are media: 0.5822472570532915\n",
      "F1 pentru setul de antrenare este: [0.57778786 0.56780916 0.55789985 0.58432637 0.55673667] si are media 0.5689119809462655\n",
      "F1 pentru setul de testare este: [0.47916962 0.49338165 0.56609025 0.55792188 0.54152059] si are media 0.5276168002127497\n"
     ]
    }
   ],
   "source": [
    "random_forest_method(x_wine, y_wine, 3, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuratetea setului de antrenare este: [0.83723958 0.82704811 0.82054616 0.84005202 0.85045514] si are media: 0.8350682027524925\n",
      "Acuratetea setului de testare este: [0.79792746 0.82291667 0.84895833 0.80208333 0.80729167] si are media: 0.8158354922279794\n",
      "F1 pentru setul de antrenare este: [0.83745596 0.82723292 0.82078695 0.84025694 0.85049631] si are media 0.8352458146888095\n",
      "F1 pentru setul de testare este: [0.79784006 0.82233966 0.84915937 0.80234129 0.80446301] si are media 0.8152286773885293\n"
     ]
    }
   ],
   "source": [
    "random_forest_method(x_mammographic, y_mammographic, 5, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adina\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuratetea setului de antrenare este: [0.77178423 0.75103734 0.77272727 0.75619835 0.77272727] si are media: 0.7648948938650937\n",
      "Acuratetea setului de testare este: [0.73770492 0.7704918  0.76666667 0.76666667 0.68333333] si are media: 0.7449726775956285\n",
      "F1 pentru setul de antrenare este: [0.70331018 0.67093556 0.71876271 0.67976395 0.69330767] si are media 0.6932160160100219\n",
      "F1 pentru setul de testare este: [0.65754664 0.69823922 0.70913992 0.68363636 0.60277778] si are media 0.6702679834896843\n"
     ]
    }
   ],
   "source": [
    "random_forest_method(x_ecoli, y_ecoli, 2, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=magenta> B. Algoritmi care necesita scalarea datelor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pentru urmatoarele metode de clasificare vom scala datele."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      fixed acidity  volatile acidity  residual sugar  free sulfur dioxide  \\\n",
      "0          0.247788          0.397260        0.068493             0.140845   \n",
      "1          0.283186          0.520548        0.116438             0.338028   \n",
      "2          0.283186          0.438356        0.095890             0.197183   \n",
      "3          0.584071          0.109589        0.068493             0.225352   \n",
      "4          0.247788          0.397260        0.068493             0.140845   \n",
      "...             ...               ...             ...                  ...   \n",
      "1594       0.141593          0.328767        0.075342             0.436620   \n",
      "1595       0.115044          0.294521        0.089041             0.535211   \n",
      "1596       0.150442          0.267123        0.095890             0.394366   \n",
      "1597       0.115044          0.359589        0.075342             0.436620   \n",
      "1598       0.123894          0.130137        0.184932             0.239437   \n",
      "\n",
      "      total sulfur dioxide        pH   alcohol  \n",
      "0                 0.098940  0.606299  0.153846  \n",
      "1                 0.215548  0.362205  0.215385  \n",
      "2                 0.169611  0.409449  0.215385  \n",
      "3                 0.190813  0.330709  0.215385  \n",
      "4                 0.098940  0.606299  0.153846  \n",
      "...                    ...       ...       ...  \n",
      "1594              0.134276  0.559055  0.323077  \n",
      "1595              0.159011  0.614173  0.430769  \n",
      "1596              0.120141  0.535433  0.400000  \n",
      "1597              0.134276  0.653543  0.276923  \n",
      "1598              0.127208  0.511811  0.400000  \n",
      "\n",
      "[1599 rows x 7 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adina\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "C:\\Users\\adina\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "x_wine.loc[:, [\"fixed acidity\", \"volatile acidity\", \"residual sugar\", \n",
    "                   \"free sulfur dioxide\", \"total sulfur dioxide\", \"pH\", \"alcohol\"]]=scaler.fit_transform(\n",
    "    x_wine.loc[:, [\"fixed acidity\", \"volatile acidity\", \"residual sugar\", \n",
    "                   \"free sulfur dioxide\", \"total sulfur dioxide\", \"pH\", \"alcohol\"]])\n",
    "\n",
    "print (x_wine.loc[:, [\"fixed acidity\", \"volatile acidity\", \"residual sugar\", \n",
    "                   \"free sulfur dioxide\", \"total sulfur dioxide\", \"pH\", \"alcohol\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      BI-RADS       Age\n",
      "0    0.090909  0.628205\n",
      "1    0.072727  0.320513\n",
      "2    0.090909  0.512821\n",
      "3    0.072727  0.128205\n",
      "4    0.090909  0.717949\n",
      "..        ...       ...\n",
      "956  0.072727  0.371795\n",
      "957  0.072727  0.487179\n",
      "958  0.072727  0.589744\n",
      "959  0.090909  0.615385\n",
      "960  0.072727  0.564103\n",
      "\n",
      "[961 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adina\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\pandas\\core\\indexing.py:965: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "scaler_mammographic = MinMaxScaler()\n",
    "\n",
    "x_mammographic.loc[:, [\"BI-RADS\",\"Age\"]] = scaler_mammographic.fit_transform(x_mammographic.loc[:,[\"BI-RADS\",\"Age\"]])\n",
    "print(x_mammographic.loc[:, [\"BI-RADS\",\"Age\"]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=magenta> 1. KNeighbourClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_neighbours_method(X, y, number_of_neighbors) -> None:\n",
    "    \n",
    "    model = KNeighborsClassifier(n_neighbors=number_of_neighbors)\n",
    "    \n",
    "    scores = cross_validate(model, X, y, cv=5, scoring=['accuracy','f1_weighted'], return_train_score=True)\n",
    "    \n",
    "    print ('Acuratetea setului de antrenare este:', scores['train_accuracy'],\n",
    "           'si are media:', scores['train_accuracy'].mean())\n",
    "    print ('Acuratetea setului de testare este:', scores['test_accuracy'],\n",
    "           'si are media:', scores['test_accuracy'].mean())\n",
    "    \n",
    "    print ('F1 pentru setul de antrenare este:', scores['train_f1_weighted'],\n",
    "           'si are media', scores['train_f1_weighted'].mean())\n",
    "    print ('F1 pentru setul de testare este:', scores['test_f1_weighted'],\n",
    "           'si are media', scores['test_f1_weighted'].mean())\n",
    "\n",
    "#     for i in range(5):\n",
    "#         X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3, random_state=i)\n",
    "    \n",
    "#         model = KNeighborsClassifier(n_neighbors = number_of_neighbors)\n",
    "#         model.fit(X_train, y_train)\n",
    "    \n",
    "#         y_predicated_train = model.predict(X_train)\n",
    "#         y_predicated_test = model.predict(X_test)\n",
    "    \n",
    "#         print (\"Iteration:\", i)\n",
    "#         print (\"Train score:\", model.score(X_train, y_train)*100)\n",
    "#         print (\"Test score:\", model.score(X_test, y_test)*100)\n",
    "#         print (\"Different outputs train:\", sum(y_predicated_train != y_train), \"from total of\", len(y_train))\n",
    "#         print (\"Different outputs test:\", sum(y_predicated_test != y_test), \"from total of\", len(y_test))\n",
    "#         print (\"Accuracy train:\", metrics.accuracy_score(y_train, y_predicated_train)*100)\n",
    "#         # average='micro' Calculate metrics globally by counting the total true positives, false negatives and false positives.\n",
    "#         print (\"F1-score train:\", metrics.f1_score(y_train, y_predicated_train, average='micro')*100)\n",
    "#         print (\"Accuracy test:\", metrics.accuracy_score(y_test, y_predicated_test)*100)\n",
    "#         print (\"F1-score test:\", metrics.f1_score(y_test, y_predicated_test, average='micro')*100)\n",
    "#         print ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuratetea setului de antrenare este: [0.64953665 0.65880371 0.64869419 0.65964617 0.6489899 ] si are media: 0.6531341213312569\n",
      "Acuratetea setului de testare este: [0.54882155 0.56228956 0.5959596  0.53198653 0.60472973] si are media: 0.5687573937573938\n",
      "F1 pentru setul de antrenare este: [0.6400713  0.64859767 0.64153687 0.6512153  0.63969849] si are media 0.6442239256194373\n",
      "F1 pentru setul de testare este: [0.53840288 0.55291814 0.59317743 0.51876893 0.59730318] si are media 0.5601141134298688\n"
     ]
    }
   ],
   "source": [
    "k_neighbours_method(x_yeast, y_yeast, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuratetea setului de antrenare este: [0.59186865 0.60516028 0.57857701 0.59186865 0.5984375 ] si are media: 0.593182417904613\n",
      "Acuratetea setului de testare este: [0.534375   0.55       0.60625    0.55625    0.58934169] si are media: 0.5672433385579938\n",
      "F1 pentru setul de antrenare este: [0.56797048 0.5754338  0.54604082 0.56664071 0.56621608] si are media 0.5644603790080673\n",
      "F1 pentru setul de testare este: [0.48839427 0.52242078 0.56997685 0.54323602 0.54830089] si are media 0.534465763609883\n"
     ]
    }
   ],
   "source": [
    "k_neighbours_method(x_wine, y_wine, 73)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuratetea setului de antrenare este: [0.81770833 0.81794538 0.81404421 0.82054616 0.83094928] si are media: 0.8202386757693976\n",
      "Acuratetea setului de testare este: [0.79274611 0.81770833 0.81770833 0.77604167 0.765625  ] si are media: 0.7939658894645941\n",
      "F1 pentru setul de antrenare este: [0.81787205 0.81809062 0.81415474 0.82057972 0.8310618 ] si are media 0.820351786167541\n",
      "F1 pentru setul de testare este: [0.79231911 0.81787156 0.81745415 0.77633975 0.76529819] si are media 0.7938565508295811\n"
     ]
    }
   ],
   "source": [
    "k_neighbours_method(x_mammographic, y_mammographic, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuratetea setului de antrenare este: [0.85892116 0.84232365 0.88016529 0.8677686  0.87603306] si are media: 0.8650423510853538\n",
      "Acuratetea setului de testare este: [0.85245902 0.91803279 0.8        0.86666667 0.8       ] si are media: 0.8474316939890711\n",
      "F1 pentru setul de antrenare este: [0.84384265 0.82650962 0.86694208 0.85363979 0.86189619] si are media 0.8505660662909703\n",
      "F1 pentru setul de testare este: [0.83341613 0.91483069 0.79482131 0.84901515 0.77924603] si are media 0.8342658627534281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adina\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "k_neighbours_method(x_ecoli , y_ecoli, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=Magenta> 2. MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_method(X, y, activ) -> None:\n",
    "    #‘sgd’ refers to stochastic gradient descent.\n",
    "    \n",
    "    model =  MLPClassifier(activation = activ, random_state=10)\n",
    "    \n",
    "    scores = cross_validate(model, X, y, cv=5, scoring=['accuracy','f1_weighted'], return_train_score=True)\n",
    "    \n",
    "    print ('Acuratetea setului de antrenare este:', scores['train_accuracy'],\n",
    "           'si are media:', scores['train_accuracy'].mean())\n",
    "    print ('Acuratetea setului de testare este:', scores['test_accuracy'],\n",
    "           'si are media:', scores['test_accuracy'].mean())\n",
    "    \n",
    "    print ('F1 pentru setul de antrenare este:', scores['train_f1_weighted'],\n",
    "           'si are media', scores['train_f1_weighted'].mean())\n",
    "    print ('F1 pentru setul de testare este:', scores['test_f1_weighted'],\n",
    "           'si are media', scores['test_f1_weighted'].mean())\n",
    "    \n",
    "#     for i in range(5):\n",
    "#         X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3, random_state=i)\n",
    "        \n",
    "#         model =  MLPClassifier(activation = activ, random_state = 10)\n",
    "#         model.fit(X_train, y_train)\n",
    "    \n",
    "#         y_predicated_train = model.predict(X_train)\n",
    "#         y_predicated_test = model.predict(X_test)\n",
    "    \n",
    "#         print (\"Iteration:\", i)\n",
    "#         print (\"Train score:\", model.score(X_train, y_train)*100)\n",
    "#         print (\"Test score:\", model.score(X_test, y_test)*100)\n",
    "#         print (\"Different outputs train:\", sum(y_predicated_train != y_train), \"from total of\", len(y_train))\n",
    "#         print (\"Different outputs test:\", sum(y_predicated_test != y_test), \"from total of\", len(y_test))\n",
    "#         print (\"Accuracy train:\", metrics.accuracy_score(y_train, y_predicated_train)*100)\n",
    "#         # average='micro' Calculate metrics globally by counting the total true positives, false negatives and false positives.\n",
    "#         print (\"F1-score train:\", metrics.f1_score(y_train, y_predicated_train, average='micro')*100)\n",
    "#         print (\"Accuracy test:\", metrics.accuracy_score(y_test, y_predicated_test)*100)\n",
    "#         print (\"F1-score test:\", metrics.f1_score(y_test, y_predicated_test, average='micro')*100)\n",
    "#         print ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adina\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\adina\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\adina\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\adina\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuratetea setului de antrenare este: [0.58972199 0.58972199 0.57877001 0.60404381 0.59848485] si are media: 0.5921485282479385\n",
      "Acuratetea setului de testare este: [0.58922559 0.57912458 0.58922559 0.54208754 0.58783784] si are media: 0.5775002275002274\n",
      "F1 pentru setul de antrenare este: [0.57604484 0.57556155 0.56599829 0.59077186 0.58408689] si are media 0.578492686928124\n",
      "F1 pentru setul de testare este: [0.57101369 0.56406854 0.57653579 0.52974852 0.57529287] si are media 0.5633318808664869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adina\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "mlp_method (x_yeast, y_yeast, 'tanh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adina\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\adina\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\adina\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuratetea setului de antrenare este: [0.61297889 0.61376075 0.59812353 0.60828772 0.60234375] si are media: 0.6070989298279906\n",
      "Acuratetea setului de testare este: [0.540625   0.56875    0.640625   0.60625    0.62382445] si are media: 0.5960148902821316\n",
      "F1 pentru setul de antrenare este: [0.59434887 0.59139703 0.57601572 0.58637614 0.57518471] si are media 0.5846644948034039\n",
      "F1 pentru setul de testare este: [0.49399119 0.55286776 0.62287243 0.59052885 0.59119195] si are media 0.5702904350896402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adina\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "mlp_method (x_wine, y_wine, 'tanh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adina\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\adina\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\adina\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\adina\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuratetea setului de antrenare este: [0.81510417 0.80884265 0.8153446  0.82184655 0.81924577] si are media: 0.816076750108366\n",
      "Acuratetea setului de testare este: [0.79274611 0.828125   0.8125     0.78125    0.796875  ] si are media: 0.8022992227979275\n",
      "F1 pentru setul de antrenare este: [0.81534534 0.80902816 0.81556437 0.82197721 0.81945419] si are media 0.816273851634192\n",
      "F1 pentru setul de testare este: [0.79255546 0.82788716 0.812704   0.78153533 0.79634636] si are media 0.8022056618884823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adina\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "mlp_method (x_mammographic, y_mammographic, 'tanh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adina\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "C:\\Users\\adina\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\adina\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\adina\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\adina\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuratetea setului de antrenare este: [0.84232365 0.82572614 0.84710744 0.84710744 0.84710744] si are media: 0.8418744213161414\n",
      "Acuratetea setului de testare este: [0.81967213 0.81967213 0.85       0.81666667 0.76666667] si are media: 0.8145355191256831\n",
      "F1 pentru setul de antrenare este: [0.82194197 0.79972792 0.82640307 0.82956608 0.82487362] si are media 0.8205025351856283\n",
      "F1 pentru setul de testare este: [0.78926975 0.78403421 0.8418239  0.77165408 0.7434995 ] si are media 0.7860562864610965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adina\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "mlp_method(x_ecoli, y_ecoli, 'tanh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlp_method(X_train_yeast, y_train_yeast, X_test_yeast, y_test_yeast, 'tanh')\n",
    "\n",
    "# # Train score: 59.45399393326593 #solver='adam'\n",
    "# # Test score: 61.41414141414141\n",
    "# # Different outputs train: 401 from total of 989\n",
    "# # Different outputs test: 191 from total of 495\n",
    "\n",
    "# # Train score: 62.588473205257834 #solver='lbfgs'\n",
    "# # Test score: 61.41414141414141\n",
    "# # Different outputs train: 370 from total of 989\n",
    "# # Different outputs test: 191 from total of 495"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# mlp_method(X_train_wine, y_train_wine, X_test_wine, y_test_wine, 'tanh')\n",
    "\n",
    "# # Train score: 62.7579737335835 #solver='adam'\n",
    "# # Test score: 53.09568480300187\n",
    "# # Different outputs train: 397 from total of 1066\n",
    "# # Different outputs test: 250 from total of 533\n",
    "\n",
    "# # Train score: 65.94746716697935 #solver='lbfgs'\n",
    "# # Test score: 54.971857410881796\n",
    "# # Different outputs train: 363 from total of 1066\n",
    "# # Different outputs test: 240 from total of 533"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlp_method(X_train_breast_cancer, y_train_breast_cancer, X_test_breast_cancer, y_test_breast_cancer, 'relu')\n",
    "\n",
    "# # Train score: 78.94736842105263 #solver='adam'\n",
    "# # Test score: 73.95833333333334\n",
    "# # Different outputs train: 40 from total of 190\n",
    "# # Different outputs test: 25 from total of 96\n",
    "\n",
    "# # Train score: 78.94736842105263 #solver='lbfgs'\n",
    "# # Test score: 68.75\n",
    "# # Different outputs train: 40 from total of 190\n",
    "# # Different outputs test: 30 from total of 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlp_method(X_train_primary_tumor, y_train_primary_tumor, X_test_primary_tumor, y_test_primary_tumor, 'identity')\n",
    "\n",
    "# # Train score: 56.19469026548673 #solver='adam'\n",
    "# # Test score: 42.47787610619469\n",
    "# # Different outputs train: 99 from total of 226\n",
    "# # Different outputs test: 65 from total of 113\n",
    "\n",
    "# # Train score: 66.3716814159292 #solver='lbfgs'\n",
    "# # Test score: 38.93805309734513\n",
    "# # Different outputs train: 76 from total of 226\n",
    "# # Different outputs test: 69 from total of 113"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=Magenta> 3. SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svc_method(X, y) -> None:\n",
    "    \n",
    "    model = SVC(class_weight=None, random_state = 10)\n",
    "    \n",
    "    scores = cross_validate(model, X, y, cv=5, scoring=['accuracy','f1_weighted'], return_train_score=True)\n",
    "    \n",
    "    print ('Acuratetea setului de antrenare este:', scores['train_accuracy'],\n",
    "           'si are media:', scores['train_accuracy'].mean())\n",
    "    print ('Acuratetea setului de testare este:', scores['test_accuracy'],\n",
    "           'si are media:', scores['test_accuracy'].mean())\n",
    "    \n",
    "    print ('F1 pentru setul de antrenare este:', scores['train_f1_weighted'],\n",
    "           'si are media', scores['train_f1_weighted'].mean())\n",
    "    print ('F1 pentru setul de testare este:', scores['test_f1_weighted'],\n",
    "           'si are media', scores['test_f1_weighted'].mean())\n",
    "    \n",
    "#     for i in range(5):\n",
    "#         X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3, random_state=i)\n",
    "        \n",
    "#         model = SVC(class_weight=None, random_state = 10)\n",
    "#         model.fit(X_train,y_train)\n",
    "    \n",
    "#         y_predicated_train = model.predict(X_train)\n",
    "#         y_predicated_test = model.predict(X_test)\n",
    "    \n",
    "#         print (\"Iteration:\", i)\n",
    "#         print (\"Train score:\", model.score(X_train, y_train)*100)\n",
    "#         print (\"Test score:\", model.score(X_test, y_test)*100)\n",
    "#         print (\"Different outputs train:\", sum(y_predicated_train != y_train), \"from total of\", len(y_train))\n",
    "#         print (\"Different outputs test:\", sum(y_predicated_test != y_test), \"from total of\", len(y_test))\n",
    "#         print (\"Accuracy train:\", metrics.accuracy_score(y_train, y_predicated_train)*100)\n",
    "#         # average='micro' Calculate metrics globally by counting the total true positives, false negatives and false positives.\n",
    "#         print (\"F1-score train:\", metrics.f1_score(y_train, y_predicated_train, average='micro')*100)\n",
    "#         print (\"Accuracy test:\", metrics.accuracy_score(y_test, y_predicated_test)*100)\n",
    "#         print (\"F1-score test:\", metrics.f1_score(y_test, y_predicated_test, average='micro')*100)\n",
    "#         print ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuratetea setului de antrenare este: [0.61078349 0.62173547 0.60320135 0.64026959 0.61784512] si are media: 0.618767001665064\n",
      "Acuratetea setului de testare este: [0.61616162 0.61616162 0.62289562 0.54882155 0.59121622] si are media: 0.599051324051324\n",
      "F1 pentru setul de antrenare este: [0.60028884 0.61091196 0.59489801 0.63121115 0.60759518] si are media 0.6089810273490984\n",
      "F1 pentru setul de testare este: [0.60209739 0.60709779 0.6130061  0.53866087 0.58190772] si are media 0.5885539757319778\n"
     ]
    }
   ],
   "source": [
    "svc_method (x_yeast, y_yeast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuratetea setului de antrenare este: [0.59499609 0.60828772 0.59108679 0.60828772 0.6046875 ] si are media: 0.6014691653635653\n",
      "Acuratetea setului de testare este: [0.55625    0.540625   0.609375   0.578125   0.58934169] si are media: 0.5747433385579936\n",
      "F1 pentru setul de antrenare este: [0.54297281 0.55367691 0.53886185 0.55483223 0.55208943] si are media 0.5484866445259429\n",
      "F1 pentru setul de testare este: [0.49180227 0.49141756 0.55174861 0.52559271 0.53525559] si are media 0.5191633464843306\n"
     ]
    }
   ],
   "source": [
    "svc_method (x_wine, y_wine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuratetea setului de antrenare este: [0.80859375 0.79973992 0.80624187 0.81274382 0.80754226] si are media: 0.8069723260728219\n",
      "Acuratetea setului de testare este: [0.77720207 0.8125     0.79166667 0.75       0.80729167] si are media: 0.7877320811744386\n",
      "F1 pentru setul de antrenare este: [0.80880901 0.80001331 0.80649859 0.81295214 0.80775637] si are media 0.8072058841864367\n",
      "F1 pentru setul de testare este: [0.77741824 0.81188905 0.79125616 0.75027201 0.80735994] si are media 0.7876390775814224\n"
     ]
    }
   ],
   "source": [
    "svc_method (x_mammographic, y_mammographic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuratetea setului de antrenare este: [0.90871369 0.90871369 0.9338843  0.90082645 0.90082645] si are media: 0.9105929151949521\n",
      "Acuratetea setului de testare este: [0.8852459  0.90163934 0.81666667 0.88333333 0.8       ] si are media: 0.8573770491803279\n",
      "F1 pentru setul de antrenare este: [0.90200694 0.90420349 0.92935965 0.89719903 0.8955247 ] si are media 0.9056587620581098\n",
      "F1 pentru setul de testare este: [0.87468132 0.89923551 0.82184314 0.87199761 0.78143579] si are media 0.8498386718794727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adina\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "svc_method(x_ecoli, y_ecoli)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color = magenta> 4. GaussianProcessClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_method(X, y) -> None:\n",
    "    \n",
    "    model = GaussianProcessClassifier(random_state = 10)\n",
    "    \n",
    "    scores = cross_validate(model, X, y, cv=5, scoring=['accuracy','f1_weighted'], return_train_score=True)\n",
    "    \n",
    "    print ('Acuratetea setului de antrenare este:', scores['train_accuracy'],\n",
    "           'si are media:', scores['train_accuracy'].mean())\n",
    "    print ('Acuratetea setului de testare este:', scores['test_accuracy'],\n",
    "           'si are media:', scores['test_accuracy'].mean())\n",
    "    \n",
    "    print ('F1 pentru setul de antrenare este:', scores['train_f1_weighted'],\n",
    "           'si are media', scores['train_f1_weighted'].mean())\n",
    "    print ('F1 pentru setul de testare este:', scores['test_f1_weighted'],\n",
    "           'si are media', scores['test_f1_weighted'].mean())\n",
    "    \n",
    "#     for i in range(5):\n",
    "#         X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3, random_state=i)\n",
    "        \n",
    "#         model = GaussianProcessClassifier(random_state = 10)\n",
    "#         model.fit(X_train, y_train)\n",
    "    \n",
    "#         y_predicated_train = model.predict(X_train)\n",
    "#         y_predicated_test = model.predict(X_test)\n",
    "    \n",
    "#         print (\"Train score:\", model.score(X_train, y_train)*100)\n",
    "#         print (\"Test score:\", model.score(X_test, y_test)*100)\n",
    "#         print (\"Different outputs train:\", sum(y_predicated_train != y_train), \"from total of\", len(y_train))\n",
    "#         print (\"Different outputs test:\", sum(y_predicated_test != y_test), \"from total of\", len(y_test))\n",
    "#         print (\"Accuracy train:\", metrics.accuracy_score(y_train, y_predicated_train)*100)\n",
    "#         # average='micro' Calculate metrics globally by counting the total true positives, false negatives and false positives.\n",
    "#         print (\"F1-score train:\", metrics.f1_score(y_train, y_predicated_train, average='micro')*100)\n",
    "#         print (\"Accuracy test:\", metrics.accuracy_score(y_test, y_predicated_test)*100)\n",
    "#         print (\"F1-score test:\", metrics.f1_score(y_test, y_predicated_test, average='micro')*100)\n",
    "#         print ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuratetea setului de antrenare este: [0.54928391 0.54759899 0.53664701 0.56697557 0.55387205] si are media: 0.5508755059723889\n",
      "Acuratetea setului de testare este: [0.53872054 0.56902357 0.56228956 0.4983165  0.55405405] si are media: 0.5444808444808444\n",
      "F1 pentru setul de antrenare este: [0.52604099 0.52297166 0.51240678 0.54444678 0.5296878 ] si are media 0.5271108034696936\n",
      "F1 pentru setul de testare este: [0.50722909 0.54379091 0.53765294 0.4757784  0.52781064] si are media 0.5184523929808442\n"
     ]
    }
   ],
   "source": [
    "gaussian_method(x_yeast, y_yeast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuratetea setului de antrenare este: [0.59343237 0.6028147  0.58952306 0.5887412  0.5953125 ] si are media: 0.5939647673964035\n",
      "Acuratetea setului de testare este: [0.546875   0.521875   0.625      0.596875   0.58934169] si are media: 0.5759933385579938\n",
      "F1 pentru setul de antrenare este: [0.54394999 0.55739554 0.54338252 0.54500169 0.54936446] si are media 0.5478188395908277\n",
      "F1 pentru setul de testare este: [0.48697201 0.49488464 0.56857956 0.55437955 0.53467028] si are media 0.5278972101434632\n"
     ]
    }
   ],
   "source": [
    "gaussian_method(x_wine, y_wine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuratetea setului de antrenare este: [0.81510417 0.80754226 0.8153446  0.82054616 0.8153446 ] si are media: 0.8147763599913308\n",
      "Acuratetea setului de testare este: [0.78756477 0.82291667 0.80729167 0.77083333 0.79166667] si are media: 0.7960546200345423\n",
      "F1 pentru setul de antrenare este: [0.81533884 0.807805   0.81559237 0.8207458  0.81559784] si are media 0.815015969793245\n",
      "F1 pentru setul de testare este: [0.78764503 0.82257065 0.80735994 0.77108267 0.79180283] si are media 0.7960922249673777\n"
     ]
    }
   ],
   "source": [
    "gaussian_method(x_mammographic, y_mammographic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adina\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuratetea setului de antrenare este: [0.74688797 0.74688797 0.75206612 0.75619835 0.75619835] si are media: 0.7516477487054628\n",
      "Acuratetea setului de testare este: [0.72131148 0.78688525 0.81666667 0.76666667 0.63333333] si are media: 0.7449726775956284\n",
      "F1 pentru setul de antrenare este: [0.68163368 0.67998342 0.6921396  0.69225959 0.68277999] si are media 0.685759256581485\n",
      "F1 pentru setul de testare este: [0.64279254 0.71327482 0.7852381  0.70287037 0.55299243] si are media 0.67943365203875\n"
     ]
    }
   ],
   "source": [
    "gaussian_method(x_ecoli, y_ecoli)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=magenta> 5. GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_nb_method(X, y) -> None:\n",
    "    \n",
    "    model = GaussianNB()\n",
    "    \n",
    "    scores = cross_validate(model, X, y, cv=5, scoring=['accuracy','f1_weighted'], return_train_score=True)\n",
    "    \n",
    "    print ('Acuratetea setului de antrenare este:', scores['train_accuracy'],\n",
    "           'si are media:', scores['train_accuracy'].mean())\n",
    "    print ('Acuratetea setului de testare este:', scores['test_accuracy'],\n",
    "           'si are media:', scores['test_accuracy'].mean())\n",
    "    \n",
    "    print ('F1 pentru setul de antrenare este:', scores['train_f1_weighted'],\n",
    "           'si are media', scores['train_f1_weighted'].mean())\n",
    "    print ('F1 pentru setul de testare este:', scores['test_f1_weighted'],\n",
    "           'si are media', scores['test_f1_weighted'].mean())\n",
    "    \n",
    "#      for i in range(5):\n",
    "#         X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3, random_state=i)\n",
    "        \n",
    "#         model = GaussianNB()\n",
    "#         model.fit(X_train, y_train)\n",
    "      \n",
    "#         y_predicated_train = model.predict(X_train)\n",
    "#         y_predicated_test = model.predict(X_test)\n",
    "    \n",
    "#         print (\"Iteration: \", i)\n",
    "#         print (\"Train score:\", model.score(X_train, y_train)*100)\n",
    "#         print (\"Test score:\", model.score(X_test, y_test)*100)\n",
    "#         print (\"Different outputs train:\", sum(y_predicated_train != y_train), \"from total of\", len(y_train))\n",
    "#         print (\"Different outputs test:\", sum(y_predicated_test != y_test), \"from total of\", len(y_test))\n",
    "#         print (\"Accuracy train:\", metrics.accuracy_score(y_train, y_predicated_train)*100)\n",
    "#         # average='micro' Calculate metrics globally by counting the total true positives, false negatives and false positives.\n",
    "#         print (\"F1-score train:\", metrics.f1_score(y_train, y_predicated_train, average='micro')*100)\n",
    "#         print (\"Accuracy test:\", metrics.accuracy_score(y_test, y_predicated_test)*100)\n",
    "#         print (\"F1-score test:\", metrics.f1_score(y_test, y_predicated_test, average='micro')*100)\n",
    "#         print ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuratetea setului de antrenare este: [0.16933446 0.15501264 0.23841618 0.1390059  0.13131313] si are media: 0.16661645945554956\n",
      "Acuratetea setului de testare este: [0.13804714 0.14478114 0.2020202  0.1043771  0.14864865] si are media: 0.14757484757484757\n",
      "F1 pentru setul de antrenare este: [0.20685848 0.17505935 0.20255769 0.13787692 0.14763672] si are media 0.17399783456613466\n",
      "F1 pentru setul de testare este: [0.15451384 0.16579675 0.17967319 0.10006242 0.16623635] si are media 0.15325650959500053\n"
     ]
    }
   ],
   "source": [
    "gaussian_nb_method(x_yeast, y_yeast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuratetea setului de antrenare este: [0.57857701 0.56763096 0.55981235 0.55512119 0.56640625] si are media: 0.5655095533620016\n",
      "Acuratetea setului de testare este: [0.49375    0.4625     0.5875     0.496875   0.57053292] si are media: 0.5222315830721004\n",
      "F1 pentru setul de antrenare este: [0.58483603 0.56655814 0.55734532 0.55500248 0.56782543] si are media 0.5663134811046133\n",
      "F1 pentru setul de testare este: [0.49347686 0.45955206 0.58256095 0.50030087 0.56716433] si are media 0.5206110161790701\n"
     ]
    }
   ],
   "source": [
    "gaussian_nb_method(x_wine, y_wine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuratetea setului de antrenare este: [0.78645833 0.79323797 0.78543563 0.79063719 0.78413524] si are media: 0.7879808734286953\n",
      "Acuratetea setului de testare este: [0.75129534 0.80729167 0.77604167 0.77604167 0.76041667] si are media: 0.7742174006908462\n",
      "F1 pentru setul de antrenare este: [0.78674116 0.79352161 0.78571053 0.79079073 0.78430745] si are media 0.7882142965108653\n",
      "F1 pentru setul de testare este: [0.74959765 0.80679471 0.77633975 0.77633975 0.75994458] si are media 0.7738032885300136\n"
     ]
    }
   ],
   "source": [
    "gaussian_nb_method(x_mammographic, y_mammographic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuratetea setului de antrenare este: [0.7219917  0.77178423 0.80578512 0.82231405 0.87190083] si are media: 0.7987551867219918\n",
      "Acuratetea setului de testare este: [0.68852459 0.81967213 0.81666667 0.75       0.73333333] si are media: 0.7616393442622951\n",
      "F1 pentru setul de antrenare este: [0.66700158 0.75554874 0.75910946 0.80681174 0.86896484] si are media 0.7714872714458815\n",
      "F1 pentru setul de testare este: [0.63659696 0.80255062 0.7748366  0.72717284 0.70079557] si are media 0.7283905172991341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adina\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "gaussian_nb_method(x_ecoli, y_ecoli)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yeast 55\n",
    "<br>Wine Red ?\n",
    "<br>Breast Cancer 75\n",
    "<br>Primary tumor 48"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>Ex3:</font> Documentati in jupyter notebook fiecare din modelele folosite, in limba romana. Daca acelasi algoritm e folosit pentru mai multe seturi de date, puteti face o sectiune separata cu documentarea algoritmilor + trimitere la algoritm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GaussianNB\n",
    "<br>\n",
    "<br>\n",
    "<br>Acest tip de clasificare este foarte simplu, de aceea pentru seturile noastre de date obtinem un rezultat bun pentru setul de date breast_cancer, intrucat acesta se imparte in doua clase(no-recurrence-events si recurrence-events).\n",
    "<br>Pentru celelalte seturi de date rezultatul este evident, intrucat celelalte seturi de date au in jur de 10 clase.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Decision Tree Classifier\n",
    "<br>\n",
    "<br>\n",
    "<br>Aceasta metoda poate clasifica atat doua clase cat si mai multe clase intr-un dataset.\n",
    "<br>\n",
    "<br>Parametri:\n",
    "<br>splitter-> reprezinta strategia aleasa pentru divizarea nodurilor\n",
    "<br>max_depth-> reprezinta adancimea arborelui\n",
    "<br>min_samples_split-> nr minim de sample-uri necesare \n",
    "<br>min_samples_leaf-> nr minim de sample-uri necesare ca un nod sa fie frunza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier\n",
    "<br>\n",
    "<br>\n",
    "<br>Aceasta metoda foloseste o padure de arbori de decizie random.\n",
    "<br>Are ca scop controlul fenomenului de overfitting.\n",
    "<br>\n",
    "<br>Parametri:\n",
    "<br>n_estimators-> nr de arbori din padure\n",
    "<br>max_depth-> adancimea arborelui \n",
    "<br>min_samples_split-> nr de sample-uri necesare unui nod pentru a se face split\n",
    "<br>min_samples_leaf-> nr minim de sample-uri necesare ca un nod sa fie frunza\n",
    "<br>si altele\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>Observatii:\n",
    "<br>n_estimators-> nu produce overfitting daca crestem nr de arbori \n",
    "<br>max_features-> cu cat e mai mic cu atat evitam overfitting-ul, dar daca e prea mic reteaua face undefitting\n",
    "<br>max_depth-> are un rol important, reduce complexitatea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-layer Perceptron classifier\n",
    "<br>\n",
    "<br>\n",
    "<br>Acest model optimizează funcția log-loss folosind LBFGS sau descendență de gradient stocastic.\n",
    "<br>Această implementare funcționează cu date reprezentate ca tablouri numpy dense sau tablouri scipy slabe de valori în virgulă mobilă.\n",
    "<br>\n",
    "<br>Parametri:\n",
    "<br>hidden_layer_sizes ->  numărul de neuroni din stratul ascuns\n",
    "<br>activation -> funcție de activare\n",
    "<br>solver ->  pentru optimizarea ponderilor\n",
    "<br>alpha -> parametrul de penalizare L2\n",
    "<br>batch_size -> dimensiunea minibatches-urilor pentru optimizarea stocastica\n",
    "<br>learning_rate -> rata de învățare pentru actualizări de ponderi\n",
    "<br>learning_rate_init -> rata inițială de învățare\n",
    "<br>power_t -> exponent pentru scalare inversă a ratei de învățare \n",
    "<br>max_iter -> numărul maxim de iterații\n",
    "<br>shuffle -> amestecare de sample-uri la fiecare iterație\n",
    "<br>random_state -> generatorul de numere aleatorii\n",
    "<br>tol -> toleranță pentru optimizare\n",
    "<br>verbose -> printare mesaje de progres în stdout\n",
    "<br>warm_start -> reutilizați soluția apelului anterior\n",
    "<br>momentum -> momentum pentru actualizarea descendenței gradientului\n",
    "<br>nesterovs_momentum -> momentumul lui Nesterov\n",
    "<br>early_stopping -> va anula automat 10% din datele de instruire și va încheia antrenarea atunci când scorul de validare nu se îmbunătățește \n",
    "<br>validation_fraction -> proportia datelor de antrenare care vor fi rezervate ca set de validare\n",
    "<br>beta_1 -> rata de descompunere exponențială pentru estimările vectorului din primul moment\n",
    "<br>beta_2 -> rata de descompunere exponențială pentru estimările vectorului din al doilea moment\n",
    "<br>epsilon -> valoare pentru stabilitatea numerică\n",
    "<br>n_iter_no_change -> numărul maxim de epoci pentru a nu respecta îmbunătățirea dată de tol\n",
    "<br>max_fun -> numărul maxim de apeluri ale funcției de loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GaussianProcessClassifier\n",
    "<br>\n",
    "<br>\n",
    "<br>Este bazată pe aproximarea Laplace.\n",
    "<br>\n",
    "<br>Parametri:\n",
    "<br>kernel -> nucleul care specifică funcția de covarianță \n",
    "<br>optimizer -> optimizator intern acceptat pentru optimizarea parametrilor nucleului\n",
    "<br>n_restarts_optimizer -> numărul de reporniri ale optimizatorului pentru găsirea parametrilor kernel-ului\n",
    "<br>max_iter_predict -> numărul maxim de iterații din metoda lui Newton\n",
    "<br>warm_start -> soluția ultimei iterații Newton este utilizată ca inițializare pentru următorul apel\n",
    "<br>copy_X_train -> o copie persistentă a datelor de instruire \n",
    "<br>random_state -> generatorul de numere aleatorii \n",
    "<br>multi_class -> specifică modul în care sunt gestionate problemele de clasificare cu mai multe clase\n",
    "<br>n_jobs -> numărul de joburi utilizate pentru calcul"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNeighborsClassifier\n",
    "<br>\n",
    "<br>\n",
    "<br>Clasificatorul care implementează votul celor mai apropiați k vecini.\n",
    "<br>\n",
    "<br>Parametri:\n",
    "<br>n_neighbors -> numărul de vecini care vor fi folosiți\n",
    "<br>weights -> funcția de ponderi folosită în predicție\n",
    "<br>algorithm -> algoritmul folosit pentru calcularea vecinilor\n",
    "<br>leaf_size -> dimensiunea frunzelor pentru BallTree sau KDTree\n",
    "<br>p -> parametru de putere pentru metrica Minkowski\n",
    "<br>metric -> distanța utilizată pentru arbore\n",
    "<br>metric_params -> argumente suplimentare pentru funcția metrică\n",
    "<br>n_jobs -> numărul de joburi utilizate pentru calcul\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C-Support Vector Classification\n",
    "<br>\n",
    "<br>\n",
    "<br>Implementarea se bazează pe libsvm. \n",
    "<br>\n",
    "<br>Parametri:\n",
    "<br>C -> parametrul de regularizare\n",
    "<br>kernel -> nucleul care specifică funcția de covarianță \n",
    "<br>degree -> gradul funcției nucleului polinomial \n",
    "<br>gamma -> coeficientul de nucleu\n",
    "<br>coef0 -> termen independent în funcția de nucleu\n",
    "<br>shrinking -> folosește euristicul micșorat\n",
    "<br>probability -> estimări de probabilitate\n",
    "<br>tol -> toleranță pentru optimizare \n",
    "<br>cache_size -> specifică dimensiunea memoriei cache a nucleului\n",
    "<br>class_weight -> setați parametrul C al clasei i la clasa_pondere[i]*C pentru SVC\n",
    "<br>verbose -> printare mesaje de progres în stdout \n",
    "<br>max_iter -> numărul maxim de iterații\n",
    "<br>decision_function_shape -> returnează funcția de decizie 'ovr' sau 'ovo' în funcție de formă\n",
    "<br>break_ties -> prezicerea va rupe legăturile în funcție de valorile de încredere ale funcției de decizie\n",
    "<br>random_state -> generatorul de numere aleatorii "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>Ex4:</font>Pentru fiecare model: efectuati o cautare a hiperparametrilor optimi folosind grid search si random search (cu parametrul cv = 4), folosind 5 fold cross validation. \n",
    "<br>\n",
    "Raportati performanta fiecarui model, folosind 5 fold cross validation. Pentru fiecare din cele 5 rulari, cautati hiperparametrii optimi folosind 4-fold cross validation. Performanta modelului va fi raportata ca medie a celor  5 rulari. \n",
    "    *Observatie:* la fiecare din cele 5 rulari, hiperparametrii optimi pot diferi, din cauza datelor utilizate pentru antrenare/validare.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=magenta> 1. KNeighbourClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_yeast, X_test_yeast, y_train_yeast, y_test_yeast = train_test_split(x_yeast, y_yeast, test_size=1/5)\n",
    "parameter_grid = {'n_neighbors': list(range(10, 20)), 'weights': ['uniform', 'distance'], 'p': [1, 2, 3, 4.7]}\n",
    "\n",
    "grid_search = GridSearchCV(estimator = KNeighborsClassifier(), param_grid = parameter_grid, scoring = 'accuracy', \n",
    "                           cv = 5, return_train_score = True)\n",
    "print(\"Grid Search :\", grid_search.fit(X_train_yeast, y_train_yeast))\n",
    "\n",
    "y_estimated_train_yeast = grid_search.predict(X_train_yeast)\n",
    "print(\"Accuracy train:\", accuracy_score(y_train_yeast, y_estimated_train_yeast))\n",
    "\n",
    "y_estimated_test_yeast = grid_search.predict(X_test_yeast)\n",
    "print(\"Accuracy test:\", accuracy_score(y_test_yeast, y_estimated_test_yeast))\n",
    "\n",
    "print(\"Best parameter:\", grid_search.best_params_)\n",
    "\n",
    "scores = cross_val_score(GridSearchCV(estimator = KNeighborsClassifier(), param_grid=parameter_grid, \n",
    "                                      scoring='accuracy', cv=5), x_yeast, y_yeast, cv=4)\n",
    "print(\"Mean accuracy:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_wine, X_test_wine, y_train_wine, y_test_wine = train_test_split(x_wine, y_wine, test_size=1/5)\n",
    "parameter_grid = {'n_neighbors': list(range(60, 80)), 'weights': ['uniform', 'distance'], 'p': [1, 2, 3, 4.7]}\n",
    "\n",
    "grid_search = GridSearchCV(estimator = KNeighborsClassifier(), param_grid=parameter_grid, scoring='accuracy', cv=5, \n",
    "                           return_train_score=True)\n",
    "print(\"Grid Search:\", grid_search.fit(X_train_wine, y_train_wine))\n",
    "\n",
    "y_estimated_train_wine = grid_search.predict(X_train_wine)\n",
    "print(\"Accuracy train:\", accuracy_score(y_train_wine, y_estimated_train_wine))\n",
    "\n",
    "y_estimated_test_wine = grid_search.predict(X_test_wine)\n",
    "print(\"Accuracy test:\", accuracy_score(y_test_wine, y_estimated_test_wine))\n",
    "\n",
    "print(\"Best parameter:\", grid_search.best_params_)\n",
    "\n",
    "scores = cross_val_score(GridSearchCV(estimator = KNeighborsClassifier(), param_grid=parameter_grid, \n",
    "                                      scoring='accuracy', cv=5), x_wine, y_wine, cv=4)\n",
    "print(\"Mean accuracy:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mammographic, X_test_mammographic, y_train_mammographic, y_test_mammographic = train_test_split(\n",
    "    x_mammographic, y_mammographic, test_size=1/5)\n",
    "parameter_grid = {'n_neighbors': list(range(1, 20)), 'weights': ['uniform', 'distance'], 'p': [1, 2, 3, 4.7]}\n",
    "\n",
    "grid_search = GridSearchCV(estimator = KNeighborsClassifier(), param_grid=parameter_grid, scoring='accuracy', cv=5, \n",
    "                           return_train_score=True)\n",
    "print(\"Grid Search:\", grid_search.fit(X_train_mammographic, y_train_mammographic))\n",
    "\n",
    "y_estimated_train_mammographic = grid_search.predict(X_train_mammographic)\n",
    "print(\"Accuracy train:\", accuracy_score(y_train_mammographic, y_estimated_train_mammographic))\n",
    "\n",
    "y_estimated_test_mammographic = grid_search.predict(X_test_mammographic)\n",
    "print(\"Accuracy test:\", accuracy_score(y_test_mammographic, y_estimated_test_mammographic))\n",
    "\n",
    "print(\"Best parameter:\", grid_search.best_params_)\n",
    "\n",
    "scores = cross_val_score(GridSearchCV(estimator = KNeighborsClassifier(), param_grid=parameter_grid, \n",
    "                                      scoring='accuracy', cv=5), x_mammographic, y_mammographic, cv=4)\n",
    "print(\"Mean accuracy:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ecoli, X_test_ecoli, y_train_ecoli, y_test_ecoli = train_test_split(\n",
    "    x_ecoli, y_ecoli, test_size=1/5)\n",
    "parameter_grid = {'n_neighbors': list(range(1, 20)), 'weights': ['uniform', 'distance'], 'p': [1, 2, 3, 4.7]}\n",
    "\n",
    "grid_search = GridSearchCV(estimator = KNeighborsClassifier(), param_grid=parameter_grid, scoring='accuracy', cv=5, \n",
    "                           return_train_score=True)\n",
    "print(\"Grid Search:\", grid_search.fit(X_train_ecoli, y_train_ecoli))\n",
    "\n",
    "y_estimated_train_ecoli = grid_search.predict(X_train_ecoli)\n",
    "print(\"Accuracy train:\", accuracy_score(y_train_ecoli, y_estimated_train_ecoli))\n",
    "\n",
    "y_estimated_test_ecoli = grid_search.predict(X_test_ecoli)\n",
    "print(\"Accuracy test:\", accuracy_score(y_test_ecoli, y_estimated_test_ecoli))\n",
    "\n",
    "print(\"Best parameter:\", grid_search.best_params_)\n",
    "\n",
    "scores = cross_val_score(GridSearchCV(estimator = KNeighborsClassifier(), param_grid=parameter_grid, \n",
    "                                      scoring='accuracy', cv=5), x_ecoli, y_ecoli, cv=4)\n",
    "print(\"Mean accuracy:\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=Magenta> 2. MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_yeast, X_test_yeast, y_train_yeast, y_test_yeast = train_test_split(x_yeast, y_yeast, test_size=1/5)\n",
    "parameter_grid = {'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "                 'learning_rate': ['constant', 'invscaling', 'adaptive']}\n",
    "# 'learning_rate': ['constant', 'invscaling', 'adaptive'], 'tol': [1e-4, 5e-6, 1e-6]\n",
    "\n",
    "grid_search = GridSearchCV(estimator = MLPClassifier(), param_grid = parameter_grid, scoring = 'accuracy', \n",
    "                           cv = 5, return_train_score = True)\n",
    "print(\"Grid Search :\", grid_search.fit(X_train_yeast, y_train_yeast))\n",
    "\n",
    "y_estimated_train_yeast = grid_search.predict(X_train_yeast)\n",
    "print(\"Accuracy train:\", accuracy_score(y_train_yeast, y_estimated_train_yeast))\n",
    "\n",
    "y_estimated_test_yeast = grid_search.predict(X_test_yeast)\n",
    "print(\"Accuracy test:\", accuracy_score(y_test_yeast, y_estimated_test_yeast))\n",
    "\n",
    "print(\"Best parameter:\", grid_search.best_params_)\n",
    "\n",
    "scores = cross_val_score(GridSearchCV(estimator = MLPClassifier(), param_grid=parameter_grid, \n",
    "                                      scoring='accuracy', cv=5), x_yeast, y_yeast, cv=4)\n",
    "print(\"Mean accuracy:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_wine, X_test_wine, y_train_wine, y_test_wine = train_test_split(x_wine, y_wine, test_size=1/5)\n",
    "parameter_grid = {'activation': ['identity', 'logistic', 'tanh', 'relu'], \n",
    "                  'learning_rate': ['constant', 'invscaling', 'adaptive']}\n",
    "# 'learning_rate': ['constant', 'invscaling', 'adaptive'], 'tol': [1e-4, 5e-6, 1e-6]\n",
    "\n",
    "grid_search = GridSearchCV(estimator = MLPClassifier(), param_grid = parameter_grid, scoring = 'accuracy', \n",
    "                           cv = 5, return_train_score = True)\n",
    "print(\"Grid Search :\", grid_search.fit(X_train_wine, y_train_wine))\n",
    "\n",
    "y_estimated_train_wine = grid_search.predict(X_train_wine)\n",
    "print(\"Accuracy train:\", accuracy_score(y_train_wine, y_estimated_train_wine))\n",
    "\n",
    "y_estimated_test_wine = grid_search.predict(X_test_wine)\n",
    "print(\"Accuracy test:\", accuracy_score(y_test_wine, y_estimated_test_wine))\n",
    "\n",
    "print(\"Best parameter:\", grid_search.best_params_)\n",
    "\n",
    "scores = cross_val_score(GridSearchCV(estimator = MLPClassifier(), param_grid=parameter_grid, \n",
    "                                      scoring='accuracy', cv=5), x_wine, y_wine, cv=4)\n",
    "print(\"Mean accuracy:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mammographic, X_test_mammographic, y_train_mammographic, y_test_mammographic = train_test_split(\n",
    "    x_mammographic, y_mammographic, test_size=1/5)\n",
    "parameter_grid = {'activation': ['identity', 'logistic', 'tanh', 'relu'], \n",
    "                  'learning_rate': ['constant', 'invscaling', 'adaptive']}\n",
    "# 'solver': ['lbfgs', 'sgd', 'adam'], 'tol': [1e-4, 5e-6, 1e-6]\n",
    "\n",
    "grid_search = GridSearchCV(estimator = MLPClassifier(), param_grid = parameter_grid, scoring = 'accuracy', \n",
    "                           cv = 5, return_train_score = True)\n",
    "print(\"Grid Search :\", grid_search.fit(X_train_mammographic, y_train_mammographic))\n",
    "\n",
    "y_estimated_train_mammographic = grid_search.predict(X_train_mammographic)\n",
    "print(\"Accuracy train:\", accuracy_score(y_train_mammographic, y_estimated_train_mammographic))\n",
    "\n",
    "y_estimated_test_mammographic = grid_search.predict(X_test_mammographic)\n",
    "print(\"Accuracy test:\", accuracy_score(y_test_mammographic, y_estimated_test_mammographic))\n",
    "\n",
    "print(\"Best parameter:\", grid_search.best_params_)\n",
    "\n",
    "scores = cross_val_score(GridSearchCV(estimator = MLPClassifier(), param_grid=parameter_grid, \n",
    "                                      scoring='accuracy', cv=5), x_mammographic, y_mammographic, cv=4)\n",
    "print(\"Mean accuracy:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ecoli, X_test_ecoli, y_train_ecoli, y_test_ecoli = train_test_split(\n",
    "    x_ecoli, y_ecoli, test_size=1/5)\n",
    "parameter_grid = {'activation': ['identity', 'logistic', 'tanh', 'relu'], \n",
    "                  'learning_rate': ['constant', 'invscaling', 'adaptive']}\n",
    "# 'solver': ['lbfgs', 'sgd', 'adam'], 'tol': [1e-4, 5e-6, 1e-6]\n",
    "\n",
    "grid_search = GridSearchCV(estimator = MLPClassifier(), param_grid = parameter_grid, scoring = 'accuracy', \n",
    "                           cv = 5, return_train_score = True)\n",
    "print(\"Grid Search :\", grid_search.fit(X_train_ecoli, y_train_ecoli))\n",
    "\n",
    "y_estimated_train_ecoli = grid_search.predict(X_train_ecoli)\n",
    "print(\"Accuracy train:\", accuracy_score(y_train_ecoli, y_estimated_train_ecoli))\n",
    "\n",
    "y_estimated_test_ecoli = grid_search.predict(X_test_ecoli)\n",
    "print(\"Accuracy test:\", accuracy_score(y_test_ecoli, y_estimated_test_ecoli))\n",
    "\n",
    "print(\"Best parameter:\", grid_search.best_params_)\n",
    "\n",
    "scores = cross_val_score(GridSearchCV(estimator = MLPClassifier(), param_grid=parameter_grid, \n",
    "                                      scoring='accuracy', cv=5), x_ecoli, y_ecoli, cv=4)\n",
    "print(\"Mean accuracy:\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=Magenta> 3. SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_yeast, X_test_yeast, y_train_yeast, y_test_yeast = train_test_split(x_yeast, y_yeast, test_size=1/5)\n",
    "parameter_grid = {'C': list(range(1, 5)), 'gamma': ['scale', 'auto']}\n",
    "\n",
    "grid_search = GridSearchCV(estimator = SVC(), param_grid = parameter_grid, scoring = 'accuracy', \n",
    "                           cv = 5, return_train_score = True)\n",
    "print(\"Grid Search :\", grid_search.fit(X_train_yeast, y_train_yeast))\n",
    "\n",
    "y_estimated_train_yeast = grid_search.predict(X_train_yeast)\n",
    "print(\"Accuracy train:\", accuracy_score(y_train_yeast, y_estimated_train_yeast))\n",
    "\n",
    "y_estimated_test_yeast = grid_search.predict(X_test_yeast)\n",
    "print(\"Accuracy test:\", accuracy_score(y_test_yeast, y_estimated_test_yeast))\n",
    "\n",
    "print(\"Best parameter:\", grid_search.best_params_)\n",
    "\n",
    "scores = cross_val_score(GridSearchCV(estimator = SVC(), param_grid=parameter_grid, \n",
    "                                      scoring='accuracy', cv=5), x_yeast, y_yeast, cv=4)\n",
    "print(\"Mean accuracy:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_wine, X_test_wine, y_train_wine, y_test_wine = train_test_split(x_wine, y_wine, test_size=1/5)\n",
    "parameter_grid = {'C': list(range(1, 5)), 'gamma': ['scale', 'auto']}\n",
    "\n",
    "grid_search = GridSearchCV(estimator = SVC(), param_grid = parameter_grid, scoring = 'accuracy', \n",
    "                           cv = 5, return_train_score = True)\n",
    "print(\"Grid Search :\", grid_search.fit(X_train_wine, y_train_wine))\n",
    "\n",
    "y_estimated_train_wine = grid_search.predict(X_train_wine)\n",
    "print(\"Accuracy train:\", accuracy_score(y_train_wine, y_estimated_train_wine))\n",
    "\n",
    "y_estimated_test_wine = grid_search.predict(X_test_wine)\n",
    "print(\"Accuracy test:\", accuracy_score(y_test_wine, y_estimated_test_wine))\n",
    "\n",
    "print(\"Best parameter:\", grid_search.best_params_)\n",
    "\n",
    "scores = cross_val_score(GridSearchCV(estimator = SVC(), param_grid=parameter_grid, \n",
    "                                      scoring='accuracy', cv=5), x_wine, y_wine, cv=4)\n",
    "print(\"Mean accuracy:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mammographic, X_test_mammographic, y_train_mammographic, y_test_mammographic = train_test_split(\n",
    "    x_mammographic, y_mammographic, test_size=1/5)\n",
    "parameter_grid = {'C': list(range(1, 5)), 'gamma': ['scale', 'auto']}\n",
    "\n",
    "grid_search = GridSearchCV(estimator = SVC(), param_grid = parameter_grid, scoring = 'accuracy', \n",
    "                           cv = 5, return_train_score = True)\n",
    "print(\"Grid Search :\", grid_search.fit(X_train_mammographic, y_train_mammographic))\n",
    "\n",
    "y_estimated_train_mammographic = grid_search.predict(X_train_mammographic)\n",
    "print(\"Accuracy train:\", accuracy_score(y_train_mammographic, y_estimated_train_mammographic))\n",
    "\n",
    "y_estimated_test_mammographic = grid_search.predict(X_test_mammographic)\n",
    "print(\"Accuracy test:\", accuracy_score(y_test_mammographic, y_estimated_test_mammographic))\n",
    "\n",
    "print(\"Best parameter:\", grid_search.best_params_)\n",
    "\n",
    "scores = cross_val_score(GridSearchCV(estimator = SVC(), param_grid=parameter_grid, \n",
    "                                      scoring='accuracy', cv=5), x_mammographic, y_mammographic, cv=4)\n",
    "print(\"Mean accuracy:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ecoli, X_test_ecoli, y_train_ecoli, y_test_ecoli = train_test_split(\n",
    "    x_ecoli, y_ecoli, test_size=1/5)\n",
    "parameter_grid = {'C': list(range(1, 5)), 'gamma': ['scale', 'auto']}\n",
    "\n",
    "grid_search = GridSearchCV(estimator = SVC(), param_grid = parameter_grid, scoring = 'accuracy', \n",
    "                           cv = 5, return_train_score = True)\n",
    "print(\"Grid Search :\", grid_search.fit(X_train_ecoli, y_train_ecoli))\n",
    "\n",
    "y_estimated_train_ecoli = grid_search.predict(X_train_ecoli)\n",
    "print(\"Accuracy train:\", accuracy_score(y_train_ecoli, y_estimated_train_ecoli))\n",
    "\n",
    "y_estimated_test_ecoli = grid_search.predict(X_test_ecoli)\n",
    "print(\"Accuracy test:\", accuracy_score(y_test_ecoli, y_estimated_test_ecoli))\n",
    "\n",
    "print(\"Best parameter:\", grid_search.best_params_)\n",
    "\n",
    "scores = cross_val_score(GridSearchCV(estimator = SVC(), param_grid=parameter_grid, \n",
    "                                      scoring='accuracy', cv=5), x_ecoli, y_ecoli, cv=4)\n",
    "print(\"Mean accuracy:\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color = magenta> 4. GaussianProcessClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_yeast, X_test_yeast, y_train_yeast, y_test_yeast = train_test_split(x_yeast, y_yeast, test_size=1/5)\n",
    "parameter_grid = {'kernel': [None, 'kernel'], 'n_restarts_optimizer': list(range(0, 5))}\n",
    "\n",
    "grid_search = GridSearchCV(estimator = GaussianProcessClassifier(), param_grid = parameter_grid, scoring = 'accuracy', \n",
    "                           cv = 5, return_train_score = True)\n",
    "print(\"Grid Search :\", grid_search.fit(X_train_yeast, y_train_yeast))\n",
    "\n",
    "y_estimated_train_yeast = grid_search.predict(X_train_yeast)\n",
    "print(\"Accuracy train:\", accuracy_score(y_train_yeast, y_estimated_train_yeast))\n",
    "\n",
    "y_estimated_test_yeast = grid_search.predict(X_test_yeast)\n",
    "print(\"Accuracy test:\", accuracy_score(y_test_yeast, y_estimated_test_yeast))\n",
    "\n",
    "print(\"Best parameter:\", grid_search.best_params_)\n",
    "\n",
    "scores = cross_val_score(GridSearchCV(estimator = GaussianProcessClassifier(), param_grid=parameter_grid, \n",
    "                                      scoring='accuracy', cv=5), x_yeast, y_yeast, cv=4)\n",
    "print(\"Mean accuracy:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_wine, X_test_wine, y_train_wine, y_test_wine = train_test_split(x_wine, y_wine, test_size=1/5)\n",
    "parameter_grid = {'kernel': [None, 'kernel'], 'n_restarts_optimizer': list(range(0, 5))}\n",
    "\n",
    "grid_search = GridSearchCV(estimator = GaussianProcessClassifier(), param_grid = parameter_grid, scoring = 'accuracy', \n",
    "                           cv = 5, return_train_score = True)\n",
    "print(\"Grid Search :\", grid_search.fit(X_train_wine, y_train_wine))\n",
    "\n",
    "y_estimated_train_wine = grid_search.predict(X_train_wine)\n",
    "print(\"Accuracy train:\", accuracy_score(y_train_wine, y_estimated_train_wine))\n",
    "\n",
    "y_estimated_test_wine = grid_search.predict(X_test_wine)\n",
    "print(\"Accuracy test:\", accuracy_score(y_test_wine, y_estimated_test_wine))\n",
    "\n",
    "print(\"Best parameter:\", grid_search.best_params_)\n",
    "\n",
    "scores = cross_val_score(GridSearchCV(estimator = GaussianProcessClassifier(), param_grid=parameter_grid, \n",
    "                                      scoring='accuracy', cv=5), x_wine, y_wine, cv=4)\n",
    "print(\"Mean accuracy:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mammographic, X_test_mammographic, y_train_mammographic, y_test_mammographic = train_test_split(\n",
    "    x_mammographic, y_mammographic, test_size=1/5)\n",
    "parameter_grid = {'kernel': [None, 'kernel'], 'n_restarts_optimizer': list(range(0, 5))}\n",
    "\n",
    "grid_search = GridSearchCV(estimator = GaussianProcessClassifier(), param_grid = parameter_grid, scoring = 'accuracy', \n",
    "                           cv = 5, return_train_score = True)\n",
    "print(\"Grid Search :\", grid_search.fit(X_train_mammographic, y_train_mammographic))\n",
    "\n",
    "y_estimated_train_mammographic = grid_search.predict(X_train_mammographic)\n",
    "print(\"Accuracy train:\", accuracy_score(y_train_mammographic, y_estimated_train_mammographic))\n",
    "\n",
    "y_estimated_test_mammographic = grid_search.predict(X_test_mammographic)\n",
    "print(\"Accuracy test:\", accuracy_score(y_test_mammographic, y_estimated_test_mammographic))\n",
    "\n",
    "print(\"Best parameter:\", grid_search.best_params_)\n",
    "\n",
    "scores = cross_val_score(GridSearchCV(estimator = GaussianProcessClassifier(), param_grid=parameter_grid, \n",
    "                                      scoring='accuracy', cv=5), x_mammographic, y_mammographic, cv=4)\n",
    "print(\"Mean accuracy:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ecoli, X_test_ecoli, y_train_ecoli, y_test_ecoli = train_test_split(\n",
    "    x_ecoli, y_ecoli, test_size=1/5)\n",
    "parameter_grid = {'kernel': [None, 'kernel'], 'n_restarts_optimizer': list(range(0, 5))}\n",
    "\n",
    "grid_search = GridSearchCV(estimator = GaussianProcessClassifier(), param_grid = parameter_grid, scoring = 'accuracy', \n",
    "                           cv = 5, return_train_score = True)\n",
    "print(\"Grid Search :\", grid_search.fit(X_train_ecoli, y_train_ecoli))\n",
    "\n",
    "y_estimated_train_ecoli = grid_search.predict(X_train_ecoli)\n",
    "print(\"Accuracy train:\", accuracy_score(y_train_ecoli, y_estimated_train_ecoli))\n",
    "\n",
    "y_estimated_test_mammographic = grid_search.predict(X_test_mammographic)\n",
    "print(\"Accuracy test:\", accuracy_score(y_test_ecoli, y_estimated_test_ecoli))\n",
    "\n",
    "print(\"Best parameter:\", grid_search.best_params_)\n",
    "\n",
    "scores = cross_val_score(GridSearchCV(estimator = GaussianProcessClassifier(), param_grid=parameter_grid, \n",
    "                                      scoring='accuracy', cv=5), x_ecoli, y_ecoli, cv=4)\n",
    "print(\"Mean accuracy:\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=magenta> 5. GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_yeast, X_test_yeast, y_train_yeast, y_test_yeast = train_test_split(x_yeast, y_yeast, test_size=1/5)\n",
    "parameter_grid = {'var_smoothing': [1e-4, 5e-6, 1e-9]}\n",
    "\n",
    "grid_search = GridSearchCV(estimator = GaussianNB(), param_grid = parameter_grid, scoring = 'accuracy', \n",
    "                           cv = 5, return_train_score = True)\n",
    "print(\"Grid Search :\", grid_search.fit(X_train_yeast, y_train_yeast))\n",
    "\n",
    "y_estimated_train_yeast = grid_search.predict(X_train_yeast)\n",
    "print(\"Accuracy train:\", accuracy_score(y_train_yeast, y_estimated_train_yeast))\n",
    "\n",
    "y_estimated_test_yeast = grid_search.predict(X_test_yeast)\n",
    "print(\"Accuracy test:\", accuracy_score(y_test_yeast, y_estimated_test_yeast))\n",
    "\n",
    "print(\"Best parameter:\", grid_search.best_params_)\n",
    "\n",
    "scores = cross_val_score(GridSearchCV(estimator = GaussianNB(), param_grid=parameter_grid, \n",
    "                                      scoring='accuracy', cv=5), x_yeast, y_yeast, cv=4)\n",
    "print(\"Mean accuracy:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_wine, X_test_wine, y_train_wine, y_test_wine = train_test_split(x_wine, y_wine, test_size=1/5)\n",
    "parameter_grid = {'var_smoothing': [1e-4, 5e-6, 1e-9]}\n",
    "\n",
    "grid_search = GridSearchCV(estimator = GaussianNB(), param_grid = parameter_grid, scoring = 'accuracy', \n",
    "                           cv = 5, return_train_score = True)\n",
    "print(\"Grid Search :\", grid_search.fit(X_train_wine, y_train_wine))\n",
    "\n",
    "y_estimated_train_wine = grid_search.predict(X_train_wine)\n",
    "print(\"Accuracy train:\", accuracy_score(y_train_wine, y_estimated_train_wine))\n",
    "\n",
    "y_estimated_test_wine = grid_search.predict(X_test_wine)\n",
    "print(\"Accuracy test:\", accuracy_score(y_test_wine, y_estimated_test_wine))\n",
    "\n",
    "print(\"Best parameter:\", grid_search.best_params_)\n",
    "\n",
    "scores = cross_val_score(GridSearchCV(estimator = GaussianNB(), param_grid=parameter_grid, \n",
    "                                      scoring='accuracy', cv=5), x_wine, y_wine, cv=4)\n",
    "print(\"Mean accuracy:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mammographic, X_test_mammographic, y_train_mammographic, y_test_mammographic = train_test_split(\n",
    "    x_mammographic, y_mammographic, test_size=1/5)\n",
    "parameter_grid = {'var_smoothing': [1e-4, 5e-6, 1e-9]}\n",
    "\n",
    "grid_search = GridSearchCV(estimator = GaussianNB(), param_grid = parameter_grid, scoring = 'accuracy', \n",
    "                           cv = 5, return_train_score = True)\n",
    "print(\"Grid Search :\", grid_search.fit(X_train_mammographic, y_train_mammographic))\n",
    "\n",
    "y_estimated_train_mammographic = grid_search.predict(X_train_mammographic)\n",
    "print(\"Accuracy train:\", accuracy_score(y_train_mammographic, y_estimated_train_mammographic))\n",
    "\n",
    "y_estimated_test_mammographic = grid_search.predict(X_test_mammographic)\n",
    "print(\"Accuracy test:\", accuracy_score(y_test_mammographic, y_estimated_test_mammographic))\n",
    "\n",
    "print(\"Best parameter:\", grid_search.best_params_)\n",
    "\n",
    "scores = cross_val_score(GridSearchCV(estimator = GaussianNB(), param_grid=parameter_grid, \n",
    "                                      scoring='accuracy', cv=5), x_mammographic, y_mammographic, cv=4)\n",
    "print(\"Mean accuracy:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ecoli, X_test_ecoli, y_train_ecoli, y_test_ecoli = train_test_split(\n",
    "    x_ecoli, y_ecoli, test_size=1/5)\n",
    "parameter_grid = {'var_smoothing': [1e-4, 5e-6, 1e-9]}\n",
    "\n",
    "grid_search = GridSearchCV(estimator = GaussianNB(), param_grid = parameter_grid, scoring = 'accuracy', \n",
    "                           cv = 5, return_train_score = True)\n",
    "print(\"Grid Search :\", grid_search.fit(X_train_ecoli, y_train_ecoli))\n",
    "\n",
    "y_estimated_train_ecoli = grid_search.predict(X_train_ecoli)\n",
    "print(\"Accuracy train:\", accuracy_score(y_train_ecoli, y_estimated_train_ecoli))\n",
    "\n",
    "y_estimated_test_ecoli = grid_search.predict(X_test_ecoli)\n",
    "print(\"Accuracy test:\", accuracy_score(y_test_ecoli, y_estimated_test_ecoli))\n",
    "\n",
    "print(\"Best parameter:\", grid_search.best_params_)\n",
    "\n",
    "scores = cross_val_score(GridSearchCV(estimator = GaussianNB(), param_grid=parameter_grid, \n",
    "                                      scoring='accuracy', cv=5), x_ecoli, y_ecoli, cv=4)\n",
    "print(\"Mean accuracy:\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color= magenta> 6. DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_yeast, X_test_yeast, y_train_yeast, y_test_yeast = train_test_split(x_yeast, y_yeast, test_size=1/5)\n",
    "parameter_grid = {'criterion': ['gini', 'entropy'], 'splitter': ['best', 'random']}\n",
    "\n",
    "grid_search = GridSearchCV(estimator = DecisionTreeClassifier(), param_grid = parameter_grid, scoring = 'accuracy', \n",
    "                           cv = 5, return_train_score = True)\n",
    "print(\"Grid Search :\", grid_search.fit(X_train_yeast, y_train_yeast))\n",
    "\n",
    "y_estimated_train_yeast = grid_search.predict(X_train_yeast)\n",
    "print(\"Accuracy train:\", accuracy_score(y_train_yeast, y_estimated_train_yeast))\n",
    "\n",
    "y_estimated_test_yeast = grid_search.predict(X_test_yeast)\n",
    "print(\"Accuracy test:\", accuracy_score(y_test_yeast, y_estimated_test_yeast))\n",
    "\n",
    "print(\"Best parameter:\", grid_search.best_params_)\n",
    "\n",
    "scores = cross_val_score(GridSearchCV(estimator = DecisionTreeClassifier(), param_grid=parameter_grid, \n",
    "                                      scoring='accuracy', cv=5), x_yeast, y_yeast, cv=4)\n",
    "print(\"Mean accuracy:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_wine, X_test_wine, y_train_wine, y_test_wine = train_test_split(x_wine, y_wine, test_size=1/5)\n",
    "parameter_grid =  {'criterion': ['gini', 'entropy'], 'splitter': ['best', 'random']}\n",
    "\n",
    "grid_search = GridSearchCV(estimator = DecisionTreeClassifier(), param_grid = parameter_grid, scoring = 'accuracy', \n",
    "                           cv = 5, return_train_score = True)\n",
    "print(\"Grid Search :\", grid_search.fit(X_train_wine, y_train_wine))\n",
    "\n",
    "y_estimated_train_wine = grid_search.predict(X_train_wine)\n",
    "print(\"Accuracy train:\", accuracy_score(y_train_wine, y_estimated_train_wine))\n",
    "\n",
    "y_estimated_test_wine = grid_search.predict(X_test_wine)\n",
    "print(\"Accuracy test:\", accuracy_score(y_test_wine, y_estimated_test_wine))\n",
    "\n",
    "print(\"Best parameter:\", grid_search.best_params_)\n",
    "\n",
    "scores = cross_val_score(GridSearchCV(estimator = DecisionTreeClassifier(), param_grid=parameter_grid, \n",
    "                                      scoring='accuracy', cv=5), x_wine, y_wine, cv=4)\n",
    "print(\"Mean accuracy:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mammographic, X_test_mammographic, y_train_mammographic, y_test_mammographic = train_test_split(\n",
    "    x_mammographic, y_mammographic, test_size=1/5)\n",
    "parameter_grid = {'criterion': ['gini', 'entropy'], 'splitter': ['best', 'random']}\n",
    "\n",
    "grid_search = GridSearchCV(estimator = DecisionTreeClassifier(), param_grid = parameter_grid, scoring = 'accuracy', \n",
    "                           cv = 5, return_train_score = True)\n",
    "print(\"Grid Search :\", grid_search.fit(X_train_mammographic, y_train_mammographic))\n",
    "\n",
    "y_estimated_train_mammographic = grid_search.predict(X_train_mammographic)\n",
    "print(\"Accuracy train:\", accuracy_score(y_train_mammographic, y_estimated_train_mammographic))\n",
    "\n",
    "y_estimated_test_mammographic = grid_search.predict(X_test_mammographic)\n",
    "print(\"Accuracy test:\", accuracy_score(y_test_mammographic, y_estimated_test_mammographic))\n",
    "\n",
    "print(\"Best parameter:\", grid_search.best_params_)\n",
    "\n",
    "scores = cross_val_score(GridSearchCV(estimator = DecisionTreeClassifier(), param_grid=parameter_grid, \n",
    "                                      scoring='accuracy', cv=5), x_mammographic, y_mammographic, cv=4)\n",
    "print(\"Mean accuracy:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ecoli, X_test_ecoli, y_train_ecoli, y_test_ecoli = train_test_split(\n",
    "    x_ecoli, y_ecoli, test_size=1/5)\n",
    "parameter_grid = {'criterion': ['gini', 'entropy'], 'splitter': ['best', 'random']}\n",
    "\n",
    "grid_search = GridSearchCV(estimator = DecisionTreeClassifier(), param_grid = parameter_grid, scoring = 'accuracy', \n",
    "                           cv = 5, return_train_score = True)\n",
    "print(\"Grid Search :\", grid_search.fit(X_train_ecoli, y_train_ecoli))\n",
    "\n",
    "y_estimated_train_ecoli = grid_search.predict(X_train_ecoli)\n",
    "print(\"Accuracy train:\", accuracy_score(y_train_ecoli, y_estimated_train_ecoli))\n",
    "\n",
    "y_estimated_test_ecoli = grid_search.predict(X_test_ecoli)\n",
    "print(\"Accuracy test:\", accuracy_score(y_test_ecoli, y_estimated_test_ecoli))\n",
    "\n",
    "print(\"Best parameter:\", grid_search.best_params_)\n",
    "\n",
    "scores = cross_val_score(GridSearchCV(estimator = DecisionTreeClassifier(), param_grid=parameter_grid, \n",
    "                                      scoring='accuracy', cv=5), x_ecoli, y_ecoli, cv=4)\n",
    "print(\"Mean accuracy:\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color= magenta> 7. RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_yeast, X_test_yeast, y_train_yeast, y_test_yeast = train_test_split(x_yeast, y_yeast, test_size = 1/5)\n",
    "parameter_grid = {'n_estimators': [100, 150, 200], 'max_depth': [2, 5], 'min_samples_leaf': [2, 10, 15]}\n",
    "\n",
    "grid_search = GridSearchCV(estimator = RandomForestClassifier(), param_grid = parameter_grid, scoring = 'accuracy', \n",
    "                           cv = 5, return_train_score = True)\n",
    "print(\"Grid Search :\", grid_search.fit(X_train_yeast, y_train_yeast))\n",
    "\n",
    "y_estimated_train_yeast = grid_search.predict(X_train_yeast)\n",
    "print(\"Accuracy train:\", accuracy_score(y_train_yeast, y_estimated_train_yeast))\n",
    "\n",
    "y_estimated_test_yeast = grid_search.predict(X_test_yeast)\n",
    "print(\"Accuracy test:\", accuracy_score(y_test_yeast, y_estimated_test_yeast))\n",
    "\n",
    "print(\"Best parameter:\", grid_search.best_params_)\n",
    "\n",
    "scores = cross_val_score(GridSearchCV(estimator = RandomForestClassifier(), param_grid = parameter_grid, \n",
    "                                      scoring = 'accuracy', cv = 5), x_yeast, y_yeast, cv = 4)\n",
    "print(\"Mean accuracy:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_wine, X_test_wine, y_train_wine, y_test_wine = train_test_split(x_wine, y_wine, test_size = 1/5)\n",
    "parameter_grid = {'n_estimators': [100, 150, 200], 'max_depth': [2, 5], 'min_samples_leaf': [2, 10, 15]}\n",
    "\n",
    "grid_search = GridSearchCV(estimator = RandomForestClassifier(), param_grid = parameter_grid, scoring = 'accuracy', \n",
    "                           cv = 5, return_train_score = True)\n",
    "print(\"Grid Search :\", grid_search.fit(X_train_wine, y_train_wine))\n",
    "\n",
    "y_estimated_train_wine = grid_search.predict(X_train_wine)\n",
    "print(\"Accuracy train:\", accuracy_score(y_train_wine, y_estimated_train_wine))\n",
    "\n",
    "y_estimated_test_wine = grid_search.predict(X_test_wine)\n",
    "print(\"Accuracy test:\", accuracy_score(y_test_wine, y_estimated_test_wine))\n",
    "\n",
    "print(\"Best parameter:\", grid_search.best_params_)\n",
    "\n",
    "scores = cross_val_score(GridSearchCV(estimator = RandomForestClassifier(), param_grid = parameter_grid, \n",
    "                                      scoring = 'accuracy', cv = 5), x_wine, y_wine, cv = 4)\n",
    "print(\"Mean accuracy:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-15d361e00c0d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m X_train_mammographic, X_test_mammographic, y_train_mammographic, y_test_mammographic = train_test_split(\n\u001b[0m\u001b[0;32m      2\u001b[0m     x_mammographic, y_mammographic, test_size = 1/5)\n\u001b[0;32m      3\u001b[0m \u001b[0mparameter_grid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'n_estimators'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m150\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'max_depth'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'min_samples_leaf'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m15\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m grid_search = GridSearchCV(estimator = RandomForestClassifier(), param_grid = parameter_grid, scoring = 'accuracy', \n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "X_train_mammographic, X_test_mammographic, y_train_mammographic, y_test_mammographic = train_test_split(\n",
    "    x_mammographic, y_mammographic, test_size = 1/5)\n",
    "parameter_grid = {'n_estimators': [100, 150, 200], 'max_depth': [2, 5], 'min_samples_leaf': [2, 10, 15]}\n",
    "\n",
    "grid_search = GridSearchCV(estimator = RandomForestClassifier(), param_grid = parameter_grid, scoring = 'accuracy', \n",
    "                           cv = 5, return_train_score = True)\n",
    "print(\"Grid Search :\", grid_search.fit(X_train_mammographic, y_train_mammographic))\n",
    "\n",
    "y_estimated_train_mammographic = grid_search.predict(X_train_mammographic)\n",
    "print(\"Accuracy train:\", accuracy_score(y_train_mammographic, y_estimated_train_mammographic))\n",
    "\n",
    "y_estimated_test_mammographic = grid_search.predict(X_test_mammographic)\n",
    "print(\"Accuracy test:\", accuracy_score(y_test_mammographic, y_estimated_test_mammographic))\n",
    "\n",
    "print(\"Best parameter:\", grid_search.best_params_)\n",
    "\n",
    "scores = cross_val_score(GridSearchCV(estimator = RandomForestClassifier(), param_grid = parameter_grid, \n",
    "                                      scoring = 'accuracy', cv = 5), x_mammographic, y_mammographic, cv = 4)\n",
    "print(\"Mean accuracy:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ecoli, X_test_ecoli, y_train_ecoli, y_test_ecoli = train_test_split(\n",
    "    x_ecoli, y_ecoli, test_size = 1/5)\n",
    "parameter_grid = {'n_estimators': [100, 150, 200], 'max_depth': [2, 5], 'min_samples_leaf': [2, 10, 15]}\n",
    "\n",
    "grid_search = GridSearchCV(estimator = RandomForestClassifier(), param_grid = parameter_grid, scoring = 'accuracy', \n",
    "                           cv = 5, return_train_score = True)\n",
    "print(\"Grid Search :\", grid_search.fit(X_train_ecoli, y_train_ecoli))\n",
    "\n",
    "y_estimated_train_ecoli = grid_search.predict(X_train_ecoli)\n",
    "print(\"Accuracy train:\", accuracy_score(y_train_ecoli, y_estimated_train_ecoli))\n",
    "\n",
    "y_estimated_test_ecoli = grid_search.predict(X_test_ecoli)\n",
    "print(\"Accuracy test:\", accuracy_score(y_test_ecoli, y_estimated_test_ecoli))\n",
    "\n",
    "print(\"Best parameter:\", grid_search.best_params_)\n",
    "\n",
    "scores = cross_val_score(GridSearchCV(estimator = RandomForestClassifier(), param_grid = parameter_grid, \n",
    "                                      scoring = 'accuracy', cv = 5), x_ecoli, y_ecoli, cv = 4)\n",
    "print(\"Mean accuracy:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "notify_time": "5",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
